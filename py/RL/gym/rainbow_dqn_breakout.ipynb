{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMUp1vKQmrI5SXCd1Wktx3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQi5XEaNQ09f","executionInfo":{"status":"ok","timestamp":1670785064600,"user_tz":-540,"elapsed":101355,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"8613f594-ad20-4b76-cd81-fd066acddc42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting colabgymrender\n","  Downloading colabgymrender-1.1.0.tar.gz (3.5 kB)\n","Collecting imageio==2.4.1\n","  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 5.7 MB/s \n","\u001b[?25hCollecting atari-py==0.2.6\n","  Downloading atari-py-0.2.6.tar.gz (790 kB)\n","\u001b[K     |████████████████████████████████| 790 kB 59.5 MB/s \n","\u001b[?25hCollecting gym==0.17.3\n","  Downloading gym-0.17.3.tar.gz (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (1.21.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from atari-py==0.2.6) (1.15.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from gym==0.17.3) (1.7.3)\n","Collecting pyglet<=1.5.0,>=1.4.0\n","  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.17.3) (1.5.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (0.16.0)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (from colabgymrender) (0.2.3.5)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy->colabgymrender) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy->colabgymrender) (4.64.1)\n","\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'atari-py' candidate (version 0.2.6 at https://files.pythonhosted.org/packages/43/dd/2721f34a89dc520d2e09363fd23d110a33bbab2399e50fdced6eb2ed2157/atari-py-0.2.6.tar.gz#sha256=6249ad5079b0489e87eb44e65485bb1b07cc1b5af729f1ee52ece749503ceb1d (from https://pypi.org/simple/atari-py/))\n","Reason for being yanked: re-release with new wheels\u001b[0m\n","Building wheels for collected packages: imageio, atari-py, gym, colabgymrender\n","  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303886 sha256=7b6e02bea06112ddfb3446f5c93e6bfd08800e505e3765ee77d0bde97ff94cbf\n","  Stored in directory: /root/.cache/pip/wheels/be/7b/04/4d8d56f1d503e5c404f0de6018c0cfa592c71588a39b49e002\n","  Building wheel for atari-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for atari-py: filename=atari_py-0.2.6-cp38-cp38-linux_x86_64.whl size=3093083 sha256=8b4ccd07384618a9b7f6ce7509949b7d4e74eb2f6e98a3c21f956b63017559a7\n","  Stored in directory: /root/.cache/pip/wheels/7f/5e/27/2e90b9887063d82ee2f9f8b2f8db76bb2290aa281dc40449c8\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654651 sha256=52c1618a99bf9abc14d43cdbd1d7577e5b36c6da94c8bdca559d6ca1c6d404b2\n","  Stored in directory: /root/.cache/pip/wheels/84/40/e7/14efb9870cfc92ac236d78cb721dce614ddec9666c8a5e0a35\n","  Building wheel for colabgymrender (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for colabgymrender: filename=colabgymrender-1.1.0-py3-none-any.whl size=3130 sha256=48d497e4a2977584f642ec049118f1be4fb7036832a90f39c6dab88285e9c9d5\n","  Stored in directory: /root/.cache/pip/wheels/e4/d2/e1/cc1c940178ad92438325422b51c3e8c3d927b9ef8381da8840\n","Successfully built imageio atari-py gym colabgymrender\n","Installing collected packages: imageio, pyglet, gym, colabgymrender, atari-py\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.9.0\n","    Uninstalling imageio-2.9.0:\n","      Successfully uninstalled imageio-2.9.0\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","  Attempting uninstall: atari-py\n","    Found existing installation: atari-py 0.2.9\n","    Uninstalling atari-py-0.2.9:\n","      Successfully uninstalled atari-py-0.2.9\n","Successfully installed atari-py-0.2.6 colabgymrender-1.1.0 gym-0.17.3 imageio-2.4.1 pyglet-1.5.0\n"]}],"source":["!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n","!pip install colabgymrender imageio==2.4.1 atari-py==0.2.6 gym==0.17.3"]},{"cell_type":"code","source":["!apt-get install x11-utils > /dev/null 2>&1 \n","!pip install pyglet > /dev/null 2>&1 \n","!apt-get install -y xvfb python-opengl > /dev/null 2>&1"],"metadata":{"id":"iIVzhYXERc5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt install xvfb -y\n","!pip install pyvirtualdisplay\n","!pip install piglet\n","# !pip install ptan pytorch-ignite pybullet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TjgMIJekRe6y","executionInfo":{"status":"ok","timestamp":1670785091713,"user_tz":-540,"elapsed":12631,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"f4273743-f6c9-4d2f-b2be-22db0c085520"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","xvfb is already the newest version (2:1.19.6-1ubuntu4.12).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Installing collected packages: pyvirtualdisplay\n","Successfully installed pyvirtualdisplay-3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting piglet\n","  Downloading piglet-1.0.0-py2.py3-none-any.whl (2.2 kB)\n","Collecting piglet-templates\n","  Downloading piglet_templates-1.3.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from piglet-templates->piglet) (3.0.9)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from piglet-templates->piglet) (22.1.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from piglet-templates->piglet) (2.0.1)\n","Requirement already satisfied: astunparse in /usr/local/lib/python3.8/dist-packages (from piglet-templates->piglet) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse->piglet-templates->piglet) (0.38.4)\n","Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n","Installing collected packages: piglet-templates, piglet\n","Successfully installed piglet-1.0.0 piglet-templates-1.3.0\n"]}]},{"cell_type":"code","source":["!pip uninstall -y torch torchvision torchaudio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QPOkdlcvmEnK","executionInfo":{"status":"ok","timestamp":1670785130438,"user_tz":-540,"elapsed":34006,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"2a09c15a-a895-474c-9d36-3b77d4304a1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 1.13.0+cu116\n","Uninstalling torch-1.13.0+cu116:\n","  Successfully uninstalled torch-1.13.0+cu116\n","Found existing installation: torchvision 0.14.0+cu116\n","Uninstalling torchvision-0.14.0+cu116:\n","  Successfully uninstalled torchvision-0.14.0+cu116\n","Found existing installation: torchaudio 0.13.0+cu116\n","Uninstalling torchaudio-0.13.0+cu116:\n","  Successfully uninstalled torchaudio-0.13.0+cu116\n"]}]},{"cell_type":"code","source":["!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ejjCimKljoQ","executionInfo":{"status":"ok","timestamp":1670785300015,"user_tz":-540,"elapsed":169582,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"a47ccd8d-b867-432f-beb2-afc842a69889"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n","Collecting torch\n","  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.0%2Bcu116-cp38-cp38-linux_x86_64.whl (1983.0 MB)\n","\u001b[K     |█████████████▌                  | 834.1 MB 1.3 MB/s eta 0:14:35tcmalloc: large alloc 1147494400 bytes == 0x39f2e000 @  0x7f909f1f4615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |█████████████████               | 1055.7 MB 1.2 MB/s eta 0:12:54tcmalloc: large alloc 1434370048 bytes == 0x7e584000 @  0x7f909f1f4615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |█████████████████████▋          | 1336.2 MB 1.2 MB/s eta 0:09:05tcmalloc: large alloc 1792966656 bytes == 0x33b6000 @  0x7f909f1f4615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:04:02tcmalloc: large alloc 2241208320 bytes == 0x6e19e000 @  0x7f909f1f4615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |████████████████████████████████| 1983.0 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1983012864 bytes == 0xf3b00000 @  0x7f909f1f31e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n","tcmalloc: large alloc 2478768128 bytes == 0x1de2ea000 @  0x7f909f1f4615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n","\u001b[K     |████████████████████████████████| 1983.0 MB 4.2 kB/s \n","\u001b[?25hCollecting torchvision\n","  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.14.0%2Bcu116-cp38-cp38-linux_x86_64.whl (24.2 MB)\n","\u001b[K     |████████████████████████████████| 24.2 MB 1.2 MB/s \n","\u001b[?25hCollecting torchaudio\n","  Downloading https://download.pytorch.org/whl/cu116/torchaudio-0.13.0%2Bcu116-cp38-cp38-linux_x86_64.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 64.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n","Installing collected packages: torch, torchvision, torchaudio\n","Successfully installed torch-1.13.0+cu116 torchaudio-0.13.0+cu116 torchvision-0.14.0+cu116\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HpTItjeBQ3Me"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import collections\n","from typing import Union\n","import math\n","import random\n","from copy import deepcopy\n","from typing import Optional\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","import gym\n","from gym.spaces import Box\n","from gym.wrappers import FrameStack\n","from colabgymrender.recorder import Recorder\n","from fastprogress import progress_bar as pb\n","import matplotlib.pyplot as plt"],"metadata":{"id":"71SJPvflyTsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ReplayBuffer:\n","\n","    def __init__(self, max_size: int):\n","        self._buf = collections.deque(maxlen=max_size)\n","\n","    def append(\n","        self,\n","        state: np.ndarray,\n","        action: int,\n","        reward: Union[int, float],\n","        done: bool,\n","        next_state: np.ndarray,\n","    ) -> None:\n","        self._buf.append(\n","            (state, action, reward, done, next_state)\n","        )\n","\n","    def sample(self, size: int):\n","        sampled_indices = np.random.choice(len(self.buffer), size, replace=False)\n","        states, actions, rewards, dones, next_states = \\\n","            zip(*[self.buffer[idx] for idx in sampled_indices])\n","        return np.array(states), np.array(actions), \\\n","               np.array(rewards, dtype=np.float32), \\\n","               np.array(dones, dtype=np.uint8), \\\n","               np.array(next_states)"],"metadata":{"id":"_2B0CAF6bVjG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NStepPriorityReplayBuffer:\n","\n","    def __init__(\n","        self,\n","        max_size: int,\n","        prob_alpha: float = 0.6,\n","        beta_start: float = 0.4,\n","        beta_frames: float = 100000,\n","        n_step: int = 4,\n","        gamma: float = 0.99,\n","    ):\n","        self._prob_alpha = prob_alpha\n","        self._max_size = max_size\n","        self._pos = 0\n","        self._buf = []\n","        self._priorities = np.zeros((max_size,), dtype=np.float32)\n","        self._beta_start = beta_start\n","        self._beta = beta_start\n","        self._beta_frames = beta_frames\n","        self._n_step = n_step\n","        self._gamma = gamma\n","        self._total_discounted_rewards = np.array([np.nan]*max_size)\n","        self._last_states = [np.nan]*max_size\n","\n","    def update_bata(self, idx) -> None:\n","        beta = self._beta_start + idx * (1.0 - self._beta_start) / self._beta_frames\n","        self._beta = min(1.0, beta)\n","        return self._beta\n","\n","    def __len__(self):\n","        return len(self._buf)\n","\n","    def append(\n","        self,\n","        state: np.ndarray,\n","        action: int,\n","        reward: Union[int, float],\n","        done: bool,\n","        next_state: np.ndarray,\n","    ) -> None:\n","        max_prio = self._priorities.max() if self._buf else 1.0\n","        if len(self._buf) < self._max_size:\n","            self._buf.append(\n","                (state, action, reward, done, next_state)\n","            )\n","        else:\n","            self._buf[self._pos] = (state, action, reward, done, next_state)\n","        self._priorities[self._pos] = max_prio\n","\n","        if len(self._buf) >= self._n_step:\n","            dis_r = 0.0\n","            last_state = self._buf[self._pos][0]\n","            for i in range(self._n_step):\n","                state, _, r, done, _ = self._buf[self._pos - i]\n","                dis_r = r + self._gamma * dis_r\n","                if done:\n","                    last_state = state\n","                    dis_r = r  # ※\n","                self._total_discounted_rewards[self._pos - i] = dis_r\n","                self._last_states[self._pos - i] = last_state\n","            \n","            for i in range(self._n_step-1):\n","                done = self._buf[self._pos - i][3]\n","                if done:\n","                    break\n","                self._total_discounted_rewards[self._pos - i] = np.nan\n","                self._last_states[self._pos - i] = np.nan\n","\n","        self._pos = (self._pos + 1) % self._max_size\n","\n","    def sample(self, size: int):\n","        sample_target_indices = np.where(~np.isnan(self._total_discounted_rewards[:len(self._buf)]))[0]\n","        # prios = self._priorities[sample_target_indices]  #self._priorities if len(self._buf) == self._max_size else self._priorities[:self._pos]\n","        prios = self._priorities\n","        probs = prios * self._prob_alpha\n","        # probs /= np.nan_to_num(probs, 0.0).sum()\n","        probs /= probs[sample_target_indices].sum()\n","        sampled_indices = np.random.choice(\n","            sample_target_indices,\n","            # np.where(~np.isnan(self._total_discounted_rewards[:len(self._buf)]))[0],\n","            size, p=probs[sample_target_indices]\n","        )\n","        states, actions, rewards, dones, next_states = zip(*[self._buf[idx] for idx in sampled_indices])\n","        states = np.array(states)\n","        actions = np.array(actions)\n","        rewards = np.array(rewards)\n","        dones = np.array(dones)\n","        next_states = np.array(next_states)\n","        total_discounted_rewards = self._total_discounted_rewards[sampled_indices]\n","        last_states = np.stack([self._last_states[idx] for idx in sampled_indices])\n","        total = len(self._buf)\n","        weights = np.array((total * probs[sampled_indices]) ** (-self._beta), dtype=np.float32)\n","        # weights = np.array((total * probs) ** (-self._beta), dtype=np.float32)\n","        weights /= weights.max()\n","        return states, actions, rewards, dones, total_discounted_rewards, last_states, sampled_indices, weights\n","\n","    def update_priorities(self, sample_indices: np.ndarray, sample_priorities: np.ndarray) -> None:\n","        self._priorities[sample_indices] = sample_priorities\n","\n","    @property\n","    def gamma(self) -> float:\n","        return self._gamma\n","\n","    @property\n","    def n_step(self) -> float:\n","        return self._n_step"],"metadata":{"id":"W9FQpg24jEnA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NoisyLinear(nn.Linear):\n","\n","    def __init__(self, in_features, out_features, sigma_init=0.017, bias=True):\n","        super(NoisyLinear, self).__init__(in_features, out_features, bias=bias)\n","        w = torch.full((out_features, in_features), sigma_init)\n","        self._sigma_weight = nn.Parameter(w)\n","        z = torch.zeros(out_features, in_features)\n","        self.register_buffer(\"epsilon_weight\", z)\n","        if bias:\n","            w = torch.full((out_features,), sigma_init)\n","            self._sigma_bias = nn.Parameter(w)\n","            z = torch.zeros(out_features)\n","            self.register_buffer(\"epsilon_bias\", z)\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        std = math.sqrt(3 / self.in_features)\n","        self.weight.data.uniform_(-std, std)\n","        self.bias.data.uniform_(-std, std)\n","\n","    def forward(self, input):\n","        self.epsilon_weight.normal_()\n","        bias = self.bias\n","        if bias is not None:\n","            self.epsilon_bias.normal_()\n","            bias = bias + self._sigma_bias * \\\n","                   self.epsilon_bias.data\n","        v = self._sigma_weight * self.epsilon_weight.data + \\\n","            self.weight\n","        return F.linear(input, v, bias)"],"metadata":{"id":"XTpLPXqqOu-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RainbowDQN(nn.Module):\n","\n","    def __init__(self, input_shape: np.ndarray, n_actions: int):\n","        super(RainbowDQN, self).__init__()\n","\n","        self._conv = nn.Sequential(\n","            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n","            nn.ReLU()\n","        )\n","\n","        conv_out_dim = int(np.prod(\n","            self._conv(torch.zeros(1, *input_shape)).size()\n","        ))\n","        self._fc_adv = nn.Sequential(\n","            NoisyLinear(conv_out_dim, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, n_actions)\n","        )\n","        self._fc_val = nn.Sequential(\n","            nn.Linear(conv_out_dim, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 1)\n","        )\n","\n","    def forward(self, x):\n","        # norm = 256\n","        # conv_out = self._conv(x / norm).view(x.size()[0], -1)\n","        conv_out = self._conv(x).view(x.size()[0], -1)\n","        adv = self._fc_adv(conv_out)\n","        val = self._fc_val(conv_out)\n","        return val - (adv - adv.mean(dim=1, keepdim=True))\n","        # return val, adv"],"metadata":{"id":"BFyEJQn6lxnn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def rainbow_loss(\n","    states: np.ndarray,\n","    actions: np.ndarray,\n","    total_discounted_rewards: np.ndarray,\n","    dones: np.ndarray,\n","    last_states: np.ndarray,\n","    weights: np.ndarray,\n","    net: nn.Module,\n","    tgt_net: nn.Module,\n","    n_step_gamma: float,\n","    double: bool = True,\n","    device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n","):\n","    states_v = torch.tensor(states).to(device)\n","    actions_v = torch.tensor(actions).to(device)\n","    discounted_rewards_v = torch.tensor(total_discounted_rewards).to(device)\n","    done_mask = torch.BoolTensor(dones).to(device)\n","    weights_v = torch.tensor(weights).to(device)\n","\n","    actions_v = actions_v.unsqueeze(-1)\n","    state_action_values = net(states_v).gather(1, actions_v)\n","    state_action_values = state_action_values.squeeze(-1)\n","    with torch.no_grad():\n","        last_states_v = torch.tensor(last_states).to(device)\n","        if double:\n","            last_state_actions = net(last_states_v).max(1)[1]\n","            last_state_actions = last_state_actions.unsqueeze(-1)\n","            last_state_values = tgt_net(last_states_v).gather(1, last_state_actions).squeeze(-1)\n","        else:\n","            last_state_values = tgt_net(last_states_v).max(1)[0]\n","        last_state_values[done_mask] = 0.0\n","        expected_state_action_values = last_state_values.detach() * n_step_gamma + discounted_rewards_v\n","    losses_v = (state_action_values - expected_state_action_values) ** 2\n","    losses_v *= weights_v\n","\n","    return losses_v.mean(), (losses_v + 1e-5).data.cpu().numpy()"],"metadata":{"id":"1VwPkDEi01y1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Agent:\n","\n","    def __init__(\n","        self,\n","        env,\n","        exp_buffer: NStepPriorityReplayBuffer,\n","        net: nn.Module,\n","        epsilon_start: float = 1.0,\n","        epsilon_final: float = 0.01,\n","        epsilon_decay_last_step: int = 200000,\n","        tgt_sync_steps: int = 10000,\n","        learning_rate: float = 1e-4,\n","        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    ):\n","        self._env = env\n","        self._exp_buffer = exp_buffer\n","        self._net = net\n","        self._tgt_net = deepcopy(net)\n","        for p in self._tgt_net.parameters():\n","            p.requires_grad = False\n","        self._epsilon_start = epsilon_start\n","        self._epsilon_final = epsilon_final\n","        self._epsilon_decay_last_step = epsilon_decay_last_step\n","        self._epsilon = epsilon_start\n","        self._device = device\n","        self._total_step = 0\n","        self._total_trained_samples = 0\n","        self._tgt_sync_steps = tgt_sync_steps\n","        self._optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","        self._reset_episode()\n","\n","    def _reset_episode(self):\n","        self._state = self._env.reset()\n","        self._total_reward = 0.0\n","\n","    @torch.no_grad()\n","    def play_step(self, epsilon: Optional[float] = None):\n","        if epsilon is None:\n","            epsilon = self._epsilon\n","        done_reward = None\n","\n","        if np.random.random() < epsilon:\n","            action = self._env.action_space.sample()\n","        else:\n","            state_a = np.array([self._state], copy=False)\n","            state_v = torch.tensor(state_a).to(self._device)\n","            q_vals_v = self._net(state_v)\n","            _, act_v = torch.max(q_vals_v, dim=1)\n","            action = int(act_v.item())\n","\n","        next_state, reward, is_done, _ = self._env.step(action)\n","        self._total_reward += reward\n","\n","        self._exp_buffer.append(\n","            self._state, action, reward, is_done, next_state\n","        )\n","        self._state = next_state\n","        if is_done:\n","            done_reward = self._total_reward\n","            self._reset_episode()\n","\n","        self._total_step += 1\n","        self._update_epsilon(self._total_step)\n","        self._exp_buffer.update_bata(self._total_step)\n","\n","        if self._total_step % self._tgt_sync_steps == 0:\n","            self._tgt_net.load_state_dict(self._net.state_dict())\n","            print(f'synced target net')\n","\n","        return done_reward\n","\n","    def train(self, n_iter: int = 1, batch_size: int = 32) -> None:\n","        for i in range(n_iter):\n","            states, actions, rewards, dones, total_discounted_rewards, \\\n","                last_states, sampled_indices, weights = self._exp_buffer.sample(batch_size)\n","            self._optimizer.zero_grad()\n","            loss_v, prios = rainbow_loss(\n","                states=states,\n","                actions=actions,\n","                total_discounted_rewards=total_discounted_rewards,\n","                dones=dones,\n","                last_states=last_states,\n","                weights=weights,\n","                net=self._net,\n","                tgt_net=self._tgt_net,\n","                n_step_gamma=self._exp_buffer.gamma ** self._exp_buffer.n_step\n","            )\n","            loss_v.backward()\n","            self._optimizer.step()\n","            self._exp_buffer.update_priorities(sampled_indices, prios)\n","            self._total_trained_samples += batch_size\n","\n","    def initial_exploration(self, n_steps: int = 10000, epsilon: float = 1.0) -> None:\n","        eps_bak = self._epsilon\n","        for i in pb(range(n_steps)):\n","            self._epsilon = epsilon\n","            self.play_step()\n","        self._total_step = 0\n","        self._epsilon = eps_bak\n","\n","    def _update_epsilon(self, step_index: int) -> None:\n","        self._epsilon = max(\n","            self._epsilon_final,\n","            self._epsilon_start - step_index / self._epsilon_decay_last_step\n","        )"],"metadata":{"id":"KCzmWe6tZQfa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SkipFrame(gym.Wrapper):\n","    def __init__(self, env, skip):\n","        super().__init__(env)\n","        self._skip = skip\n","\n","    def step(self, action):\n","        total_reward = 0.0\n","        done = False\n","        for i in range(self._skip):\n","            obs, reward, done, info = self.env.step(action)\n","            total_reward += reward\n","            if done:\n","                break\n","        return obs, total_reward, done, info\n","\n","\n","class GrayScaleObservation(gym.ObservationWrapper):\n","    def __init__(self, env):\n","        super().__init__(env)\n","        obs_shape = self.observation_space.shape[:2]\n","        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n","\n","    def permute_orientation(self, observation):\n","        observation = np.transpose(observation, (2, 0, 1))\n","        observation = torch.tensor(observation.copy(), dtype=torch.float)\n","        return observation\n","\n","    def observation(self, observation):\n","        observation = self.permute_orientation(observation)\n","        transform = T.Grayscale()\n","        observation = transform(observation)\n","        return observation\n","\n","\n","class ResizeObservation(gym.ObservationWrapper):\n","    def __init__(self, env, shape):\n","        super().__init__(env)\n","        if isinstance(shape, int):\n","            self.shape = (shape, shape)\n","        else:\n","            self.shape = tuple(shape)\n","\n","        obs_shape = self.shape + self.observation_space.shape[2:]\n","        self.observation_space = Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n","\n","    def observation(self, observation):\n","        transforms = T.Compose(\n","            [T.Resize(self.shape), T.Normalize(0, 255)]\n","        )\n","        observation = transforms(observation).squeeze(0)\n","        return observation\n","\n","\n","class LazyFramesToNumpy(gym.ObservationWrapper):\n","    def __init__(self, env):\n","        super(LazyFramesToNumpy, self).__init__(env)\n","\n","    def observation(self, observation):\n","        return observation.__array__()"],"metadata":{"id":"yibBIGFFi4Ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JquC8cUBQ_yi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SEED = 77"],"metadata":{"id":"WRpvAThwRSz-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.seed(SEED)\n","torch.manual_seed(SEED)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","!rm -rf /content/video\n","\n","env = gym.make(\"Breakout-v0\")\n","env = SkipFrame(env, skip=4)\n","env = GrayScaleObservation(env)\n","env = ResizeObservation(env, shape=224)\n","env = FrameStack(env, num_stack=4)\n","env = LazyFramesToNumpy(env)\n","directory = './video'\n","env = Recorder(env, directory)"],"metadata":{"id":"GuSxnztRRQgg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = RainbowDQN(env.observation_space.shape, env.action_space.n).to(device)"],"metadata":{"id":"46KtGZwwSVQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env.action_space.n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mBqDe8eupWau","executionInfo":{"status":"ok","timestamp":1670786470931,"user_tz":-540,"elapsed":13,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"65a9cb3c-bbab-46a9-9849-9f49103d6ad6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["state = env.reset()"],"metadata":{"id":"bm1BuSftnSpH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["state.max()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s9M3vyERBxFC","executionInfo":{"status":"ok","timestamp":1670786470931,"user_tz":-540,"elapsed":12,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"9a99c661-6756-47f3-d9a1-45d03433cdc2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.58158356"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["state.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zM92lpmWo-j7","executionInfo":{"status":"ok","timestamp":1670786470931,"user_tz":-540,"elapsed":10,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"2760c2fc-9459-4943-a334-caa0639d0d2b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 224, 224)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["plt.imshow(state[0], cmap='gray')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"1qMPymoMNxVn","executionInfo":{"status":"ok","timestamp":1670786471350,"user_tz":-540,"elapsed":428,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"df9d823d-7422-416e-eed3-9f67226a6c7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fe33085d580>"]},"metadata":{},"execution_count":16},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["net(torch.tensor(state).unsqueeze(0).to(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ES0UFwA1ng6k","executionInfo":{"status":"ok","timestamp":1670786474426,"user_tz":-540,"elapsed":3077,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"2ae69df6-9e88-4258-f601-a4c468b0471f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0179,  0.0397,  0.0255,  0.0609]], device='cuda:0',\n","       grad_fn=<SubBackward0>)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[],"metadata":{"id":"I03--kgmoK69"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["exp_buffer = NStepPriorityReplayBuffer(\n","    max_size=10000,\n","    prob_alpha=0.6,\n","    beta_start=0.4,\n","    beta_frames=50000, #100000,\n","    n_step=4,\n","    gamma=0.99,\n",")\n","agent = Agent(\n","    env=env,\n","    exp_buffer=exp_buffer,\n","    net=net,\n","    epsilon_start=0.6,\n","    epsilon_final=0.01,\n","    epsilon_decay_last_step=50000, #200000,\n","    tgt_sync_steps=1000,\n","    learning_rate=1e-4,\n","    device=device\n",")"],"metadata":{"id":"3ylZLU3Bpujg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent.initial_exploration(n_steps=10000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"s8ZWbtSMqlF1","executionInfo":{"status":"ok","timestamp":1670786526352,"user_tz":-540,"elapsed":51931,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"a7fb4b04-7dab-40e2-d312-165cafc7d3df"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='10000' class='' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [10000/10000 00:51&lt;00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["synced target net\n","synced target net\n","synced target net\n","synced target net\n","synced target net\n","synced target net\n","synced target net\n","synced target net\n","synced target net\n","synced target net\n"]}]},{"cell_type":"code","source":["states, actions, rewards, dones, next_states = zip(*agent._exp_buffer._buf)"],"metadata":{"id":"66slc2xACT4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(16, 6))\n","plt.plot(rewards[:200])\n","plt.plot(agent._exp_buffer._total_discounted_rewards[:200])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"qKVFAcisCLwQ","executionInfo":{"status":"ok","timestamp":1670777262685,"user_tz":-540,"elapsed":501,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"7b5ff46d-0fce-46f8-c60c-9ca41459dcdf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f1e6297e0a0>]"]},"metadata":{},"execution_count":69},{"output_type":"display_data","data":{"text/plain":["<Figure size 1152x432 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA6IAAAFlCAYAAADxilWiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7QlZ3nf+d9TtVvgCAweSyFYQpaCxXgUjxM8vcDBsQfHYAuGJXl8yaCMHV9w5HgZL2fsNRMcz2AWkxVfMrYzWRAzysDyZWIuvkYrFiMSDLEdG1stX0Eg0wgYpGCQwAY7XNRV7zN/VNU+++xT+5z9vHv3qep+v5+1WN19evfpQruqdz31e9/nMXcXAAAAAACnpZr6AAAAAAAAZaEQBQAAAACcKgpRAAAAAMCpohAFAAAAAJwqClEAAAAAwKmiEAUAAAAAnKrFVH/xVVdd5ddff/1Ufz0AAAAA4CK69957H3H3q8d+b7JC9Prrr9e5c+em+usBAAAAABeRmb1/0++xNBcAAAAAcKooRAEAAAAAp4pCFAAAAABwqihEAQAAAACnikIUAAAAAHCqKEQBAAAAAKeKQhQAAAAAcKooRAEAAAAAp4pCFAAAAABwqk4sRM3sNWb2YTN7+4bfNzP7F2Z23sz+0My+aP+HCQAAAAC4XGyTiP6kpJuP+f3nSbqx/9/tkn5i98MCAAAAAFyuTixE3f3XJH30mJfcKumnvfM2SU80syfv6wABAJiLT3z8o/rQe0cXCAG4BD3ygfv18Uf+ZOrDwCXooXf9ji48+qmpD+OSto89otdI+sDKrx/sv3aEmd1uZufM7NzDDz+8h78aAIBT8t5fV/uKZ+rMTz1/6iMBsKuUpN98hZ7w6mfp3f/Pd099NLiUfPrP9ejPf7uued1z9Udv/L+nPppL2uI0/zJ3v0PSHZJ09uxZP82/GwCALO0F6a0/KP36j+nxcn3Sr5j6iADs4s8/JP3yd0jvebPOSLIL/3nqI8Kl4qF7pV/4Nl3x0QckSY9+4uMTH9ClbR+J6EOSnrLy62v7rwEAcGn76APSa75K+vUflZ7+Dfqtq75OtdqpjwpArj9+k/QTz5Le/5vSC35c77brZc41jROkJP3Gj0uv/kqpeVQfueWn+6830x7XJW4fheidkv5e3z33iyV9zN0/uIfvCwDAdP7g9dKrvkz6yHnp639SuvUV+mR1pWqlqY8MQNSFT0lv/EfSz3699Pi/It3+Vunst6pVrYpCFMf5+H+SfuZW6d+/TPr8F0jf8Rv65Oc8q/s9zp2dnLg018xeK+nZkq4yswcl/YCkM5Lk7q+SdJek50s6L+kTkr7lYh0sAAAX3ac+Lv3K90p/9AbpumdJX3OH9MRu4U/rlWpzpbZVVdcTHyiArXz4XdIvvEj60NulZ36H9JyXSWceK0lqVJGIYrN3/Yr0b14sNZ+SbnmF9PRvkMzUfOwRSZK3JKK7OLEQdffbTvh9l/SdezsiAACm8oF7uhvWjz0offn3S1/6vVJ1UHA21i0katuGQhSYO3fp3Guku/+xdMXjpL/7c9LTvvLQS1qvVDvFBNZc+KR09/dL514tPfmvS1/7aumqG5e/3Xj/7z9Lc3dyqs2KAACYpdRKv/Fj0lt+UHrCNdK3vFG67plHXtb6QSF6Ro857aMEsK1PfFS687ukd/1b6al/W/rqV0mPf9KRl7WqtHCW22PFn7y9eyD58LukZ32X9LdfKi0ON6lrh92NnDs7oRAFAJTtYw9Kv/jt0vt/Q/qCr5Ve8OPSY58w+tJG3VPwtrlwmkcIIOK9vyb94u3Sf35E+qp/2i3HrcbbolxQpc9gaS6kLkH/nTukN/1v0mc8UfrGX+oeYoxoXEpuJKI7ohAFAJTr/Juln//W7mbiq18l/fUXSmYbX95693tty40rMEtv/eFu3NJnf570d1/fLas8RuuVjKW5uPBJ6Q3fJL37bulpN0u3vlK68qqNL0+pT0UTnwW7oBAFAJTrrT8kPfYzpW/8Zemzn3riyy/0S3MTiSgwP5/8M+mt/7TrbPo1d0hXXHniH2m8UsVIJrznV7si9Ct+QPpb/9OxDyQlqUlJrSoZiehO9jG+BQCAS1PzKekv/7WtilDpYF9QS6dEYH7aR7sfn/rlWxWhUndNM74Faj7V/fj5/92JRagkJffu84A9ojuhEAUAlCu1h7rinqQZElEKUWB+hnSq2n7B3wWnEIUOlthuee40ratVzR7RHVGIAgDK5W3spnVoVkQhCsxPsJhIydWoViVSreItz53tHky27syg3QMKUQBAuVITSkSHZkWpoRAFZmdIp2z7YiKJPaJQ/NxJw9Jczp1dUIgCAMqVmvAyPomlucAsBRPRNnWpVsU+PwSXdXeFaC2ja+5OKEQBAOVKaesn4NLBHlGW5gIzNKRTG2aGrhtSLRJRHJw7sUSUpbm7oRAFAJQruDR3SESdBhXA/ERTLXe1XpOIIitNb52lubuiEAUAlCu4NLfp94i27BEF5idaiLZdqlWTiGJ57gQTUZbm7oRCFABQLo+Nbxm65pKIAjM0FAWBZkXd0lwS0eJlnTs1S3N3RCEKAChXNBFNfddc9ogC85OzvJJEFFJmsyL2iO6KQhQAUK6U6JoLXC6yGs4wRxRaOXeCXXMpRHdCIQoAKFdqJNv+o/CCk4gCs5W5z29BMYEUe4jRJFcrU8W5sxMKUQBAucLNivquuS03H8DsZM6CJBHF8qGk2XYvXyainDu7oBAFAJTL21Ah+mhiaS4wW8E9okOqVVOIIsU+C5rlHlE+C3ZBIQoAKFNKkqdQ19yGOaLAfAU7nyZ3NaopRNEnott/FgznDjNod0MhCgAoU7CxiSQ92nfN9XThYhwRgF0E94g2rSt5pcpcieX2ZYsmov25Q7Oi3VCIAgDKFExPJOmChj2iPAUHZif4cGlItSSpZbl92byVqu3Lou7cYQbtrihEAQBlCjY2kaQLJKLAfAWv6Sa5Un8r3DZc00ULz5Tuzp2KPaI7oRAFAJQpoxB9lDmiwHwFmxW1qUu1JKmhEC1bsBDtzp2a8S07ohAFAJRpaDIR2CN6kIhy8wHMznK5/Xa3t+1qIsoe0bKlNrRNYzh3jKW5O6EQBQCUKdjYRDoY3+IkosD8ZMwRHfaIJhLRsgWbFQ1pek0iuhMKUQBAmYLL+CQSUWDWPL40t10mojxcKpq3oYeSw7lDIrobClEAQJmG9CSwHOvTfSIq5ogC8xMd35LSshBl33fhUhObKZ1crWoS0R1RiAIAyhRcxpdW0hMSUWCGgqsckjuFKDrBZkXDucP4lt1QiAIAyhRsVtSsFKIkosAMBZsVNa2r9X6OaMM1XbRgs6Lu3KnomrsjClEAQJmCy/i6Aebda0lEgRmKrnLwg/EtiYdLZUuxPaLD5wGJ6G4oRAEAZQretDYrox5IRIEZ2uGapmtu4YJLc5uUlFSpFg8ld0EhCgAo03IZ33ZPwYd2/Yf+LID5WHbNjVzT/fgWrumyhbvmSg17RHdGIQoAKFPGzMG0bFZEIgrMTrBZUUsiikEwEW1JRPeCQhQAUKZls6Ltb1qH9IREFJihYLOi1VUOJKKFSylYiEqNatVOIroLClEAQJmWiej2N60tS3OB+UpNt9TebKuXr17TJKKFS83WDzCkLhFtSUR3RiEKAChTdGmuuyRT63awFw3AfESXV7qrpRM2pIxzR8wR3QMKUQBAmaLNilrvflRF11xgjsINZ1YS0ZZrumjhc6dLRBcUojuhEAUAlCkrEZVa1TLSE2B+Uhvc5+dqfeiaSyFatHCzou7cqcyVWj4PclGIAgDKFO6w2T35blWxNBeYo9RkJKLdflInES1byk/TW86dbBSiAIAyLWcObtusqP9RFc2KgDlK7dZL7aWhmOj3iJJqlW2Hc4dCNB+FKACgTMGluc1KImokosD8BJdXNqt7RFmaW7asc6dL01s6LmejEAUAlClYiKZlIlqzNBeYo+Ae0XQoEaUQLVqwEE2+mojyeZCLQhQAUKZg19xDiSjpCTA/3m691F46nIg613TZPIX2iDYtM2j3gUIUAFCmZbOi7W4+Ut81t6FrLjBPGalWMxSiJKJlCza66s6d7vUNhWg2ClEAQJk8Vog2/RzR5MYeUWCOgg1nmuRKy0SUa7ponDuToBAFAJQpc45oo5pCFJijaCKaDlItEtHCZZ07/fgWEtFsFKIAgDJFC9HUJ6J0zQXmKdis6FCqxTVdth3OnUSzomwUogCAMgWbFQ2FKIkoMFPBZkVtcjXev55EtGzehvaIdufO0DWXRDQXhSgAoEzBZkWriag8XayjApAruLyyPdQ1l4dLRQs2K2pJRPeCQhQAUKbMpbmtKlVOegLMTrQQdT94PeNbypZx7qR+NU0iEc22VSFqZjeb2f1mdt7MXjLy+9eZ2VvM7PfM7A/N7Pn7P1QAAPYo2DV3mYhaLSMRBeYn2Pm0bV113RUfJKKFi547yVVVQyHKuZPrxELUzGpJr5T0PEk3SbrNzG5ae9n/KukN7v50SS+U9C/3faAAAOxVMBFtVgpRElFghlJsn1+TXFVNIlq8lCR5rFlR61J/7pCI5tsmEX2GpPPu/oC7PyrpdZJuXXuNS/rM/udPkPSf9neIAABcBKlPNbd8Cp768S1OIgrMU7DhTHJXtTjT/4JUq1jL1THb71hM7jLS9J1tU/pfI+kDK79+UNIz117zMklvMrPvknSlpOfs5egAALhYlonodjeuTTsUopUquuYC8xPc59ck16JeSI0oREsWXB0j9Wl6tZBaKTFHNNu+mhXdJukn3f1aSc+X9DNmduR7m9ntZnbOzM49/PDDe/qrAQDIkJouDTXb6uXtMhFdkIgCcxQsRFNyLRZ9qsXDpXJlFKJpZVl34iFGtm0K0YckPWXl19f2X1v1IklvkCR3/y1Jj5V01fo3cvc73P2su5+9+uqr844YAIB9yJgbJ/WJqLjxAGYnpVDDmSalZbMi9ogWLDhTWuoS0Zo9ojvbphC9R9KNZnaDmV2hrhnRnWuv+f8kfYUkmdl/pa4QJfIEAMxXxsxBqUtEWZoLzFB4FqRU15Uar1iaW7LlTOlYImpDmt6yQibXiYWouzeSXizpbknvVNcd9x1m9nIzu6V/2fdK+vtm9geSXivpm937NUwAAMxRarMKUVU1hSgwR+GHS0l1ZUqiEC1asF+A1Cei1VCIkojm2upqdfe7JN219rWXrvz8Pklfst9DAwDgIkqtdLSdwUYHiWitSjwBB2YnutzepboyNaplPFwqV3CmtNT1DKiW+4tZ1p1rX82KAAC4tGQuzVVVs0cUmKOdElGKiWJlNCtqV/eINpw7uShEAQBliu4nG3acVAtVdM0F5ie1oYYzbXLVlam1ikS0ZEMhuuW54+5qV7rminMnG4UoAKBMnrlHlK65wDyleCfs2kxJNYloyVL/YHHLz4Pho6BeDF1zOXdyUYgCAMqUcdMqSapJRIFZylhuv6hNrSqJa7pcwWZFw2dBvTgjSXIaXWWjEAUAlCm4jK/pbz7MatUkosD8ZMwGrqzbI2okouUKNisaCtEzy/EtnDu5KEQBAGUKpiep30/m1YJCFJij6Egmdy0qU0vX3LIFmxUN/QLqekhEKURzUYgCAMoULESbfj9Zt0eUZXzA7AQbkDWtq6pMiWZFZYsWou2wNLd/PUtzs1GIAgDK5Cl005p8JRHlphWYn+By+9QnoolEtGxDs6Itz50hEV2c6RNRluZmoxAFAJQpIz2pK5OsVk0iCsxPxiqHLhGlEC1asFlR0xeui35pLuNb8lGIAgDKlJpwetIlohSiwOy4h5sVpbSSiLK8slzBQnQIUElEd0chCgAoU7CxSZPSMhFljygwMx6bBSkd7PtOVsm4psu17Jq73bmzTETPLA7/eYRRiAIAyhSeOSjVlcmqhc4YNx7ArARTLemgE3aymvEtJQs2KxoS0TP9HFGRiGajEAUAlCnYrKhNSbV1S3MlKbUUo8BsDEtrg7OB66qfI0oiWq5gs6IhER0KUScRzUYhCgAoU7BZ0ZCIDn+maS5crCMDEBVMtaSDfd/JalUUE+WK7hHtu+ae6feIMr4lH4UoAKBM4aW5SYvaZNb9mcRyLGA+MgrRpm9W5HTNLVvw3GkShei+UIgCAMoUnDnYulSbSTWJKDA7y2ZFkVUOB+NbSEQLtmxWtOUc0b4QretKrdtBIYswClEAQJmCXXPbla65ktSyRxSYj4xmRe2QiKpS5ewRLVaKdc0dCtFFZWpV0TV3BxSiAIAypUaqtv8YbFrv94j2S3NJRIH5GArRYLOiZSIqioliLc+d7T4PhqW5VWVqmUG7EwpRAECZPJaIDo1NrO7+TMseUWA+gqmW1I1vWVQmrxYyEtFyBc+ddCgRrUlEd0AhCgAoU7BZ0TDqYUhcaFYEzEhms6LauqW5NcVEuTKbFdVmSlYxg3YHFKIAgDKlJtasqC9Eq5quucDspFjDmSHVqqtKXtUyluaWKzq+ZXnuDIkoaXouClEAQJlSCjYr6tKT4WalbShEgdkIdj5dplqV5FaTiJZs2XE5mIgOzYpIRLNRiAIAypSacIfNujLZ0KyImw9gPoLLK5OvJKJWy0SqVaxgItr6QSGaVDGDdgcUogCAMnmbVYgOc0TpmgvMyLA0d8vl9iSiWAqeO227WojSNXcXFKIAgDIFmxW1fdfcapmIcvMBzEbmLMghEa1IRMsVTNNXE9HWSER3QSEKAChTarOaFTFHFJihZTGx3a3tshA1SVWtmmZF5YouzU1riSiFaDYKUQBAmVJ8ae5itWsuiSgwH56ZiNYkosULNitqV+aIJqMQ3QWFKACgTNGluclVmckq9ogCsxNdXrkyC1JGIlq04dyxWJpeGc2KdkUhCgAoU0bX3EV9kIg6c0SB+VgWE7HOp4vK5NVCNbMgyzXMlDbb6uUHiWhFIrojClEAQHnc+665OySiLM0F5iMFl1f2nU+ryiSrWJpbshT/LJC67cgkoruhEAUAlCe4J0jqEpRFZbL6jCQptSzNBWYjcxZkl4ie0YKlueXK6KAukYjuA4UoAKA8y7lx238MNq2rqkxVP0fUSUSB+Vg2K9q282n3MKqqTKpIRIvmKbRNo1lJRN1qVRSi2ShEAQDlCTY2kaS0TET7rrnsEQXmI9ysqPtx0Y9kWliSJ4rRIgX7BST2iO4NhSgAoDzBZXxS9xS8rkxVf6NLIgrMSLBZUTMkon3XXElKFKJlGpoVbalZ6bjsqlTR6CobhSgAoDzBmYNS9xS8ruiaC8xSsFlRWklErf8zTfPoxTgyzF2wWVFazqDt5oiyNDcfhSgAoDwpXog2yVXbSiGaKESB2QiuchgS0boy+dAJu6WgKFKwED2UiFotY39xNgpRAEB5ggPMpSERrVSTiALzEyxEU9/5tK4ORjI1DZ2wi5SarvPQti9fOXdIRHdDIQoAKE9mIrqo6ZoLzFJwuX3THoxvEYlo2YIzpQ+dO1ZRiO6AQhQAUJ6MrrmtuyozVYtujiiJKDAj0a65PozgONgj2rJHtEyZc0SrypRsoYoZtNkoRAEA5cnomtumbnzLco8oT8GB+VjOBt52juhIIsoqhzIFu+a2KXXnjSQ3ZtDugkIUAFAej3XYdHe1yVWtFKIiEQXmY7ncPlaIHk5E2SNapJRiiWjqzhtJ8mrB0twdUIgCAMoTbmzS/bioTPWwNJf0BJiP6NLc1US0f7iUeLhUptQEV8esJqI1iegOKEQBAOXJXMZXV6ZquGFhfAswH56ZiJrJbGhWxDVdJG+DhWg3ukXqCtGaRDQbhSgAoDyZ6UldmerFFZJIRIFZyU1Ea5ORiJYt2qwoJdV1V4iqIhHdBYUoAKA8wf1kTepuNGo7GN9CIgrMSHCVQzM8XLKDOaKp4ZouUmpDzYqa5IcTUbrmZqMQBQCUJ7iMr69DVVemRb9HVCSiwHykVpJJ1Xa3tskPVjksE1EeLpUpxZbmJnfV/R5RsUd0JxSiAIDyBJfxLRPRajURpRAFZiO4vLJpVwrRZddcCtEiZZw79bJrLntEd0EhCgAoz1CIbtusaCU9WQx7RLn5AOYj2vl0JBFl33ehMs6d1US0JhHNRiEKACjPco9ovFlRNSz9YxkfMB8enQW5moh2RUjbMke0SN6Gz51DiSiFaDYKUQBAeXYoRK2q1HhFIQrMSXgW5MrDpSERpWtumVJ+IapqQbOiHVCIAgDKs2xWtN3HYLvSYVOSkqqDDkYAphfsfNqOdc1tKSiKlFrJti+J2pWuuWa1FpbkfB5k2eq/upndbGb3m9l5M3vJhtf8HTO7z8zeYWY/u9/DBABgj3aYOShJjWpZYhkfMBvhWZD9NV1VququE7azNLdMGefOwdLcoeMyhWiOE/+rm1kt6ZWSnivpQUn3mNmd7n7fymtulPR9kr7E3f/UzP7yxTpgAAB2Fm1W1N+0VquJqHPjAcxG5tLcqpKq/s/RrKhQGefOwdLcLtNr20b1YvtiFp1tEtFnSDrv7g+4+6OSXifp1rXX/H1Jr3T3P5Ukd//wfg8TAIA9iu4R9SE96W4+Wqtk7BEF5iParMgPEtHlHFH2iJYp2qzIfflZoKpL09uGND3HNoXoNZI+sPLrB/uvrXqapKeZ2X80s7eZ2c1j38jMbjezc2Z27uGHH847YgAAdhUsRIeZg1U1JKL1wT5TANPbJRFlfEvZUhs+d4bPAltJRBG3r2ZFC0k3Snq2pNsk/Ssze+L6i9z9Dnc/6+5nr7766j391QAABC33iG73MZjWE1FVMgpRYD5Sk9WsqNsjSiJatIxzZ7HSNVeS2oZzJ8c2n8APSXrKyq+v7b+26kFJd7r7BXd/r6Q/VleYAgAwPx5MRNN6IlodpKoAphccwbG8pk2q6r4IYbl9mTLOnaFfwFDA8hAjzzaF6D2SbjSzG8zsCkkvlHTn2mt+WV0aKjO7St1S3Qf2eJwAAOxPsGtuSuuJaE0iCsxJsPNp6hvOmNmya26iEC1TxrkzdFAf9he3dFzOcmIh6u6NpBdLulvSOyW9wd3fYWYvN7Nb+pfdLekjZnafpLdI+p/d/SMX66ABANhJsGtusz5H1FiaC8xKardeai911/RwPS8TUeaIlim4R3Q8EeXcybFV+e/ud0m6a+1rL135uUv6nv5/AADM2zDzLZiI1ivNiihEgRkJdj5NfjCCo6qv6L4FiWiZPFaIppWuucP+4rZ59KIc2uVuX82KAAC4dASbFTXrhahRiAKzEmw407SrhWj/7wD7vsu0w7kzFLCpZa50DgpRAEB5gs2KhpmDhxJRblqB+Qg2nFlNROvFFf23IBEt0g7njlVDx2US0RwUogCA8gSbFbXtwagHqd8jKp6AA7MR7nyaVpZX9mkYqxzK4x5e1t0kX34WWM0e0V1QiAIAyhNsVjQkosNK3mS1jP1kwHykJtSsqE0H45jqvmuuk4iWZ1jZEtkjmnx57hwkonTNzUEhCgAoT7BZUZvWElHVJKLAnARTrXY1EV2cOfgeKIvHC9EuER3Gt/Sjf0hEs1CIAgDKkxpJtnWC0i6bFfV/3CpV3LQC8xGcBdkmLUdw1MPSXFY5lCe4TUPqPg+Gc8eWzYo4d3JQiAIAypOa0BPwg0J02CNK11xgVoKdT9uUtKi7YmLRJ6KeWOVQnOA2Dan7PDhIRIeluRSiOShEAQDlCS/j6wvR/im4W00iCsxJSrGHS35wPQ+zIJXY51ecFOugLnU9A4Y9olV/zrG/OA+FKACgPKkNPwGXpLo+mCNaOekJMBvhVQ5pOYJjSERFIlqejGZFo4ko47yyUIgCAMoTHvWwloiqUiVuPIDZiI7gaA9mQQ7jW+iEXaCcZkVtGpkjSpqeg0IUAFCeaHriwx7RvhCtFizNBeYk2Kwo+UEhKkkXvJZTiJYno1lR8oPPgrpPRFmam4dCFABQnmgh2nZL9paFqCqW5gJzElxu36TDhWhSxfiWEmU0K2pWlnWrT9NZmpuHQhQAUJ5os6IuEF1JRGuW5gJzktrwPr/VQrRVJaOYKE9Gs6KUVhPRvuMyiWgWClEAQHmCe0TbtJaI0jUXmJfwHFFf7vmWukKURLRAGc2KmpSW584wR9R5iJGFQhQAUJ7USLb9R2C/MnfZKdGNRBSYlYzZwIcSUatpVlSi5R7R7c4ddz+8R3Qx7BGlWVEOClEAQHkyE9Hq0BxR9ogCs5ExG/joHlGu6eJ4bGnucpTXco5oX4iSiGahEAUAlCecnnQ/riaiNYkoMB/R2cC+vkeURLRIwWZF6x3UqwVdc3dBIQoAKE84PekT0eHGtapVifQEmI0dmxWRiBaq/7c9OxGtSUR3QSEKAChP9KbVfZmGSkMiyk0rMBsZzYoW63tEnVSrOME9okMhulgrREWanoVCFABQntSEZw5WKzetolkRMC8ZzYoqO5yIGoloeTIL0eHcIRHdDYUoAKA8wWZFaS098WqhmptWYB5SkuTxRLReKUTpmlumzGZFw7lTL/o5opw7WShEAQDlCS7ja9ZmDsoq9ogCc+HxWZAkopC0kojGCtFlIjqccySiWShEAQDlCe4RTclV16uJ6BktWJoLzEOw86l0dN93EntEizQUkMGuuYvlHNErJJGI5qIQBQCUx2OF6JFEtCIRBWYjxZZXSlLTHt73nawmES1RiqXpTdsnostmRSSiu6AQBQCUJ9isKK3NHFS10MKSPHHjCkwu2HBG6q7pxVohWjnFRHGC505aS0QXyz2inDs5KEQBAOWJ7hFtD9+0Wl/EJgpRYHo5iWhy1dXBbbCrklGIlie4R7RZmyNa911zjUI0C4UoAKA8wa65ra+Nb+n/bNM8uu8jAxCV0awoJVe9chdMIlqoYNfctF6I0jV3JxSiAIDyBJsVtWvjW4Y/m1puXIHJZTQrapJrsZKIJqtl7PsuT7BZ0ZCIDp8H1XAO8RAjC4UoAKA8wWZFbVpPRLs/2zQX9n1kAKIyluamtfEtbhWJaImCzYrWx7dYVanx6uBhCEIoRAEA5QnuET2aiHZ/lkQUmIHgPj+pT0Tr1WZFC/aIlihzjujqudOqlugXkIVCFABQnmDX3HYtPbH+6XnLHlFgesFUS50sKGsAACAASURBVOr3fZOIItg1d5gjunrutKpkidUxOShEAQDlSSmeiNYjiSidEoHpZTQrWl/lkGzBbOASBZsVLRPRlf3FrSqJGbRZKEQBAOVJjVRt/xHYuqseTUR5Cg5MLtisyN2P7vsmES1TsFnRco/ooY7LlYw9olkoRAEA5cnYI1qv3rT2s+PahpsPYHLBfX59LXEoEXWrVYlCtDjRpbmjiWhN19xMFKIAgPJ4bI5o0x4uRK1/es7sOGAGgl1zm76xTL1eiLK8sjzhc2eYI7ryLVTR6CoThSgAoDzRZkW+VoguE1GW5gKTCzYrGhqcrheiNYloeYKJaFoWomuJKP0CslCIAgDKk9Gs6FAh2t+0OONbgOkFmxUtE1EjES1esFnRMhFdOXdIRPNRiAIAypOacIfN1Sfgy0S0ZWkuMLnoHtGxRLRij2iRMpsVrZ47rdUUopkoRAEA5ckpRA812OzHt1CIAtMLds3duEeU8S3lSY0k27qL+lgh6iSi2ShEAQDlCTYr2pSIUogCMxBsONP60WJC1YI9oiVKwc+CkXOntVrGHtEsFKIAgLKk1A0fjzQrSn6oS+KwRzTRNReYXrBZ0ViqJatUk4iWJ7w6ZiRNF0tzc1GIAgDKEmxOIXVPwVfnxlV9IuokosD0MmdBHt4julBNMVGeaCLaP6tYsEd0LyhEAQBlCaYnUnfjWo10zU10zQWmF3y41I50PhV7RMvkbVYiWh3aX8we0VwUogCAsgTTE6m7cV19Al7VZyRJ3jJHFJhcsFnRUIgu6sNdc9kjWqDoTOmRRDSpVkUhmoVCFABQluCoB6lPRFfSk2qYI0qDCmB60WZFfSFarSWi7BEtUGqCnwV9Iro6R9QqGedOFgpRAEBZhqH1wUJ09Qk4XXOBGYk2K+o7ny7Wu+aayxMFRVHCe0SPnjvJSERzUYgCAMqyXMa3/Udgs7ZHdNmsiEQUmF5wuX3T9onooUK0+7MtD5fKkmJ7RJt09NxxmhVloxAFAJQluIxPkpKv7xElEQVmI9isKI0mol0x0jTs+y5KsFnR2LlDIpqPQhQAUJaMZkVNmw6Neqjq+vD3AjCdYLOisVTLbOiEzTVdlGCzomZs9I8qOi5nohAFAJQlo1lRcq0Vol3X3EQhCkwvuMohjezzU7/KoWm4posSbFaUNsygJRHNs1UhamY3m9n9ZnbezF5yzOu+1szczM7u7xABANijjGZFTUqjS3PFHFFgesFmRWOp1jAb2ElEyxJsVtSMzKB1q1Q5iWiOEwtR69YqvFLS8yTdJOk2M7tp5HWPl/Tdkn573wcJAMDeZDQrSklrzYr6OaIkosD0gsvt00gxMRQj7BEtTGqlKvJZ4DI72qyoYgZtlm3+yz9D0nl3f8DdH5X0Okm3jrzuf5f0w5I+tcfjAwBgvzKW5q4novWi/7N0zQWmF7ymh1RrUR8tRJ1VDmUJLs1t1kZ5SZIbS3NzbVOIXiPpAyu/frD/2pKZfZGkp7j7rxz3jczsdjM7Z2bnHn744fDBAgCws+B+MndX8sMDzOmaC8xIsGvuMEd09ZoeluY2LYloUTw4R9T90Hkj9UtzSUSz7NysyMwqST8m6XtPeq273+HuZ9397NVXX73rXw0AQFxwGd/YAPPlHlGW5gLTGx4ubdn9tG2Ha3rlNrgvRhLNisoS7JrbtuOJaM0e0SzbFKIPSXrKyq+v7b82eLykL5D0VjN7n6QvlnQnDYsAALMUbFa0TE9Wl+b2haizNBeYXrBZ0cE1ffC1IRFllUNhUoonokcKURLRXNsUovdIutHMbjCzKyS9UNKdw2+6+8fc/Sp3v97dr5f0Nkm3uPu5i3LEAADsYh+J6OLM4e8FYDpDqrW2ZHKTg2v64DbY+odLLYVoWVITmindju0RrRbMEc10YiHq7o2kF0u6W9I7Jb3B3d9hZi83s1su9gECALBXy665sUK0PpSI9n+WBhXA9DKKCUmqRxJROmEXJuPcqdcKUVmlmkI0y1ZZtLvfJemuta+9dMNrn737YQEAcJEEmxWNFaKLPhFl5iAwA9GGM8tr+qASHfZ9t+wRLUvGuXOkEK0Wqlmam2XnZkUAAFxSgktzm5FCdNmsiEQUmF5qQw1nmrE5okYiWqRgs6Im+eHzRv0cUZoVZaEQBQCUJZiIpmMSUeaIAjMQXF65vKbr1X3fjGQqUmrD587qeSOJRHQHFKIAgLJ4rMPmWHpS9XtEjUIUmF6KLa8cu6bNKESLlHHujCWi7BHNQyEKACjLHpoVSdIFr1nGB8xBtOGMH72mre5WOVCIFibj3Dm6R7QmEc1EIQoAKMtyj2h+syJJSqrYIwrMQTDVatsuvTpciHa3xN5yTRclNcFzZ0Mhai5PpKJRFKIAgLJEu+aOpCeS1KpiaS4wBx7b59d2l/RaAzIS0SJ5ihWi7oe6LUta/nlm0MZRiAIAypJie0Q3JaItiSgwD8HOp206mohWzBEtU2ok274c6sa3HP6a9ecehWgchSgAoCzBZkVDIbpYL0StlnHTCkwvujS3X0G5ek1Xw2zgdGGvh4aZC587Y4loX4g2nDtRFKIAgLJkNiuqbGyPKHuCgMlFG870iejqNW1DItpyTRclfO641qe3LAtR9heHUYgCAMqS2axoUa8vzSURBWZhH4loTSJapIxEdLFhj2giEQ2jEAUAlCXYrKghEQXmLdqsaEhEq6OzgROJaFk8Xoiu16FWsUc0F4UoAKAswWZFyYc9ooc/MlurZc6NBzC5aLMi9yN7vklECxVtVuTHJaJ8HkRRiAIAyrJcmrvdjWvTz3pYv/dIqmQkosD0grMgm+SH0lDpIBEVI5nKsodzZ5mIslUjjEIUAFAWjy3N3ZSIJrrmAvMQ3OeX0tFEtGaOaJn2cO6o7ueIkoiGUYgCAMoS7JrbbJgjSiIKzESK7RFtkh+5nmsS0fKkJMl3PneYQZuPQhQAUJa+UcnWiejGQpQ9osAsBJsVpbFiYjlHlGu6GMGZ0lJ/7qw1rhs+S5gjGkchCgAoS3SP6DC+Zb0QtVqVk54Akws2K2pGlldW/fJKUYiWI7g6RpKalFSvjfKy/txhWXcchSgAoCxDl8T1p9obtJvGt1jN0lxgDoINZ5L7keu57osJZ2luOYIzpSUpuY4kokOzotRy7kRRiAIAypIxN06SFjVLc4FZSinW+bQdSUT7pbkkogUJzpSWukR0/dyxYXxLy9LcKApRAEBZMmYOSkcTUbdKFYkoML3UHJ2vdIzWj47goFlRgYIzpaX+mcd6Ibpcmsu5E0UhCgAoS7Bdf9s3NxrbI2rsEQWmF1ya246Nb6FZUXmC/QKk8US0IhHNRiEKAChLcNRD24ee61023SpVIhEFJpex3P5oIjo0K+LhUjGCM6Wl7vPgaCI6jG/h3ImiEAUAlCU1wUK0KzaPjG+xhSr2iALTiy63H0tEKUTLk9E1tx3bIzoszW34PIiiEAUAlCW8jK/7cSwRpWsuMAPh5fZHu+ZWda3kdpCS4fKX0TV39Nypho7LFKJRFKIAgLJ4G34CLm1IRMVNKzC51MaaFSU/0gVbkhpVdM0tSf9ve2yFzOYZtMwRjaMQBQCUJZieNP34lvXZcaJrLjAPwVUOTfKj17OkpErG0txyZDUr8iMPJYc5ouwRjaMQBQCUJdysqC9E6/WluTWJKDAHwWZFyY8WE5LUqmZpbkkymhWNnTvDDFonEQ2jEAUAlCXcrGg8EXWrSUSBOUix5fZNu6EQtYpmRSXJaFY0lohW/edJ4twJoxAFAJQl2qzI+0L0SLOiWjWJKDC96MOlYxJRZgMXJNisKCWX+9HPAhLRfBSiAICyeIoVou3mQpREFJiBjK65Y4VoUsXS3JIsmxVtd+4sH0oe6Zrb7xFlnFcYhSgAoCypkSzQYXPDzYdX7BEFZiFjuX090mW3VS2ja245lonodp8Hm/oFDImoSETDKEQBAGUJzxF1mUnVWCIqElFgUu7hZkVtco1Mb+m65rLKoRzBpbmb+gUczBHlwWQUhSgAoCwZXXPX58ZJkqoFe0SBqQ2FY2g28HgimoxEtCjDMuwtz51N/QLqRV+IkoiGUYgCAMqSkYhWIzMHZZVqElFgWhmzILtCdORbqToobHH5iyaiG/oFVDWJaC4KUQBAWaLNijYkol4tVNPYBJhWis+CbN21GNsjarUqGs6UI7NZ0frnwVCIijQ9jEIUAFCWYLOiJvmR/aGSJPaIAtPLTETHrmknES1LZrOi9XOnJhHNRiEKAChLcGlu8k2JKHNEgckFl1dKm1c5tMYc0aJkNis6kogOXXNJRMMoRAEAZQnOHGw2zByU1ewRBabmseWV0uZ9365KFYVoOTy2rHuZiNp6Ilof/n7YGoUoAKAswa65aVMhWi1Umyu13HwAkxlSqMhs4A2JaCIRLUsKds0dEtG12T+LPhGla24chSgAoCypCRWiTRpvbDJ8j5abD2A6GUtzm+SqRwaJJlvQrKgkwf3FzTBHdO3zoGZpbjYKUQBAWbwNzRxMycd7WVCIAtNbds0NXNPuqkeW5iZVMpoVlSN47qRhjuiRpbn9QxDOnTAKUQBAWYLNijYlotZ/j7a5sLdDAxCUk4i2aXS5vVvNHtGSBM+dZuMc0VrJjUQ0A4UoAKAswUK0ddfYFtGDRJQbV2AyGXNEkx8tJiQpGYloUYKF6DIRHeu4rOrgXMTWKEQBAGVJKTZzsN20R7S7eUkkosB0hgQzNBs4jY9ksoUqRjKVY3josOVWjWbD+BapK0SNRDSMQhQAUJZgs6LW/cgAc0ky9ogC08tYmpuSRq9pN8a3FCXYrGg5vmUsTVfFHtEMFKIAgLJ4bI7oplEPy0SUQhSYTsbS3E2JaGKPaFmC5057TCLaWM0e0QwUogCAsqQm1DW3TSSiwGwFO5+6u5JL1UjXXLdalUi1ipGbiG7suMxDjCgKUQBAWdKeE9GGQhSYTGYxMb5HtGaPaEmCy7qX587IDNpW9cF+ZWyNQhQAUJbUxvaIpvGZg0MiytJcYELLZkVbFqK+eZ9fN76FRLQYwWZFy3NnUyJK19wwClEAQFmizYqSj7brt36IOUtzgQnlplpjhWhFIlqUcJreFa7jXXNrluZm2KoQNbObzex+MztvZi8Z+f3vMbP7zOwPzezNZva5+z9UAAD2IGOO6Ggh2t+8OA0qgOlkFqJj17RIRMsy9AsYSTjHtP2psWkGLUtz404sRM2slvRKSc+TdJOk28zsprWX/Z6ks+7+hZJ+XtKP7PtAAQDYmXt3sxBoVtRsSESrIRFljygwnT6liu4RHbum3WrVJKLlCG/T6M610UJUNUtzM2yTiD5D0nl3f8DdH5X0Okm3rr7A3d/i7p/of/k2Sdfu9zABANiDIe0INStKG9OT7ltSiAKTCS6vbI4rRCu65hYluDrmuHMnGV1zc2xTiF4j6QMrv36w/9omL5L0xl0OCgCAiyI46kHqlmONJqIL5ogCk/PYLMh0wtJcEtGCeAp3UJeOSUQpRMO2/6+/BTP7BklnJf23G37/dkm3S9J11123z78aAICTBdMTqU9Ex7rmGoUoMLnhmt5yuf0y1WKOKFIj2fZ9W9tjzh3miObZ5r/+Q5KesvLra/uvHWJmz5H0/ZJucfdPj30jd7/D3c+6+9mrr74653gBAMgXbGwi9V1zR+bGWX2m+5YUosB09tmsqFpoQTFRjmjjumOX5taqOHfCtilE75F0o5ndYGZXSHqhpDtXX2BmT5f0f6krQj+8/8MEAGAPgjMHpWPmiNZV/y25+QAms8dmRbKKRLQkGTOlpc2FqNFxOezEQtTdG0kvlnS3pHdKeoO7v8PMXm5mt/Qv+2eSHifp58zs983szg3fDgCA6aTYfjKpG98yNjeuIhEFphedBenHNStaqKYQLUdqw58F0vgc0W6PKJ8FUVv913f3uyTdtfa1l678/Dl7Pi4AAPYvZ49o66rGClHmiALT2+vS3JpCtCSpyUpExz4P3Cpm0GbYfocuAACXupyuuZsS0UWXiHq6sJdDA5AhuNx+KCbGrmlVC1XmSiy3L0NwpvRx5063NJfzJopCFABQjsxmRWNPwK0vZlNDIgpMJjMRrUb2fQ8dVJuGh0tFyGxWtDkRpRCNohAFAJQjsxA9bo+ouPkAphPc971MtUY6YQ/fg33fhcgsRMcT0YUqZtCGUYgCAMox7OEJLMdqko/uJ6vrPhHlphWYzrIQ3e6WdjlHdOT1wyoHEtFCpBTaptEcs7+YRDQPhSgAoBwZzYrSxvEtwx5Rbj6AyQRXOaSha+7Y0tz+e7TsES1DsFlRSpvPnWQLGY2uwihEAQDlyGhW1CRXPbKMr667m1YnEQWmE2xW1LTHdc3tl+aSiJYh2Kzo+ES0Vk0iGkYhCgAoR8Ye0eTjiWg1FKIkosB0chPRYxqQtTxcKkNwj2hyV2WSbWh0RSIaRyEKAChHsLGJ1D0FHx/f0n8P5ogC0wle08elWjQrKkxqMz4LxkunZAsS0QwUogCAcgSX8aXkch9v11+TiALTCzYrSscUosuRTBSiZUhteI/oxtPMKlUkomEUogCAcgSbFbW+uV3/sDSXRBSYUHB5ZXPMCA7rr+mW2cBlCDYrOi4R9WpB19wMFKIAgHIE95MdN8CcRBSYgcxZkNVYJ+whEeXhUhkyzp2xFd1SP76FRDSMQhQAUI5g19zjBphXizP99+SmFZiMp1Dn0+U1PdIJWzVdc4sS7JrbJtei3pyI1uKhZBSFKACgHMHGJsPS3LH0pK7rw98TwOmLplrHXNNmfSHKNV2GYLOi1n30vJEkWU0imoFCFABQjmCzorbdnIjWfSLqJKLAdFK7daMiSWpTVywct0eURLQQ0XOnHe+gLvVzRElEwyhEAQDlyGxWNNZhs142K+LmA5hMeJ9f9+PYNV0t94hyTRchI00fHfsjSVWt2klEoyhEAQDlyGxWVI88NacQBWYgXIh2xcLo+BYS0bJkNCvaWIiSiGahEAUAlCOzWdFYf4qqrpXcDpb7Ajh94WZF3Y/HzRGlE3YhMpoVbSpEvWKPaA4KUQBAOaLNio5JRCWpUUXXXGBKwVmQxyWiw2zg1HJNFyHarOi4RLRaaEEhGkYhCgAoR3CPaHNMIipJSZWM9ASYTnB55fKaHp0jOnTNpRAtQvAhRpPS6Hkjqeuaa67U8nkQQSEKAChHtGvuCYloq5qlucCUUhtMRPtremSOaLXoClEnES1D+NwZT9IlLb9Py7kTQiEKAChHbrOiDU/BW6toVgRMKaPhjLQpEe33iJJqlSGj0RWF6H5RiAIAypG9R3RDIapaRiIKTMdTLNU6ZiRTVXezgVmaWwhPwfEtmz8LhmXdLR2XQyhEAQDlyO6aO37zkWhWBEwrNbHOp+1xheiQiHJNFyE1km1fCm2TiDYN504EhSgAoBzBZkVDerIgEQXmKbq80jcvzR0SUefhUhn2OUe0Yn9xDgpRAEA5ws2Kunb81TGJKF1zgQllNCsyG7+mSUQLk3HubOoXYMtElKW5ERSiAIByhJsVdT9uSkSTkYgCk8qYBbnpeh7miDoPly5/7t2Dyei5M9JtWdJBIsq5E0IhCgAoR7AQbYZEdMNT8KSKQhSYUnAWZJt84/VcsbyyHMHGddLx586QiNKsKIZCFABQjr6w3PbGdXj5pqfgLYkoMC1vY82KjktEF/0eUa7py99ym0agWZFvPneGgjYx+ieEQhQAUI4hEd3y5mNIRDd3zaUQBSYVbDjTHNNwpl7034dE9PIXXB0jSU27+dwZlnW3LYloBIUoAKAcw03rhuVVR15+TIdNSUpWdbPoAEwjWIgmP6YQZZ9fOTIK0ePOnWGVDYloDIUoAKAcwWV8zTEzB6UuEa2c9ASYTEqhPaJdIjp++1sNiSjjWy5/wZnS0vFpulVn+m9LIhpBIQoAKEeww+YyEd1w8+FWyUhEgekEmxWl5Ko33P3WdM0tR0azonRMIVr1JxWJaAyFKACgHMG5cU3qCtHN41sWJKLAlKKrHJJrsTER7VItEtECZDQrIhHdPwpRAEA5MkY9SFK1cWkuiSgwqege0eTaUIeqrvt/G0hEL385e0STb+wXYH0iSpoeQyEKAChH8Ka1PSERdatV0TUXmE5wuf1xiWi9TES5pi97OV1zk28c5bVMRJkjGkIhCgAoR8bMQUkbh5gn9ogC00qtNkacI1p3bWp8utwjysOly19Gs6LkvvGzwIY5ojzECKEQBQCUI5ieLBPRDU/B3RaqxI0HMJnoKof2mES0pmtuMTKaFXVp+vFzRNkjGkMhCgAoR3SP6AlzRN0qluYCU4oWou4b93xbVal1Y2luCZZLc2MrZDaeO/3+Ym9ZIRNBIQoAKEewa+6QiG6cI8oeUWBaGcvtN6VaktSqphAtwbJr7n7OnSERdRLREApRAEA5MpsVbZ4jWqsST8CByWQst9+UaklSq0rGw6XLX0azouPOnWUhyjivEApRAEA5MpsVHV+IctMKTCbarGirRJRi4rKX+geIwRUyJ+4RbTh3IihEAQDlyGxWdGwhStdcYDoZqxw27fmWhk7YPFy67OXsEfVj5ogO5yDnTgiFKACgHMFmRc1JhWhFIgpMKqcQJRFFcGluSi53qd44g3bomsu5E0EhCgAoR26zok0JCokoMJ2UJHlouX2T0gmFaCVxTV/+gs2KDh5Kjv/+kIg6ja5CKEQBAOW4CM2KahJRYBoenwXZ+ubrWZKSKhmJ6OUvmogOo7xOmEHrJKIhFKIAgHLkdNg0yTbNEa0oRIHJZM2CPD4RTarZI1qCFHuIcVIiuuyay0OMEApRAEA5vJUs0GHTXYvjOnIyvgWYzrKYiBSixyeiLc2KyrA8d7b7PDhYHTP++qrfI8oM2hgKUQBAOTKW5h53n+JWq+amFZhG1izIdHzXXBLRMgTPnYN+AeO/z9LcPBSiAIByBLvmdnPjjvmorBaqSUSBaaRYwxmp75q7qZqQlIxCtAhDIbrlubMsRDeszR2W5jK+JYZCFABQjsw9ohtZRSEKTMVzluaeMEdUlYzllZe/YKOrkzqok4jmoRAFAJQjoxBdbOpOIcmrBXtEgankLM111+K4ZkVWy7imL3/BZkVt3zV307lTLc50PyERDdmqEDWzm83sfjM7b2YvGfn9x5jZ6/vf/20zu37fBwoAwM6CzYqa5Mc2NrFqoTPGjQcwiZxmRe3x13SymvEtJYg2K2qPH+W1GJoVkYiGnPhf38xqSa+U9DxJN0m6zcxuWnvZiyT9qbt/nqQfl/TD+z5QAAB2FmxWlE5Yxuf9DXBqKUaBU5eZiJ44R5RE9PIXbVbkxxeiy/EtJKIh2/zXf4ak8+7+gCSZ2esk3SrpvpXX3CrpZf3Pf17SK8zM3Pt37RLzZ4/8iT70qlunPgwAwJ7d0Lxfv/UX1+qf/8v/uNXr3/+RT+gzzhyTtvSF6Pkf/GI5u12AU3WFHtUNkv75r75H/+E3t7umP/IXj6o6IRG94ZP36f5/8sw9HSXm6Anpz/RXJH3bz/yePlJ/4MTXf+pC93Bi07mz6Jfm/tX3vk73/5M37+04t/G53/NmPfYvPe5U/8592aYQvUbS6jv0oKT1q3P5GndvzOxjkj5b0iOrLzKz2yXdLknXXXdd5iFffGamTy+unPowAAB79q7FF+rex325HveY7Z6C/7XP+Uz9zad+9sbfv/rpL9AffOheumwCE/i0rtS9i7+p91/5hXrcYrtr+lmfd5We/wVP3vj7f/75/4Pe++4793WImKkP60q9u/qv9ehnXK3HbdE593GPkZ5705P033zuZ43+fl0v9Larv15/6c8f2PehnuyYVTtzZyeFlmb2dZJudvdv63/9jZKe6e4vXnnN2/vXPNj/+j39ax4Z+56SdPbsWT937twe/i8AAAAAAObGzO5197Njv7fNOqKHJD1l5dfX9l8bfY2ZLSQ9QdJH4ocKAAAAALjcbVOI3iPpRjO7wcyukPRCSetrFu6U9E39z79O0q9eqvtDAQAAAAAX14kL6vs9ny+WdLekWtJr3P0dZvZySefc/U5Jr5b0M2Z2XtJH1RWrAAAAAAAcsdXObne/S9Jda1976crPPyXp6/d7aAAAAACAyxG95gEAAAAAp4pCFAAAAABwqihEAQAAAACnikIUAAAAAHCqKEQBAAAAAKeKQhQAAAAAcKooRAEAAAAAp4pCFAAAAABwqihEAQAAAACnytx9mr/Y7GFJ75/kL9/eVZIemfogcATvyzzxvswT78s88b7MD+/JPPG+zBPvyzzN8X35XHe/euw3JitELwVmds7dz059HDiM92WeeF/mifdlnnhf5of3ZJ54X+aJ92WeLrX3haW5AAAAAIBTRSEKAAAAADhVFKLHu2PqA8Ao3pd54n2ZJ96XeeJ9mR/ek3nifZkn3pd5uqTeF/aIAgAAAABOFYkoAAAAAOBUUYiOMLObzex+MztvZi+Z+nhKZWZPMbO3mNl9ZvYOM/vu/usvM7OHzOz3+/89f+pjLY2Zvc/M/qj/73+u/9p/YWb/zsze3f/4WVMfZ0nM7L9cuSZ+38w+bmb/kOvl9JnZa8zsw2b29pWvjV4f1vkX/efNH5rZF0135Je3De/LPzOzd/X/7X/JzJ7Yf/16M/vkynXzqumO/PK24X3Z+O+WmX1ff73cb2ZfNc1RX/42vC+vX3lP3mdmv99/nevllBxzb3xJfsawNHeNmdWS/ljScyU9KOkeSbe5+32THliBzOzJkp7s7r9rZo+XdK+kr5b0dyT9hbv/H5MeYMHM7H2Szrr7Iytf+xFJH3X3H+of4HyWu/+jqY6xZP2/Yw9JeqakbxHXy6kysy+T9BeSftrdv6D/2uj10d9gf5ek56t7v/5Pd3/mVMd+OdvwvnylpF9198bMfliS+vflekn/dngdLp4N78vLNPLvlpndJOm1kp4h6XMk/XtJHbT75AAAA/tJREFUT3P39lQPugBj78va7/+opI+5+8u5Xk7PMffG36xL8DOGRPSoZ0g67+4PuPujkl4n6daJj6lI7v5Bd//d/ud/Lumdkq6Z9qhwjFsl/VT/859S9w8jpvEVkt7j7u+f+kBK5O6/Jumja1/edH3cqu5Gz939bZKe2N9oYM/G3hd3f5O7N/0v3ybp2lM/sMJtuF42uVXS69z90+7+Xknn1d23Yc+Oe1/MzNSFAq891YPCcffGl+RnDIXoUddI+sDKrx8Uxc/k+qdtT5f02/2XXtwvMXgNS0An4ZLeZGb3mtnt/dee5O4f7H/+J5KeNM2hQdILdfgGgetlepuuDz5z5uNbJb1x5dc3mNnvmdl/MLMvneqgCjb27xbXyzx8qaQPufu7V77G9XLK1u6NL8nPGApRzJ6ZPU7SL0j6h+7+cUk/Iempkv6GpA9K+tEJD69Uf8vdv0jS8yR9Z7+EZ8m7Nf+s+5+AmV0h6RZJP9d/ietlZrg+5sfMvl9SI+lf91/6oKTr3P3pkr5H0s+a2WdOdXwF4t+tebtNhx92cr2cspF746VL6TOGQvSohyQ9ZeXX1/ZfwwTM7Iy6C+1fu/svSpK7f8jdW3dPkv6VWJZz6tz9of7HD0v6JXXvwYeG5R79jx+e7giL9jxJv+vuH5K4XmZk0/XBZ87EzOybJb1A0v/Y38CpX/r5kf7n90p6j6SnTXaQhTnm3y2ul4mZ2ULS10h6/fA1rpfTNXZvrEv0M4ZC9Kh7JN1oZjf0ycILJd058TEVqd+D8GpJ73T3H1v5+ura9v9e0tvX/ywuHjO7st8gLzO7UtJXqnsP7pT0Tf3LvknSv5nmCIt36Ek118tsbLo+7pT09/rOhl+srvnHB8e+AfbPzG6W9L9IusXdP7Hy9av7pl8ys78q6UZJD0xzlOU55t+tOyW90MweY2Y3qHtffue0j69wz5H0Lnd/cPgC18vp2XRvrEv0M2Yx9QHMTd8578WS7pZUS3qNu79j4sMq1ZdI+kZJfzS0CJf0jyXdZmZ/Q92yg/dJ+vZpDq9YT5L0S92/hVpI+ll3/3/N7B5JbzCzF0l6v7pGBjhF/YOB5+rwNfEjXC+ny8xeK+nZkq4yswcl/YCkH9L49XGXum6G5yV9Ql2XY1wEG96X75P0GEn/rv837W3u/g8kfZmkl5vZBUlJ0j9w920b6iBgw/vy7LF/t9z9HWb2Bkn3qVtK/Z10zL04xt4Xd3+1jvYgkLheTtOme+NL8jOG8S0AAAAAgFPF0lwAAAAAwKmiEAUAAAAAnCoKUQAAAADAqaIQBQAAAACcKgpRAAAAAMCpohAFAAAAAJwqClEAAAAAwKmiEAUAAAAAnKr/HwavNtXVDG/KAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["!rm -rf /content/video/*"],"metadata":{"id":"eo6LHjNEzUuP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# env = gym.make(\"Breakout-v0\")\n","# env = SkipFrame(env, skip=4)\n","# env = GrayScaleObservation(env)\n","# env = ResizeObservation(env, shape=224)\n","# env = FrameStack(env, num_stack=4)\n","# env = LazyFramesToNumpy(env)\n","# exp_buffer = NStepPriorityReplayBuffer(\n","#     max_size=10000,\n","#     prob_alpha=0.6,\n","#     beta_start=0.4,\n","#     beta_frames=50000, #100000,\n","#     n_step=4,\n","#     gamma=0.99,\n","# )\n","# agent = Agent(\n","#     env=env,\n","#     exp_buffer=exp_buffer,\n","#     net=net,\n","#     epsilon_start=0.6,\n","#     epsilon_final=0.01,\n","#     epsilon_decay_last_step=50000, #200000,\n","#     tgt_sync_steps=1000,\n","#     learning_rate=1e-4,\n","#     device=device\n","# )\n","\n","episode = 0\n","\n","while True:\n","\n","    for stp in range(20):\n","        done_reward = agent.play_step()\n","        if done_reward is not None:\n","            print(f'episode : {episode}, done reward : {done_reward}, total_step : {agent._total_step}, cur_epsilon : {agent._epsilon}')\n","            episode += 1\n","    \n","    agent.train(n_iter=20, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckqdMUneN_K2","outputId":"dab64edc-9133-415f-e20c-b81123636ba3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["episode : 0, done reward : 1.0, total_step : 38, cur_epsilon : 0.59924\n","episode : 1, done reward : 1.0, total_step : 116, cur_epsilon : 0.59768\n","episode : 2, done reward : 0.0, total_step : 169, cur_epsilon : 0.5966199999999999\n","episode : 3, done reward : 1.0, total_step : 235, cur_epsilon : 0.5952999999999999\n","episode : 4, done reward : 2.0, total_step : 325, cur_epsilon : 0.5935\n","episode : 5, done reward : 2.0, total_step : 407, cur_epsilon : 0.5918599999999999\n","episode : 6, done reward : 3.0, total_step : 492, cur_epsilon : 0.59016\n","episode : 7, done reward : 2.0, total_step : 573, cur_epsilon : 0.58854\n","episode : 8, done reward : 1.0, total_step : 644, cur_epsilon : 0.58712\n","episode : 9, done reward : 0.0, total_step : 715, cur_epsilon : 0.5857\n","episode : 10, done reward : 2.0, total_step : 803, cur_epsilon : 0.58394\n","episode : 11, done reward : 2.0, total_step : 884, cur_epsilon : 0.58232\n","episode : 12, done reward : 3.0, total_step : 990, cur_epsilon : 0.5801999999999999\n","synced target net\n","episode : 13, done reward : 0.0, total_step : 1051, cur_epsilon : 0.5789799999999999\n","episode : 14, done reward : 1.0, total_step : 1113, cur_epsilon : 0.57774\n","episode : 15, done reward : 0.0, total_step : 1161, cur_epsilon : 0.57678\n","episode : 16, done reward : 2.0, total_step : 1246, cur_epsilon : 0.5750799999999999\n","episode : 17, done reward : 2.0, total_step : 1323, cur_epsilon : 0.5735399999999999\n","episode : 18, done reward : 1.0, total_step : 1400, cur_epsilon : 0.572\n","episode : 19, done reward : 1.0, total_step : 1480, cur_epsilon : 0.5704\n","episode : 20, done reward : 0.0, total_step : 1550, cur_epsilon : 0.569\n","episode : 21, done reward : 3.0, total_step : 1633, cur_epsilon : 0.56734\n","episode : 22, done reward : 1.0, total_step : 1713, cur_epsilon : 0.56574\n","episode : 23, done reward : 1.0, total_step : 1765, cur_epsilon : 0.5647\n","episode : 24, done reward : 2.0, total_step : 1856, cur_epsilon : 0.5628799999999999\n","episode : 25, done reward : 2.0, total_step : 1950, cur_epsilon : 0.5609999999999999\n","synced target net\n","episode : 26, done reward : 5.0, total_step : 2073, cur_epsilon : 0.55854\n","episode : 27, done reward : 4.0, total_step : 2196, cur_epsilon : 0.55608\n","episode : 28, done reward : 3.0, total_step : 2289, cur_epsilon : 0.5542199999999999\n","episode : 29, done reward : 3.0, total_step : 2399, cur_epsilon : 0.55202\n","episode : 30, done reward : 2.0, total_step : 2480, cur_epsilon : 0.5504\n","episode : 31, done reward : 1.0, total_step : 2548, cur_epsilon : 0.54904\n","episode : 32, done reward : 3.0, total_step : 2640, cur_epsilon : 0.5472\n","episode : 33, done reward : 0.0, total_step : 2690, cur_epsilon : 0.5462\n","episode : 34, done reward : 5.0, total_step : 2799, cur_epsilon : 0.54402\n","episode : 35, done reward : 3.0, total_step : 2890, cur_epsilon : 0.5422\n","episode : 36, done reward : 0.0, total_step : 2946, cur_epsilon : 0.54108\n","synced target net\n","episode : 37, done reward : 1.0, total_step : 3017, cur_epsilon : 0.53966\n","episode : 38, done reward : 4.0, total_step : 3110, cur_epsilon : 0.5378\n","episode : 39, done reward : 5.0, total_step : 3261, cur_epsilon : 0.53478\n","episode : 40, done reward : 2.0, total_step : 3331, cur_epsilon : 0.53338\n","episode : 41, done reward : 2.0, total_step : 3417, cur_epsilon : 0.53166\n","episode : 42, done reward : 1.0, total_step : 3485, cur_epsilon : 0.5303\n","episode : 43, done reward : 0.0, total_step : 3535, cur_epsilon : 0.5293\n","episode : 44, done reward : 4.0, total_step : 3633, cur_epsilon : 0.5273399999999999\n","episode : 45, done reward : 3.0, total_step : 3715, cur_epsilon : 0.5257\n","episode : 46, done reward : 3.0, total_step : 3794, cur_epsilon : 0.5241199999999999\n","episode : 47, done reward : 2.0, total_step : 3860, cur_epsilon : 0.5227999999999999\n","episode : 48, done reward : 3.0, total_step : 3948, cur_epsilon : 0.52104\n","synced target net\n","episode : 49, done reward : 3.0, total_step : 4025, cur_epsilon : 0.5195\n","episode : 50, done reward : 5.0, total_step : 4138, cur_epsilon : 0.5172399999999999\n","episode : 51, done reward : 4.0, total_step : 4255, cur_epsilon : 0.5149\n","episode : 52, done reward : 4.0, total_step : 4361, cur_epsilon : 0.51278\n","episode : 53, done reward : 4.0, total_step : 4470, cur_epsilon : 0.5105999999999999\n","episode : 54, done reward : 4.0, total_step : 4571, cur_epsilon : 0.50858\n","episode : 55, done reward : 1.0, total_step : 4628, cur_epsilon : 0.50744\n","episode : 56, done reward : 2.0, total_step : 4695, cur_epsilon : 0.5061\n","episode : 57, done reward : 4.0, total_step : 4817, cur_epsilon : 0.50366\n","episode : 58, done reward : 3.0, total_step : 4893, cur_epsilon : 0.50214\n","episode : 59, done reward : 2.0, total_step : 4962, cur_epsilon : 0.50076\n","synced target net\n","episode : 60, done reward : 5.0, total_step : 5099, cur_epsilon : 0.49801999999999996\n","episode : 61, done reward : 2.0, total_step : 5174, cur_epsilon : 0.49651999999999996\n","episode : 62, done reward : 3.0, total_step : 5263, cur_epsilon : 0.49473999999999996\n","episode : 63, done reward : 3.0, total_step : 5355, cur_epsilon : 0.4929\n","episode : 64, done reward : 2.0, total_step : 5428, cur_epsilon : 0.49144\n","episode : 65, done reward : 0.0, total_step : 5478, cur_epsilon : 0.49044\n","episode : 66, done reward : 2.0, total_step : 5556, cur_epsilon : 0.48888\n","episode : 67, done reward : 5.0, total_step : 5675, cur_epsilon : 0.4865\n","episode : 68, done reward : 4.0, total_step : 5774, cur_epsilon : 0.48451999999999995\n","episode : 69, done reward : 7.0, total_step : 5895, cur_epsilon : 0.4821\n","synced target net\n","episode : 70, done reward : 7.0, total_step : 6034, cur_epsilon : 0.47931999999999997\n","episode : 71, done reward : 2.0, total_step : 6105, cur_epsilon : 0.4779\n","episode : 72, done reward : 6.0, total_step : 6219, cur_epsilon : 0.47562\n","episode : 73, done reward : 3.0, total_step : 6305, cur_epsilon : 0.4739\n","episode : 74, done reward : 2.0, total_step : 6389, cur_epsilon : 0.47222\n","episode : 75, done reward : 3.0, total_step : 6491, cur_epsilon : 0.47018\n","episode : 76, done reward : 5.0, total_step : 6606, cur_epsilon : 0.46787999999999996\n","episode : 77, done reward : 2.0, total_step : 6677, cur_epsilon : 0.46646\n","episode : 78, done reward : 3.0, total_step : 6758, cur_epsilon : 0.46484\n","episode : 79, done reward : 4.0, total_step : 6859, cur_epsilon : 0.46282\n","episode : 80, done reward : 3.0, total_step : 6954, cur_epsilon : 0.46092\n","synced target net\n","episode : 81, done reward : 3.0, total_step : 7055, cur_epsilon : 0.4589\n","episode : 82, done reward : 2.0, total_step : 7132, cur_epsilon : 0.45736\n","episode : 83, done reward : 4.0, total_step : 7232, cur_epsilon : 0.45536\n","episode : 84, done reward : 4.0, total_step : 7344, cur_epsilon : 0.45311999999999997\n","episode : 85, done reward : 6.0, total_step : 7476, cur_epsilon : 0.45048\n","episode : 86, done reward : 3.0, total_step : 7559, cur_epsilon : 0.44882\n","episode : 87, done reward : 4.0, total_step : 7650, cur_epsilon : 0.44699999999999995\n","episode : 88, done reward : 4.0, total_step : 7782, cur_epsilon : 0.44436\n","episode : 89, done reward : 2.0, total_step : 7866, cur_epsilon : 0.44267999999999996\n","episode : 90, done reward : 2.0, total_step : 7952, cur_epsilon : 0.44096\n","synced target net\n","episode : 91, done reward : 7.0, total_step : 8075, cur_epsilon : 0.4385\n","episode : 92, done reward : 2.0, total_step : 8146, cur_epsilon : 0.43707999999999997\n","episode : 93, done reward : 1.0, total_step : 8206, cur_epsilon : 0.43588\n","episode : 94, done reward : 4.0, total_step : 8317, cur_epsilon : 0.43366\n","episode : 95, done reward : 2.0, total_step : 8379, cur_epsilon : 0.43241999999999997\n","episode : 96, done reward : 2.0, total_step : 8443, cur_epsilon : 0.43113999999999997\n","episode : 97, done reward : 4.0, total_step : 8536, cur_epsilon : 0.42928\n","episode : 98, done reward : 3.0, total_step : 8630, cur_epsilon : 0.4274\n","episode : 99, done reward : 3.0, total_step : 8714, cur_epsilon : 0.42572\n","episode : 100, done reward : 4.0, total_step : 8817, cur_epsilon : 0.42366\n","episode : 101, done reward : 2.0, total_step : 8891, cur_epsilon : 0.42218\n","synced target net\n","episode : 102, done reward : 6.0, total_step : 9023, cur_epsilon : 0.41953999999999997\n","episode : 103, done reward : 7.0, total_step : 9165, cur_epsilon : 0.41669999999999996\n","episode : 104, done reward : 2.0, total_step : 9226, cur_epsilon : 0.41547999999999996\n","episode : 105, done reward : 2.0, total_step : 9294, cur_epsilon : 0.41412\n","episode : 106, done reward : 5.0, total_step : 9406, cur_epsilon : 0.41187999999999997\n","episode : 107, done reward : 4.0, total_step : 9518, cur_epsilon : 0.40964\n","episode : 108, done reward : 2.0, total_step : 9597, cur_epsilon : 0.40806\n","episode : 109, done reward : 0.0, total_step : 9645, cur_epsilon : 0.4071\n","episode : 110, done reward : 2.0, total_step : 9719, cur_epsilon : 0.40562\n","episode : 111, done reward : 4.0, total_step : 9821, cur_epsilon : 0.40357999999999994\n","episode : 112, done reward : 5.0, total_step : 9930, cur_epsilon : 0.4014\n","synced target net\n","episode : 113, done reward : 5.0, total_step : 10042, cur_epsilon : 0.39915999999999996\n","episode : 114, done reward : 5.0, total_step : 10162, cur_epsilon : 0.39676\n","episode : 115, done reward : 6.0, total_step : 10285, cur_epsilon : 0.3943\n","episode : 116, done reward : 4.0, total_step : 10382, cur_epsilon : 0.39236\n","episode : 117, done reward : 2.0, total_step : 10454, cur_epsilon : 0.39092\n","episode : 118, done reward : 11.0, total_step : 10616, cur_epsilon : 0.38767999999999997\n","episode : 119, done reward : 3.0, total_step : 10723, cur_epsilon : 0.38554\n","episode : 120, done reward : 3.0, total_step : 10807, cur_epsilon : 0.38386\n","episode : 121, done reward : 2.0, total_step : 10875, cur_epsilon : 0.38249999999999995\n","synced target net\n","episode : 122, done reward : 7.0, total_step : 11018, cur_epsilon : 0.37964\n","episode : 123, done reward : 0.0, total_step : 11067, cur_epsilon : 0.37866\n","episode : 124, done reward : 2.0, total_step : 11144, cur_epsilon : 0.37712\n","episode : 125, done reward : 4.0, total_step : 11243, cur_epsilon : 0.37514\n","episode : 126, done reward : 4.0, total_step : 11371, cur_epsilon : 0.37257999999999997\n","episode : 127, done reward : 4.0, total_step : 11480, cur_epsilon : 0.37039999999999995\n","episode : 128, done reward : 3.0, total_step : 11577, cur_epsilon : 0.36846\n","episode : 129, done reward : 4.0, total_step : 11674, cur_epsilon : 0.36651999999999996\n","episode : 130, done reward : 5.0, total_step : 11803, cur_epsilon : 0.36394\n","episode : 131, done reward : 7.0, total_step : 11937, cur_epsilon : 0.36125999999999997\n","synced target net\n","episode : 132, done reward : 8.0, total_step : 12057, cur_epsilon : 0.35885999999999996\n","episode : 133, done reward : 6.0, total_step : 12173, cur_epsilon : 0.35653999999999997\n","episode : 134, done reward : 2.0, total_step : 12244, cur_epsilon : 0.35512\n","episode : 135, done reward : 5.0, total_step : 12361, cur_epsilon : 0.35278\n","episode : 136, done reward : 3.0, total_step : 12460, cur_epsilon : 0.3508\n","episode : 137, done reward : 4.0, total_step : 12564, cur_epsilon : 0.34872\n","episode : 138, done reward : 1.0, total_step : 12626, cur_epsilon : 0.34747999999999996\n","episode : 139, done reward : 3.0, total_step : 12707, cur_epsilon : 0.34586\n","episode : 140, done reward : 4.0, total_step : 12812, cur_epsilon : 0.34375999999999995\n","episode : 141, done reward : 3.0, total_step : 12903, cur_epsilon : 0.34193999999999997\n","synced target net\n","episode : 142, done reward : 5.0, total_step : 13010, cur_epsilon : 0.3398\n","episode : 143, done reward : 5.0, total_step : 13119, cur_epsilon : 0.33762\n","episode : 144, done reward : 2.0, total_step : 13196, cur_epsilon : 0.33608\n","episode : 145, done reward : 11.0, total_step : 13351, cur_epsilon : 0.33298\n","episode : 146, done reward : 3.0, total_step : 13441, cur_epsilon : 0.33118\n","episode : 147, done reward : 4.0, total_step : 13551, cur_epsilon : 0.32898\n","episode : 148, done reward : 7.0, total_step : 13691, cur_epsilon : 0.32617999999999997\n","episode : 149, done reward : 7.0, total_step : 13838, cur_epsilon : 0.32323999999999997\n","episode : 150, done reward : 3.0, total_step : 13928, cur_epsilon : 0.32144\n","synced target net\n","episode : 151, done reward : 5.0, total_step : 14050, cur_epsilon : 0.31899999999999995\n","episode : 152, done reward : 2.0, total_step : 14127, cur_epsilon : 0.31745999999999996\n","episode : 153, done reward : 3.0, total_step : 14216, cur_epsilon : 0.31567999999999996\n","episode : 154, done reward : 5.0, total_step : 14339, cur_epsilon : 0.31322\n","episode : 155, done reward : 5.0, total_step : 14479, cur_epsilon : 0.31042\n","episode : 156, done reward : 5.0, total_step : 14589, cur_epsilon : 0.30822\n","episode : 157, done reward : 5.0, total_step : 14746, cur_epsilon : 0.30507999999999996\n","episode : 158, done reward : 3.0, total_step : 14855, cur_epsilon : 0.3029\n","episode : 159, done reward : 3.0, total_step : 14946, cur_epsilon : 0.30107999999999996\n","synced target net\n","episode : 160, done reward : 5.0, total_step : 15066, cur_epsilon : 0.29868\n","episode : 161, done reward : 4.0, total_step : 15175, cur_epsilon : 0.2965\n","episode : 162, done reward : 4.0, total_step : 15291, cur_epsilon : 0.29418\n","episode : 163, done reward : 6.0, total_step : 15411, cur_epsilon : 0.29178\n","episode : 164, done reward : 2.0, total_step : 15506, cur_epsilon : 0.28987999999999997\n","episode : 165, done reward : 4.0, total_step : 15617, cur_epsilon : 0.28765999999999997\n","episode : 166, done reward : 3.0, total_step : 15715, cur_epsilon : 0.28569999999999995\n","episode : 167, done reward : 2.0, total_step : 15810, cur_epsilon : 0.2838\n","episode : 168, done reward : 4.0, total_step : 15933, cur_epsilon : 0.28134\n","synced target net\n","episode : 169, done reward : 10.0, total_step : 16142, cur_epsilon : 0.27715999999999996\n","episode : 170, done reward : 3.0, total_step : 16223, cur_epsilon : 0.27553999999999995\n","episode : 171, done reward : 3.0, total_step : 16329, cur_epsilon : 0.27342\n","episode : 172, done reward : 3.0, total_step : 16418, cur_epsilon : 0.27164\n","episode : 173, done reward : 5.0, total_step : 16536, cur_epsilon : 0.26927999999999996\n","episode : 174, done reward : 4.0, total_step : 16624, cur_epsilon : 0.26752\n","episode : 175, done reward : 5.0, total_step : 16752, cur_epsilon : 0.26496\n","episode : 176, done reward : 3.0, total_step : 16826, cur_epsilon : 0.26348\n","episode : 177, done reward : 2.0, total_step : 16904, cur_epsilon : 0.26192\n","synced target net\n","episode : 178, done reward : 6.0, total_step : 17046, cur_epsilon : 0.25908\n","episode : 179, done reward : 3.0, total_step : 17136, cur_epsilon : 0.25727999999999995\n","episode : 180, done reward : 4.0, total_step : 17230, cur_epsilon : 0.25539999999999996\n","episode : 181, done reward : 4.0, total_step : 17339, cur_epsilon : 0.25322\n","episode : 182, done reward : 3.0, total_step : 17425, cur_epsilon : 0.2515\n","episode : 183, done reward : 5.0, total_step : 17568, cur_epsilon : 0.24863999999999997\n","episode : 184, done reward : 5.0, total_step : 17732, cur_epsilon : 0.24535999999999997\n","episode : 185, done reward : 3.0, total_step : 17819, cur_epsilon : 0.24362\n","episode : 186, done reward : 6.0, total_step : 17953, cur_epsilon : 0.24094\n","synced target net\n","episode : 187, done reward : 1.0, total_step : 18023, cur_epsilon : 0.23953999999999998\n","episode : 188, done reward : 3.0, total_step : 18102, cur_epsilon : 0.23796\n","episode : 189, done reward : 3.0, total_step : 18188, cur_epsilon : 0.23624\n","episode : 190, done reward : 1.0, total_step : 18243, cur_epsilon : 0.23513999999999996\n","episode : 191, done reward : 3.0, total_step : 18328, cur_epsilon : 0.23343999999999998\n","episode : 192, done reward : 3.0, total_step : 18418, cur_epsilon : 0.23163999999999996\n","episode : 193, done reward : 7.0, total_step : 18554, cur_epsilon : 0.22891999999999996\n","episode : 194, done reward : 6.0, total_step : 18685, cur_epsilon : 0.2263\n","episode : 195, done reward : 4.0, total_step : 18803, cur_epsilon : 0.22393999999999997\n","episode : 196, done reward : 4.0, total_step : 18896, cur_epsilon : 0.22208\n","episode : 197, done reward : 3.0, total_step : 18970, cur_epsilon : 0.22059999999999996\n","synced target net\n","episode : 198, done reward : 2.0, total_step : 19037, cur_epsilon : 0.21925999999999995\n","episode : 199, done reward : 6.0, total_step : 19165, cur_epsilon : 0.2167\n","episode : 200, done reward : 4.0, total_step : 19333, cur_epsilon : 0.21333999999999997\n","episode : 201, done reward : 5.0, total_step : 19438, cur_epsilon : 0.21123999999999998\n","episode : 202, done reward : 9.0, total_step : 19624, cur_epsilon : 0.20751999999999998\n","episode : 203, done reward : 6.0, total_step : 19748, cur_epsilon : 0.20504\n","episode : 204, done reward : 3.0, total_step : 19839, cur_epsilon : 0.20321999999999996\n","episode : 205, done reward : 1.0, total_step : 19900, cur_epsilon : 0.20199999999999996\n","synced target net\n","episode : 206, done reward : 7.0, total_step : 20031, cur_epsilon : 0.19938\n","episode : 207, done reward : 5.0, total_step : 20141, cur_epsilon : 0.19717999999999997\n","episode : 208, done reward : 3.0, total_step : 20226, cur_epsilon : 0.19548\n","episode : 209, done reward : 3.0, total_step : 20311, cur_epsilon : 0.19377999999999995\n","episode : 210, done reward : 5.0, total_step : 20426, cur_epsilon : 0.19147999999999998\n","episode : 211, done reward : 4.0, total_step : 20523, cur_epsilon : 0.18954\n","episode : 212, done reward : 4.0, total_step : 20623, cur_epsilon : 0.18753999999999998\n","episode : 213, done reward : 3.0, total_step : 20715, cur_epsilon : 0.18569999999999998\n","episode : 214, done reward : 3.0, total_step : 20804, cur_epsilon : 0.18391999999999997\n","episode : 215, done reward : 6.0, total_step : 20934, cur_epsilon : 0.18131999999999998\n","synced target net\n","episode : 216, done reward : 6.0, total_step : 21050, cur_epsilon : 0.179\n","episode : 217, done reward : 3.0, total_step : 21135, cur_epsilon : 0.17729999999999996\n","episode : 218, done reward : 1.0, total_step : 21188, cur_epsilon : 0.17623999999999995\n","episode : 219, done reward : 7.0, total_step : 21355, cur_epsilon : 0.1729\n","episode : 220, done reward : 6.0, total_step : 21482, cur_epsilon : 0.17035999999999996\n","episode : 221, done reward : 4.0, total_step : 21571, cur_epsilon : 0.16857999999999995\n","episode : 222, done reward : 3.0, total_step : 21653, cur_epsilon : 0.16693999999999998\n","episode : 223, done reward : 5.0, total_step : 21761, cur_epsilon : 0.16477999999999998\n","episode : 224, done reward : 11.0, total_step : 21923, cur_epsilon : 0.16153999999999996\n","synced target net\n","episode : 225, done reward : 4.0, total_step : 22042, cur_epsilon : 0.15915999999999997\n","episode : 226, done reward : 6.0, total_step : 22160, cur_epsilon : 0.1568\n","episode : 227, done reward : 1.0, total_step : 22215, cur_epsilon : 0.1557\n","episode : 228, done reward : 5.0, total_step : 22332, cur_epsilon : 0.15336\n","episode : 229, done reward : 8.0, total_step : 22488, cur_epsilon : 0.15023999999999998\n","episode : 230, done reward : 2.0, total_step : 22569, cur_epsilon : 0.14861999999999997\n","episode : 231, done reward : 3.0, total_step : 22667, cur_epsilon : 0.14665999999999996\n","episode : 232, done reward : 4.0, total_step : 22759, cur_epsilon : 0.14482\n","episode : 233, done reward : 5.0, total_step : 22868, cur_epsilon : 0.14264\n","synced target net\n","episode : 234, done reward : 7.0, total_step : 23027, cur_epsilon : 0.13945999999999997\n","episode : 235, done reward : 4.0, total_step : 23123, cur_epsilon : 0.13754\n","episode : 236, done reward : 1.0, total_step : 23179, cur_epsilon : 0.13641999999999999\n","episode : 237, done reward : 7.0, total_step : 23320, cur_epsilon : 0.1336\n","episode : 238, done reward : 2.0, total_step : 23386, cur_epsilon : 0.13227999999999995\n","episode : 239, done reward : 6.0, total_step : 23593, cur_epsilon : 0.12813999999999998\n","episode : 240, done reward : 7.0, total_step : 23725, cur_epsilon : 0.1255\n","episode : 241, done reward : 7.0, total_step : 23875, cur_epsilon : 0.1225\n","episode : 242, done reward : 4.0, total_step : 23968, cur_epsilon : 0.12063999999999997\n","synced target net\n","episode : 243, done reward : 8.0, total_step : 24135, cur_epsilon : 0.11729999999999996\n","episode : 244, done reward : 2.0, total_step : 24201, cur_epsilon : 0.11597999999999997\n","episode : 245, done reward : 11.0, total_step : 24388, cur_epsilon : 0.11223999999999995\n","episode : 246, done reward : 3.0, total_step : 24468, cur_epsilon : 0.11063999999999996\n","episode : 247, done reward : 8.0, total_step : 24626, cur_epsilon : 0.10747999999999996\n","episode : 248, done reward : 3.0, total_step : 24696, cur_epsilon : 0.10607999999999995\n","episode : 249, done reward : 6.0, total_step : 24813, cur_epsilon : 0.10374\n","episode : 250, done reward : 5.0, total_step : 24914, cur_epsilon : 0.10171999999999998\n","synced target net\n","episode : 251, done reward : 4.0, total_step : 25006, cur_epsilon : 0.09987999999999997\n","episode : 252, done reward : 8.0, total_step : 25159, cur_epsilon : 0.09682000000000002\n","episode : 253, done reward : 3.0, total_step : 25232, cur_epsilon : 0.09536\n","episode : 254, done reward : 5.0, total_step : 25359, cur_epsilon : 0.09282000000000001\n","episode : 255, done reward : 4.0, total_step : 25449, cur_epsilon : 0.09101999999999999\n","episode : 256, done reward : 4.0, total_step : 25566, cur_epsilon : 0.08867999999999998\n","episode : 257, done reward : 1.0, total_step : 25625, cur_epsilon : 0.08750000000000002\n","episode : 258, done reward : 5.0, total_step : 25778, cur_epsilon : 0.08443999999999996\n","episode : 259, done reward : 8.0, total_step : 25953, cur_epsilon : 0.08094000000000001\n","synced target net\n","episode : 260, done reward : 8.0, total_step : 26144, cur_epsilon : 0.07711999999999997\n","episode : 261, done reward : 5.0, total_step : 26276, cur_epsilon : 0.07447999999999999\n","episode : 262, done reward : 8.0, total_step : 26424, cur_epsilon : 0.07152000000000003\n","episode : 263, done reward : 6.0, total_step : 26600, cur_epsilon : 0.06799999999999995\n","episode : 264, done reward : 1.0, total_step : 26671, cur_epsilon : 0.06657999999999997\n","episode : 265, done reward : 4.0, total_step : 26769, cur_epsilon : 0.06462000000000001\n","episode : 266, done reward : 6.0, total_step : 26927, cur_epsilon : 0.06145999999999996\n","synced target net\n","episode : 267, done reward : 1.0, total_step : 27005, cur_epsilon : 0.05989999999999995\n","episode : 268, done reward : 8.0, total_step : 27216, cur_epsilon : 0.05567999999999995\n","episode : 269, done reward : 6.0, total_step : 27331, cur_epsilon : 0.05337999999999998\n","episode : 270, done reward : 8.0, total_step : 27528, cur_epsilon : 0.04943999999999993\n","episode : 271, done reward : 4.0, total_step : 27619, cur_epsilon : 0.047619999999999996\n","episode : 272, done reward : 7.0, total_step : 27747, cur_epsilon : 0.04505999999999999\n","episode : 273, done reward : 9.0, total_step : 27913, cur_epsilon : 0.04174\n","synced target net\n","episode : 274, done reward : 7.0, total_step : 28086, cur_epsilon : 0.03827999999999998\n","episode : 275, done reward : 4.0, total_step : 28197, cur_epsilon : 0.03605999999999998\n","episode : 276, done reward : 5.0, total_step : 28362, cur_epsilon : 0.03276000000000001\n","episode : 277, done reward : 4.0, total_step : 28492, cur_epsilon : 0.030159999999999965\n","episode : 278, done reward : 9.0, total_step : 28652, cur_epsilon : 0.026959999999999984\n","episode : 279, done reward : 4.0, total_step : 28778, cur_epsilon : 0.024440000000000017\n","synced target net\n","episode : 280, done reward : 7.0, total_step : 29080, cur_epsilon : 0.018399999999999972\n","episode : 281, done reward : 7.0, total_step : 29207, cur_epsilon : 0.015859999999999985\n","episode : 282, done reward : 6.0, total_step : 29331, cur_epsilon : 0.013379999999999947\n","episode : 283, done reward : 8.0, total_step : 29471, cur_epsilon : 0.010579999999999923\n","episode : 284, done reward : 3.0, total_step : 29591, cur_epsilon : 0.01\n","episode : 285, done reward : 2.0, total_step : 29653, cur_epsilon : 0.01\n","episode : 286, done reward : 7.0, total_step : 29779, cur_epsilon : 0.01\n","synced target net\n","episode : 287, done reward : 9.0, total_step : 30099, cur_epsilon : 0.01\n","episode : 288, done reward : 6.0, total_step : 30268, cur_epsilon : 0.01\n","episode : 289, done reward : 3.0, total_step : 30457, cur_epsilon : 0.01\n","episode : 290, done reward : 9.0, total_step : 30670, cur_epsilon : 0.01\n","episode : 291, done reward : 6.0, total_step : 30789, cur_epsilon : 0.01\n","episode : 292, done reward : 6.0, total_step : 30912, cur_epsilon : 0.01\n","synced target net\n","episode : 293, done reward : 5.0, total_step : 31017, cur_epsilon : 0.01\n","episode : 294, done reward : 14.0, total_step : 31205, cur_epsilon : 0.01\n","episode : 295, done reward : 4.0, total_step : 31298, cur_epsilon : 0.01\n","episode : 296, done reward : 8.0, total_step : 31616, cur_epsilon : 0.01\n","episode : 297, done reward : 6.0, total_step : 31760, cur_epsilon : 0.01\n","episode : 298, done reward : 3.0, total_step : 31839, cur_epsilon : 0.01\n","episode : 299, done reward : 7.0, total_step : 31972, cur_epsilon : 0.01\n","synced target net\n","episode : 300, done reward : 2.0, total_step : 32036, cur_epsilon : 0.01\n","episode : 301, done reward : 5.0, total_step : 32176, cur_epsilon : 0.01\n","episode : 302, done reward : 5.0, total_step : 32286, cur_epsilon : 0.01\n","episode : 303, done reward : 3.0, total_step : 32383, cur_epsilon : 0.01\n","episode : 304, done reward : 7.0, total_step : 32509, cur_epsilon : 0.01\n","episode : 305, done reward : 6.0, total_step : 32639, cur_epsilon : 0.01\n","episode : 306, done reward : 6.0, total_step : 32765, cur_epsilon : 0.01\n","synced target net\n","episode : 307, done reward : 8.0, total_step : 33089, cur_epsilon : 0.01\n","episode : 308, done reward : 5.0, total_step : 33236, cur_epsilon : 0.01\n","episode : 309, done reward : 3.0, total_step : 33307, cur_epsilon : 0.01\n","episode : 310, done reward : 6.0, total_step : 33416, cur_epsilon : 0.01\n","episode : 311, done reward : 7.0, total_step : 33555, cur_epsilon : 0.01\n","episode : 312, done reward : 2.0, total_step : 33616, cur_epsilon : 0.01\n","episode : 313, done reward : 7.0, total_step : 33766, cur_epsilon : 0.01\n","episode : 314, done reward : 9.0, total_step : 33923, cur_epsilon : 0.01\n","synced target net\n","episode : 315, done reward : 4.0, total_step : 34021, cur_epsilon : 0.01\n","episode : 316, done reward : 6.0, total_step : 34131, cur_epsilon : 0.01\n","episode : 317, done reward : 7.0, total_step : 34253, cur_epsilon : 0.01\n","episode : 318, done reward : 11.0, total_step : 34883, cur_epsilon : 0.01\n","synced target net\n","episode : 319, done reward : 7.0, total_step : 35004, cur_epsilon : 0.01\n","episode : 320, done reward : 6.0, total_step : 35256, cur_epsilon : 0.01\n","episode : 321, done reward : 8.0, total_step : 35394, cur_epsilon : 0.01\n","episode : 322, done reward : 9.0, total_step : 35551, cur_epsilon : 0.01\n","episode : 323, done reward : 6.0, total_step : 35676, cur_epsilon : 0.01\n","episode : 324, done reward : 6.0, total_step : 35833, cur_epsilon : 0.01\n","episode : 325, done reward : 5.0, total_step : 35942, cur_epsilon : 0.01\n","synced target net\n","episode : 326, done reward : 4.0, total_step : 36034, cur_epsilon : 0.01\n","episode : 327, done reward : 4.0, total_step : 36124, cur_epsilon : 0.01\n","episode : 328, done reward : 7.0, total_step : 36259, cur_epsilon : 0.01\n","episode : 329, done reward : 5.0, total_step : 36364, cur_epsilon : 0.01\n","episode : 330, done reward : 7.0, total_step : 36508, cur_epsilon : 0.01\n","episode : 331, done reward : 6.0, total_step : 36628, cur_epsilon : 0.01\n","episode : 332, done reward : 7.0, total_step : 36779, cur_epsilon : 0.01\n","episode : 333, done reward : 3.0, total_step : 36905, cur_epsilon : 0.01\n","synced target net\n","episode : 334, done reward : 7.0, total_step : 37031, cur_epsilon : 0.01\n","episode : 335, done reward : 4.0, total_step : 37122, cur_epsilon : 0.01\n","episode : 336, done reward : 8.0, total_step : 37270, cur_epsilon : 0.01\n","episode : 337, done reward : 2.0, total_step : 37363, cur_epsilon : 0.01\n","episode : 338, done reward : 4.0, total_step : 37466, cur_epsilon : 0.01\n","episode : 339, done reward : 5.0, total_step : 37569, cur_epsilon : 0.01\n","episode : 340, done reward : 7.0, total_step : 37701, cur_epsilon : 0.01\n","episode : 341, done reward : 3.0, total_step : 37779, cur_epsilon : 0.01\n","synced target net\n","episode : 342, done reward : 10.0, total_step : 38019, cur_epsilon : 0.01\n","episode : 343, done reward : 3.0, total_step : 38091, cur_epsilon : 0.01\n","episode : 344, done reward : 4.0, total_step : 38182, cur_epsilon : 0.01\n","episode : 345, done reward : 7.0, total_step : 38386, cur_epsilon : 0.01\n","episode : 346, done reward : 5.0, total_step : 38505, cur_epsilon : 0.01\n","episode : 347, done reward : 7.0, total_step : 38723, cur_epsilon : 0.01\n","episode : 348, done reward : 9.0, total_step : 38950, cur_epsilon : 0.01\n","synced target net\n","episode : 349, done reward : 5.0, total_step : 39063, cur_epsilon : 0.01\n","episode : 350, done reward : 6.0, total_step : 39225, cur_epsilon : 0.01\n","episode : 351, done reward : 6.0, total_step : 39361, cur_epsilon : 0.01\n","episode : 352, done reward : 6.0, total_step : 39486, cur_epsilon : 0.01\n","episode : 353, done reward : 4.0, total_step : 39591, cur_epsilon : 0.01\n","episode : 354, done reward : 3.0, total_step : 39675, cur_epsilon : 0.01\n","episode : 355, done reward : 9.0, total_step : 39880, cur_epsilon : 0.01\n","synced target net\n","episode : 356, done reward : 14.0, total_step : 40057, cur_epsilon : 0.01\n","episode : 357, done reward : 6.0, total_step : 40198, cur_epsilon : 0.01\n","episode : 358, done reward : 2.0, total_step : 40287, cur_epsilon : 0.01\n","episode : 359, done reward : 9.0, total_step : 40450, cur_epsilon : 0.01\n","episode : 360, done reward : 4.0, total_step : 40548, cur_epsilon : 0.01\n","episode : 361, done reward : 8.0, total_step : 40853, cur_epsilon : 0.01\n","episode : 362, done reward : 4.0, total_step : 40955, cur_epsilon : 0.01\n","synced target net\n","episode : 363, done reward : 8.0, total_step : 41089, cur_epsilon : 0.01\n","episode : 364, done reward : 5.0, total_step : 41208, cur_epsilon : 0.01\n","episode : 365, done reward : 5.0, total_step : 41320, cur_epsilon : 0.01\n","episode : 366, done reward : 6.0, total_step : 41428, cur_epsilon : 0.01\n","episode : 367, done reward : 4.0, total_step : 41540, cur_epsilon : 0.01\n","episode : 368, done reward : 7.0, total_step : 41673, cur_epsilon : 0.01\n","episode : 369, done reward : 3.0, total_step : 41778, cur_epsilon : 0.01\n","synced target net\n","episode : 370, done reward : 6.0, total_step : 42029, cur_epsilon : 0.01\n","episode : 371, done reward : 3.0, total_step : 42142, cur_epsilon : 0.01\n","episode : 372, done reward : 6.0, total_step : 42265, cur_epsilon : 0.01\n","episode : 373, done reward : 6.0, total_step : 42395, cur_epsilon : 0.01\n","episode : 374, done reward : 8.0, total_step : 42565, cur_epsilon : 0.01\n","episode : 375, done reward : 7.0, total_step : 42702, cur_epsilon : 0.01\n","episode : 376, done reward : 8.0, total_step : 42878, cur_epsilon : 0.01\n","synced target net\n","episode : 377, done reward : 8.0, total_step : 43025, cur_epsilon : 0.01\n","episode : 378, done reward : 3.0, total_step : 43120, cur_epsilon : 0.01\n","episode : 379, done reward : 9.0, total_step : 43278, cur_epsilon : 0.01\n","episode : 380, done reward : 8.0, total_step : 43443, cur_epsilon : 0.01\n","episode : 381, done reward : 7.0, total_step : 43580, cur_epsilon : 0.01\n","episode : 382, done reward : 6.0, total_step : 43720, cur_epsilon : 0.01\n","synced target net\n","episode : 383, done reward : 4.0, total_step : 44022, cur_epsilon : 0.01\n","episode : 384, done reward : 5.0, total_step : 44122, cur_epsilon : 0.01\n","episode : 385, done reward : 6.0, total_step : 44241, cur_epsilon : 0.01\n","episode : 386, done reward : 4.0, total_step : 44345, cur_epsilon : 0.01\n","episode : 387, done reward : 6.0, total_step : 44480, cur_epsilon : 0.01\n","episode : 388, done reward : 4.0, total_step : 44573, cur_epsilon : 0.01\n","episode : 389, done reward : 4.0, total_step : 44790, cur_epsilon : 0.01\n","episode : 390, done reward : 6.0, total_step : 44926, cur_epsilon : 0.01\n","synced target net\n","episode : 391, done reward : 4.0, total_step : 45025, cur_epsilon : 0.01\n","episode : 392, done reward : 5.0, total_step : 45142, cur_epsilon : 0.01\n","episode : 393, done reward : 3.0, total_step : 45236, cur_epsilon : 0.01\n","episode : 394, done reward : 5.0, total_step : 45425, cur_epsilon : 0.01\n","episode : 395, done reward : 4.0, total_step : 45624, cur_epsilon : 0.01\n","episode : 396, done reward : 4.0, total_step : 45708, cur_epsilon : 0.01\n","episode : 397, done reward : 10.0, total_step : 45851, cur_epsilon : 0.01\n","synced target net\n","episode : 398, done reward : 10.0, total_step : 46020, cur_epsilon : 0.01\n","episode : 399, done reward : 9.0, total_step : 46405, cur_epsilon : 0.01\n","episode : 400, done reward : 4.0, total_step : 46500, cur_epsilon : 0.01\n","episode : 401, done reward : 11.0, total_step : 46706, cur_epsilon : 0.01\n","synced target net\n","episode : 402, done reward : 7.0, total_step : 47190, cur_epsilon : 0.01\n","episode : 403, done reward : 9.0, total_step : 47417, cur_epsilon : 0.01\n","episode : 404, done reward : 7.0, total_step : 47595, cur_epsilon : 0.01\n","episode : 405, done reward : 7.0, total_step : 47772, cur_epsilon : 0.01\n","episode : 406, done reward : 7.0, total_step : 47905, cur_epsilon : 0.01\n","synced target net\n","episode : 407, done reward : 6.0, total_step : 48038, cur_epsilon : 0.01\n","episode : 408, done reward : 6.0, total_step : 48156, cur_epsilon : 0.01\n","episode : 409, done reward : 8.0, total_step : 48294, cur_epsilon : 0.01\n","episode : 410, done reward : 8.0, total_step : 48448, cur_epsilon : 0.01\n","episode : 411, done reward : 8.0, total_step : 48696, cur_epsilon : 0.01\n","episode : 412, done reward : 5.0, total_step : 48808, cur_epsilon : 0.01\n","episode : 413, done reward : 7.0, total_step : 48949, cur_epsilon : 0.01\n","synced target net\n","episode : 414, done reward : 8.0, total_step : 49096, cur_epsilon : 0.01\n","episode : 415, done reward : 6.0, total_step : 49212, cur_epsilon : 0.01\n","episode : 416, done reward : 10.0, total_step : 49372, cur_epsilon : 0.01\n","episode : 417, done reward : 8.0, total_step : 49573, cur_epsilon : 0.01\n","episode : 418, done reward : 7.0, total_step : 49701, cur_epsilon : 0.01\n","episode : 419, done reward : 7.0, total_step : 49826, cur_epsilon : 0.01\n","episode : 420, done reward : 7.0, total_step : 49954, cur_epsilon : 0.01\n","synced target net\n","episode : 421, done reward : 8.0, total_step : 50113, cur_epsilon : 0.01\n","episode : 422, done reward : 7.0, total_step : 50245, cur_epsilon : 0.01\n","episode : 423, done reward : 6.0, total_step : 50376, cur_epsilon : 0.01\n","episode : 424, done reward : 7.0, total_step : 50540, cur_epsilon : 0.01\n","episode : 425, done reward : 3.0, total_step : 50685, cur_epsilon : 0.01\n","episode : 426, done reward : 2.0, total_step : 50748, cur_epsilon : 0.01\n","synced target net\n","episode : 427, done reward : 12.0, total_step : 51051, cur_epsilon : 0.01\n","episode : 428, done reward : 9.0, total_step : 51208, cur_epsilon : 0.01\n","episode : 429, done reward : 7.0, total_step : 51333, cur_epsilon : 0.01\n","episode : 430, done reward : 8.0, total_step : 51474, cur_epsilon : 0.01\n","episode : 431, done reward : 7.0, total_step : 51597, cur_epsilon : 0.01\n","episode : 432, done reward : 11.0, total_step : 51770, cur_epsilon : 0.01\n","episode : 433, done reward : 4.0, total_step : 51861, cur_epsilon : 0.01\n","episode : 434, done reward : 7.0, total_step : 51996, cur_epsilon : 0.01\n","synced target net\n","episode : 435, done reward : 11.0, total_step : 52155, cur_epsilon : 0.01\n","episode : 436, done reward : 8.0, total_step : 52296, cur_epsilon : 0.01\n","episode : 437, done reward : 7.0, total_step : 52449, cur_epsilon : 0.01\n","episode : 438, done reward : 9.0, total_step : 52600, cur_epsilon : 0.01\n","episode : 439, done reward : 11.0, total_step : 52784, cur_epsilon : 0.01\n","episode : 440, done reward : 4.0, total_step : 52946, cur_epsilon : 0.01\n","synced target net\n","episode : 441, done reward : 9.0, total_step : 53115, cur_epsilon : 0.01\n","episode : 442, done reward : 8.0, total_step : 53263, cur_epsilon : 0.01\n","episode : 443, done reward : 6.0, total_step : 53381, cur_epsilon : 0.01\n","episode : 444, done reward : 8.0, total_step : 53524, cur_epsilon : 0.01\n","episode : 445, done reward : 8.0, total_step : 53673, cur_epsilon : 0.01\n","episode : 446, done reward : 5.0, total_step : 53770, cur_epsilon : 0.01\n","episode : 447, done reward : 6.0, total_step : 53897, cur_epsilon : 0.01\n","synced target net\n","episode : 448, done reward : 8.0, total_step : 54032, cur_epsilon : 0.01\n","episode : 449, done reward : 6.0, total_step : 54149, cur_epsilon : 0.01\n","episode : 450, done reward : 5.0, total_step : 54258, cur_epsilon : 0.01\n","episode : 451, done reward : 7.0, total_step : 54393, cur_epsilon : 0.01\n","episode : 452, done reward : 13.0, total_step : 54613, cur_epsilon : 0.01\n","episode : 453, done reward : 5.0, total_step : 54728, cur_epsilon : 0.01\n","episode : 454, done reward : 3.0, total_step : 54813, cur_epsilon : 0.01\n","episode : 455, done reward : 8.0, total_step : 54959, cur_epsilon : 0.01\n","synced target net\n","episode : 456, done reward : 7.0, total_step : 55091, cur_epsilon : 0.01\n","episode : 457, done reward : 4.0, total_step : 55189, cur_epsilon : 0.01\n","episode : 458, done reward : 6.0, total_step : 55307, cur_epsilon : 0.01\n","episode : 459, done reward : 5.0, total_step : 55444, cur_epsilon : 0.01\n","episode : 460, done reward : 12.0, total_step : 55627, cur_epsilon : 0.01\n","episode : 461, done reward : 0.0, total_step : 55677, cur_epsilon : 0.01\n","episode : 462, done reward : 4.0, total_step : 55771, cur_epsilon : 0.01\n","episode : 463, done reward : 5.0, total_step : 55884, cur_epsilon : 0.01\n","episode : 464, done reward : 5.0, total_step : 55989, cur_epsilon : 0.01\n","synced target net\n","episode : 465, done reward : 2.0, total_step : 56055, cur_epsilon : 0.01\n","episode : 466, done reward : 10.0, total_step : 56280, cur_epsilon : 0.01\n","episode : 467, done reward : 7.0, total_step : 56418, cur_epsilon : 0.01\n","episode : 468, done reward : 7.0, total_step : 56543, cur_epsilon : 0.01\n","episode : 469, done reward : 5.0, total_step : 56648, cur_epsilon : 0.01\n","episode : 470, done reward : 1.0, total_step : 56701, cur_epsilon : 0.01\n","episode : 471, done reward : 6.0, total_step : 56822, cur_epsilon : 0.01\n","episode : 472, done reward : 7.0, total_step : 56978, cur_epsilon : 0.01\n","synced target net\n","episode : 473, done reward : 8.0, total_step : 57198, cur_epsilon : 0.01\n","episode : 474, done reward : 10.0, total_step : 57445, cur_epsilon : 0.01\n","episode : 475, done reward : 6.0, total_step : 57559, cur_epsilon : 0.01\n","episode : 476, done reward : 7.0, total_step : 57711, cur_epsilon : 0.01\n","episode : 477, done reward : 6.0, total_step : 57837, cur_epsilon : 0.01\n","episode : 478, done reward : 6.0, total_step : 57962, cur_epsilon : 0.01\n","synced target net\n","episode : 479, done reward : 10.0, total_step : 58128, cur_epsilon : 0.01\n","episode : 480, done reward : 4.0, total_step : 58257, cur_epsilon : 0.01\n","episode : 481, done reward : 11.0, total_step : 58443, cur_epsilon : 0.01\n","episode : 482, done reward : 9.0, total_step : 58568, cur_epsilon : 0.01\n","episode : 483, done reward : 9.0, total_step : 58742, cur_epsilon : 0.01\n","episode : 484, done reward : 6.0, total_step : 58859, cur_epsilon : 0.01\n","synced target net\n","episode : 485, done reward : 11.0, total_step : 59006, cur_epsilon : 0.01\n","episode : 486, done reward : 3.0, total_step : 59090, cur_epsilon : 0.01\n","episode : 487, done reward : 3.0, total_step : 59169, cur_epsilon : 0.01\n","episode : 488, done reward : 7.0, total_step : 59294, cur_epsilon : 0.01\n","episode : 489, done reward : 7.0, total_step : 59456, cur_epsilon : 0.01\n","episode : 490, done reward : 7.0, total_step : 59597, cur_epsilon : 0.01\n","episode : 491, done reward : 12.0, total_step : 59790, cur_epsilon : 0.01\n","episode : 492, done reward : 8.0, total_step : 59937, cur_epsilon : 0.01\n","synced target net\n","episode : 493, done reward : 11.0, total_step : 60179, cur_epsilon : 0.01\n","episode : 494, done reward : 9.0, total_step : 60339, cur_epsilon : 0.01\n","episode : 495, done reward : 6.0, total_step : 60465, cur_epsilon : 0.01\n","episode : 496, done reward : 9.0, total_step : 60630, cur_epsilon : 0.01\n","episode : 497, done reward : 5.0, total_step : 60740, cur_epsilon : 0.01\n","episode : 498, done reward : 4.0, total_step : 60842, cur_epsilon : 0.01\n","episode : 499, done reward : 9.0, total_step : 60996, cur_epsilon : 0.01\n","synced target net\n","episode : 500, done reward : 7.0, total_step : 61165, cur_epsilon : 0.01\n","episode : 501, done reward : 11.0, total_step : 61418, cur_epsilon : 0.01\n","episode : 502, done reward : 9.0, total_step : 61570, cur_epsilon : 0.01\n","episode : 503, done reward : 4.0, total_step : 61667, cur_epsilon : 0.01\n","episode : 504, done reward : 8.0, total_step : 61866, cur_epsilon : 0.01\n","episode : 505, done reward : 5.0, total_step : 61976, cur_epsilon : 0.01\n","synced target net\n","episode : 506, done reward : 8.0, total_step : 62125, cur_epsilon : 0.01\n","episode : 507, done reward : 8.0, total_step : 62269, cur_epsilon : 0.01\n","episode : 508, done reward : 5.0, total_step : 62381, cur_epsilon : 0.01\n","episode : 509, done reward : 4.0, total_step : 62464, cur_epsilon : 0.01\n","episode : 510, done reward : 14.0, total_step : 62644, cur_epsilon : 0.01\n","episode : 511, done reward : 7.0, total_step : 62802, cur_epsilon : 0.01\n","episode : 512, done reward : 9.0, total_step : 62961, cur_epsilon : 0.01\n","synced target net\n","episode : 513, done reward : 10.0, total_step : 63145, cur_epsilon : 0.01\n","episode : 514, done reward : 7.0, total_step : 63275, cur_epsilon : 0.01\n","episode : 515, done reward : 11.0, total_step : 63441, cur_epsilon : 0.01\n","episode : 516, done reward : 10.0, total_step : 63621, cur_epsilon : 0.01\n","episode : 517, done reward : 4.0, total_step : 63716, cur_epsilon : 0.01\n","episode : 518, done reward : 7.0, total_step : 63843, cur_epsilon : 0.01\n","episode : 519, done reward : 2.0, total_step : 63920, cur_epsilon : 0.01\n","synced target net\n","episode : 520, done reward : 7.0, total_step : 64054, cur_epsilon : 0.01\n","episode : 521, done reward : 13.0, total_step : 64237, cur_epsilon : 0.01\n","episode : 522, done reward : 7.0, total_step : 64806, cur_epsilon : 0.01\n","episode : 523, done reward : 8.0, total_step : 64954, cur_epsilon : 0.01\n","synced target net\n","episode : 524, done reward : 7.0, total_step : 65098, cur_epsilon : 0.01\n","episode : 525, done reward : 5.0, total_step : 65230, cur_epsilon : 0.01\n","episode : 526, done reward : 7.0, total_step : 65424, cur_epsilon : 0.01\n","episode : 527, done reward : 6.0, total_step : 65563, cur_epsilon : 0.01\n","episode : 528, done reward : 5.0, total_step : 65674, cur_epsilon : 0.01\n","episode : 529, done reward : 9.0, total_step : 65840, cur_epsilon : 0.01\n","synced target net\n","episode : 530, done reward : 8.0, total_step : 66006, cur_epsilon : 0.01\n","episode : 531, done reward : 3.0, total_step : 66081, cur_epsilon : 0.01\n","episode : 532, done reward : 8.0, total_step : 66305, cur_epsilon : 0.01\n","episode : 533, done reward : 11.0, total_step : 66491, cur_epsilon : 0.01\n","episode : 534, done reward : 9.0, total_step : 66650, cur_epsilon : 0.01\n","episode : 535, done reward : 5.0, total_step : 66774, cur_epsilon : 0.01\n","episode : 536, done reward : 8.0, total_step : 66926, cur_epsilon : 0.01\n","synced target net\n","episode : 537, done reward : 6.0, total_step : 67047, cur_epsilon : 0.01\n","episode : 538, done reward : 7.0, total_step : 67206, cur_epsilon : 0.01\n","episode : 539, done reward : 2.0, total_step : 67269, cur_epsilon : 0.01\n","episode : 540, done reward : 8.0, total_step : 67411, cur_epsilon : 0.01\n","episode : 541, done reward : 5.0, total_step : 67526, cur_epsilon : 0.01\n","episode : 542, done reward : 8.0, total_step : 67634, cur_epsilon : 0.01\n","episode : 543, done reward : 5.0, total_step : 67734, cur_epsilon : 0.01\n","episode : 544, done reward : 7.0, total_step : 67871, cur_epsilon : 0.01\n","episode : 545, done reward : 6.0, total_step : 67995, cur_epsilon : 0.01\n","synced target net\n","episode : 546, done reward : 8.0, total_step : 68144, cur_epsilon : 0.01\n","episode : 547, done reward : 8.0, total_step : 68304, cur_epsilon : 0.01\n","episode : 548, done reward : 9.0, total_step : 68508, cur_epsilon : 0.01\n","episode : 549, done reward : 9.0, total_step : 68664, cur_epsilon : 0.01\n","episode : 550, done reward : 5.0, total_step : 68795, cur_epsilon : 0.01\n","episode : 551, done reward : 4.0, total_step : 68897, cur_epsilon : 0.01\n","synced target net\n","episode : 552, done reward : 6.0, total_step : 69016, cur_epsilon : 0.01\n","episode : 553, done reward : 7.0, total_step : 69144, cur_epsilon : 0.01\n","episode : 554, done reward : 8.0, total_step : 69288, cur_epsilon : 0.01\n","episode : 555, done reward : 7.0, total_step : 69432, cur_epsilon : 0.01\n","episode : 556, done reward : 9.0, total_step : 69605, cur_epsilon : 0.01\n","episode : 557, done reward : 5.0, total_step : 69721, cur_epsilon : 0.01\n","episode : 558, done reward : 8.0, total_step : 69859, cur_epsilon : 0.01\n","synced target net\n","episode : 559, done reward : 9.0, total_step : 70031, cur_epsilon : 0.01\n","episode : 560, done reward : 10.0, total_step : 70210, cur_epsilon : 0.01\n","episode : 561, done reward : 9.0, total_step : 70367, cur_epsilon : 0.01\n","episode : 562, done reward : 11.0, total_step : 70555, cur_epsilon : 0.01\n","episode : 563, done reward : 5.0, total_step : 70671, cur_epsilon : 0.01\n","episode : 564, done reward : 10.0, total_step : 70875, cur_epsilon : 0.01\n","synced target net\n","episode : 565, done reward : 6.0, total_step : 71002, cur_epsilon : 0.01\n","episode : 566, done reward : 6.0, total_step : 71231, cur_epsilon : 0.01\n","episode : 567, done reward : 5.0, total_step : 71339, cur_epsilon : 0.01\n","episode : 568, done reward : 8.0, total_step : 71486, cur_epsilon : 0.01\n","episode : 569, done reward : 9.0, total_step : 71642, cur_epsilon : 0.01\n","episode : 570, done reward : 4.0, total_step : 71742, cur_epsilon : 0.01\n","episode : 571, done reward : 9.0, total_step : 71921, cur_epsilon : 0.01\n","synced target net\n","episode : 572, done reward : 3.0, total_step : 72003, cur_epsilon : 0.01\n","episode : 573, done reward : 5.0, total_step : 72113, cur_epsilon : 0.01\n","episode : 574, done reward : 7.0, total_step : 72248, cur_epsilon : 0.01\n","episode : 575, done reward : 8.0, total_step : 72391, cur_epsilon : 0.01\n","episode : 576, done reward : 8.0, total_step : 72541, cur_epsilon : 0.01\n","episode : 577, done reward : 7.0, total_step : 72684, cur_epsilon : 0.01\n","episode : 578, done reward : 8.0, total_step : 72840, cur_epsilon : 0.01\n","episode : 579, done reward : 6.0, total_step : 72952, cur_epsilon : 0.01\n","synced target net\n","episode : 580, done reward : 16.0, total_step : 73148, cur_epsilon : 0.01\n","episode : 581, done reward : 7.0, total_step : 73279, cur_epsilon : 0.01\n","episode : 582, done reward : 16.0, total_step : 73477, cur_epsilon : 0.01\n","episode : 583, done reward : 9.0, total_step : 73644, cur_epsilon : 0.01\n","episode : 584, done reward : 9.0, total_step : 73805, cur_epsilon : 0.01\n","episode : 585, done reward : 8.0, total_step : 73960, cur_epsilon : 0.01\n","synced target net\n","episode : 586, done reward : 6.0, total_step : 74113, cur_epsilon : 0.01\n","episode : 587, done reward : 5.0, total_step : 74255, cur_epsilon : 0.01\n","episode : 588, done reward : 12.0, total_step : 74532, cur_epsilon : 0.01\n","episode : 589, done reward : 7.0, total_step : 74662, cur_epsilon : 0.01\n","episode : 590, done reward : 8.0, total_step : 74757, cur_epsilon : 0.01\n","episode : 591, done reward : 8.0, total_step : 74903, cur_epsilon : 0.01\n","synced target net\n","episode : 592, done reward : 8.0, total_step : 75039, cur_epsilon : 0.01\n","episode : 593, done reward : 14.0, total_step : 75250, cur_epsilon : 0.01\n","episode : 594, done reward : 8.0, total_step : 75384, cur_epsilon : 0.01\n","episode : 595, done reward : 4.0, total_step : 75486, cur_epsilon : 0.01\n","episode : 596, done reward : 5.0, total_step : 75615, cur_epsilon : 0.01\n","episode : 597, done reward : 12.0, total_step : 75817, cur_epsilon : 0.01\n","episode : 598, done reward : 6.0, total_step : 75939, cur_epsilon : 0.01\n","synced target net\n","episode : 599, done reward : 5.0, total_step : 76050, cur_epsilon : 0.01\n","episode : 600, done reward : 8.0, total_step : 76193, cur_epsilon : 0.01\n","episode : 601, done reward : 11.0, total_step : 76368, cur_epsilon : 0.01\n","episode : 602, done reward : 6.0, total_step : 76496, cur_epsilon : 0.01\n","episode : 603, done reward : 9.0, total_step : 76660, cur_epsilon : 0.01\n","episode : 604, done reward : 17.0, total_step : 76867, cur_epsilon : 0.01\n","synced target net\n","episode : 605, done reward : 8.0, total_step : 77010, cur_epsilon : 0.01\n","episode : 606, done reward : 6.0, total_step : 77132, cur_epsilon : 0.01\n","episode : 607, done reward : 11.0, total_step : 77290, cur_epsilon : 0.01\n","episode : 608, done reward : 7.0, total_step : 77427, cur_epsilon : 0.01\n","episode : 609, done reward : 6.0, total_step : 77542, cur_epsilon : 0.01\n","episode : 610, done reward : 6.0, total_step : 77668, cur_epsilon : 0.01\n","episode : 611, done reward : 9.0, total_step : 77855, cur_epsilon : 0.01\n","synced target net\n","episode : 612, done reward : 9.0, total_step : 78004, cur_epsilon : 0.01\n","episode : 613, done reward : 22.0, total_step : 78214, cur_epsilon : 0.01\n","episode : 614, done reward : 4.0, total_step : 78313, cur_epsilon : 0.01\n","episode : 615, done reward : 6.0, total_step : 78434, cur_epsilon : 0.01\n","episode : 616, done reward : 11.0, total_step : 78627, cur_epsilon : 0.01\n","episode : 617, done reward : 7.0, total_step : 78761, cur_epsilon : 0.01\n","episode : 618, done reward : 7.0, total_step : 78892, cur_epsilon : 0.01\n","synced target net\n","episode : 619, done reward : 9.0, total_step : 79056, cur_epsilon : 0.01\n","episode : 620, done reward : 7.0, total_step : 79193, cur_epsilon : 0.01\n","episode : 621, done reward : 8.0, total_step : 79334, cur_epsilon : 0.01\n","episode : 622, done reward : 10.0, total_step : 79562, cur_epsilon : 0.01\n","episode : 623, done reward : 7.0, total_step : 79688, cur_epsilon : 0.01\n","episode : 624, done reward : 12.0, total_step : 79844, cur_epsilon : 0.01\n","episode : 625, done reward : 8.0, total_step : 79992, cur_epsilon : 0.01\n","synced target net\n","episode : 626, done reward : 5.0, total_step : 80105, cur_epsilon : 0.01\n","episode : 627, done reward : 10.0, total_step : 80318, cur_epsilon : 0.01\n","episode : 628, done reward : 8.0, total_step : 80467, cur_epsilon : 0.01\n","episode : 629, done reward : 8.0, total_step : 80620, cur_epsilon : 0.01\n","episode : 630, done reward : 7.0, total_step : 80748, cur_epsilon : 0.01\n","episode : 631, done reward : 4.0, total_step : 80832, cur_epsilon : 0.01\n","synced target net\n","episode : 632, done reward : 17.0, total_step : 81043, cur_epsilon : 0.01\n","episode : 633, done reward : 10.0, total_step : 81196, cur_epsilon : 0.01\n","episode : 634, done reward : 7.0, total_step : 81311, cur_epsilon : 0.01\n","episode : 635, done reward : 6.0, total_step : 81444, cur_epsilon : 0.01\n","episode : 636, done reward : 9.0, total_step : 81624, cur_epsilon : 0.01\n","episode : 637, done reward : 3.0, total_step : 81708, cur_epsilon : 0.01\n","episode : 638, done reward : 12.0, total_step : 81900, cur_epsilon : 0.01\n","synced target net\n","episode : 639, done reward : 9.0, total_step : 82062, cur_epsilon : 0.01\n","episode : 640, done reward : 7.0, total_step : 82186, cur_epsilon : 0.01\n","episode : 641, done reward : 4.0, total_step : 82281, cur_epsilon : 0.01\n","episode : 642, done reward : 9.0, total_step : 82442, cur_epsilon : 0.01\n","episode : 643, done reward : 8.0, total_step : 82586, cur_epsilon : 0.01\n","episode : 644, done reward : 13.0, total_step : 82764, cur_epsilon : 0.01\n","episode : 645, done reward : 10.0, total_step : 82923, cur_epsilon : 0.01\n","synced target net\n","episode : 646, done reward : 9.0, total_step : 83084, cur_epsilon : 0.01\n","episode : 647, done reward : 6.0, total_step : 83223, cur_epsilon : 0.01\n","episode : 648, done reward : 15.0, total_step : 83433, cur_epsilon : 0.01\n","episode : 649, done reward : 10.0, total_step : 83602, cur_epsilon : 0.01\n","episode : 650, done reward : 14.0, total_step : 83784, cur_epsilon : 0.01\n","episode : 651, done reward : 9.0, total_step : 83934, cur_epsilon : 0.01\n","synced target net\n","episode : 652, done reward : 9.0, total_step : 84093, cur_epsilon : 0.01\n","episode : 653, done reward : 3.0, total_step : 84172, cur_epsilon : 0.01\n","episode : 654, done reward : 4.0, total_step : 84270, cur_epsilon : 0.01\n","episode : 655, done reward : 4.0, total_step : 84360, cur_epsilon : 0.01\n","episode : 656, done reward : 8.0, total_step : 84512, cur_epsilon : 0.01\n","episode : 657, done reward : 7.0, total_step : 84639, cur_epsilon : 0.01\n","episode : 658, done reward : 7.0, total_step : 84778, cur_epsilon : 0.01\n","episode : 659, done reward : 8.0, total_step : 84923, cur_epsilon : 0.01\n","synced target net\n","episode : 660, done reward : 8.0, total_step : 85080, cur_epsilon : 0.01\n","episode : 661, done reward : 11.0, total_step : 85265, cur_epsilon : 0.01\n","episode : 662, done reward : 9.0, total_step : 85414, cur_epsilon : 0.01\n","episode : 663, done reward : 12.0, total_step : 85610, cur_epsilon : 0.01\n","episode : 664, done reward : 7.0, total_step : 85757, cur_epsilon : 0.01\n","episode : 665, done reward : 9.0, total_step : 85922, cur_epsilon : 0.01\n","synced target net\n","episode : 666, done reward : 9.0, total_step : 86089, cur_epsilon : 0.01\n","episode : 667, done reward : 7.0, total_step : 86232, cur_epsilon : 0.01\n","episode : 668, done reward : 7.0, total_step : 86355, cur_epsilon : 0.01\n","episode : 669, done reward : 5.0, total_step : 86454, cur_epsilon : 0.01\n","episode : 670, done reward : 11.0, total_step : 86633, cur_epsilon : 0.01\n","episode : 671, done reward : 5.0, total_step : 86743, cur_epsilon : 0.01\n","episode : 672, done reward : 7.0, total_step : 86873, cur_epsilon : 0.01\n","synced target net\n","episode : 673, done reward : 9.0, total_step : 87024, cur_epsilon : 0.01\n","episode : 674, done reward : 4.0, total_step : 87114, cur_epsilon : 0.01\n","episode : 675, done reward : 6.0, total_step : 87232, cur_epsilon : 0.01\n","episode : 676, done reward : 15.0, total_step : 87472, cur_epsilon : 0.01\n","episode : 677, done reward : 8.0, total_step : 87576, cur_epsilon : 0.01\n","episode : 678, done reward : 5.0, total_step : 87699, cur_epsilon : 0.01\n","episode : 679, done reward : 4.0, total_step : 87797, cur_epsilon : 0.01\n","episode : 680, done reward : 5.0, total_step : 87906, cur_epsilon : 0.01\n","synced target net\n","episode : 681, done reward : 8.0, total_step : 88061, cur_epsilon : 0.01\n","episode : 682, done reward : 7.0, total_step : 88197, cur_epsilon : 0.01\n","episode : 683, done reward : 5.0, total_step : 88295, cur_epsilon : 0.01\n","episode : 684, done reward : 4.0, total_step : 88391, cur_epsilon : 0.01\n","episode : 685, done reward : 8.0, total_step : 88534, cur_epsilon : 0.01\n","episode : 686, done reward : 5.0, total_step : 88636, cur_epsilon : 0.01\n","episode : 687, done reward : 5.0, total_step : 88746, cur_epsilon : 0.01\n","episode : 688, done reward : 7.0, total_step : 88885, cur_epsilon : 0.01\n","synced target net\n","episode : 689, done reward : 9.0, total_step : 89039, cur_epsilon : 0.01\n","episode : 690, done reward : 8.0, total_step : 89174, cur_epsilon : 0.01\n","episode : 691, done reward : 3.0, total_step : 89248, cur_epsilon : 0.01\n","episode : 692, done reward : 8.0, total_step : 89387, cur_epsilon : 0.01\n","episode : 693, done reward : 11.0, total_step : 89576, cur_epsilon : 0.01\n","episode : 694, done reward : 7.0, total_step : 89702, cur_epsilon : 0.01\n","episode : 695, done reward : 11.0, total_step : 89882, cur_epsilon : 0.01\n","synced target net\n","episode : 696, done reward : 8.0, total_step : 90042, cur_epsilon : 0.01\n","episode : 697, done reward : 9.0, total_step : 90208, cur_epsilon : 0.01\n","episode : 698, done reward : 7.0, total_step : 90339, cur_epsilon : 0.01\n","episode : 699, done reward : 7.0, total_step : 90454, cur_epsilon : 0.01\n","episode : 700, done reward : 4.0, total_step : 90550, cur_epsilon : 0.01\n","episode : 701, done reward : 14.0, total_step : 90732, cur_epsilon : 0.01\n","episode : 702, done reward : 7.0, total_step : 90887, cur_epsilon : 0.01\n","synced target net\n","episode : 703, done reward : 8.0, total_step : 91032, cur_epsilon : 0.01\n","episode : 704, done reward : 6.0, total_step : 91152, cur_epsilon : 0.01\n","episode : 705, done reward : 8.0, total_step : 91290, cur_epsilon : 0.01\n","episode : 706, done reward : 3.0, total_step : 91373, cur_epsilon : 0.01\n","episode : 707, done reward : 3.0, total_step : 91455, cur_epsilon : 0.01\n","episode : 708, done reward : 8.0, total_step : 91609, cur_epsilon : 0.01\n","episode : 709, done reward : 14.0, total_step : 91888, cur_epsilon : 0.01\n","synced target net\n","episode : 710, done reward : 12.0, total_step : 92095, cur_epsilon : 0.01\n","episode : 711, done reward : 8.0, total_step : 92242, cur_epsilon : 0.01\n","episode : 712, done reward : 3.0, total_step : 92318, cur_epsilon : 0.01\n","episode : 713, done reward : 8.0, total_step : 92473, cur_epsilon : 0.01\n","episode : 714, done reward : 7.0, total_step : 92601, cur_epsilon : 0.01\n","episode : 715, done reward : 6.0, total_step : 92715, cur_epsilon : 0.01\n","episode : 716, done reward : 14.0, total_step : 92915, cur_epsilon : 0.01\n","synced target net\n","episode : 717, done reward : 5.0, total_step : 93019, cur_epsilon : 0.01\n","episode : 718, done reward : 13.0, total_step : 93187, cur_epsilon : 0.01\n","episode : 719, done reward : 3.0, total_step : 93262, cur_epsilon : 0.01\n","episode : 720, done reward : 12.0, total_step : 93437, cur_epsilon : 0.01\n","episode : 721, done reward : 2.0, total_step : 93514, cur_epsilon : 0.01\n","episode : 722, done reward : 9.0, total_step : 93671, cur_epsilon : 0.01\n","episode : 723, done reward : 9.0, total_step : 93836, cur_epsilon : 0.01\n","episode : 724, done reward : 3.0, total_step : 93916, cur_epsilon : 0.01\n","synced target net\n","episode : 725, done reward : 13.0, total_step : 94098, cur_epsilon : 0.01\n","episode : 726, done reward : 8.0, total_step : 94261, cur_epsilon : 0.01\n","episode : 727, done reward : 9.0, total_step : 94421, cur_epsilon : 0.01\n","episode : 728, done reward : 8.0, total_step : 94555, cur_epsilon : 0.01\n","episode : 729, done reward : 8.0, total_step : 94704, cur_epsilon : 0.01\n","episode : 730, done reward : 9.0, total_step : 94880, cur_epsilon : 0.01\n","synced target net\n","episode : 731, done reward : 7.0, total_step : 95016, cur_epsilon : 0.01\n","episode : 732, done reward : 15.0, total_step : 95224, cur_epsilon : 0.01\n","episode : 733, done reward : 9.0, total_step : 95388, cur_epsilon : 0.01\n","episode : 734, done reward : 15.0, total_step : 95593, cur_epsilon : 0.01\n","episode : 735, done reward : 10.0, total_step : 95763, cur_epsilon : 0.01\n","episode : 736, done reward : 6.0, total_step : 95886, cur_epsilon : 0.01\n","episode : 737, done reward : 3.0, total_step : 95965, cur_epsilon : 0.01\n","synced target net\n","episode : 738, done reward : 5.0, total_step : 96075, cur_epsilon : 0.01\n","episode : 739, done reward : 10.0, total_step : 96244, cur_epsilon : 0.01\n","episode : 740, done reward : 6.0, total_step : 96372, cur_epsilon : 0.01\n","episode : 741, done reward : 7.0, total_step : 96499, cur_epsilon : 0.01\n","episode : 742, done reward : 5.0, total_step : 96607, cur_epsilon : 0.01\n","episode : 743, done reward : 8.0, total_step : 96759, cur_epsilon : 0.01\n","episode : 744, done reward : 8.0, total_step : 96912, cur_epsilon : 0.01\n","synced target net\n","episode : 745, done reward : 8.0, total_step : 97072, cur_epsilon : 0.01\n","episode : 746, done reward : 6.0, total_step : 97183, cur_epsilon : 0.01\n","episode : 747, done reward : 6.0, total_step : 97301, cur_epsilon : 0.01\n","episode : 748, done reward : 6.0, total_step : 97436, cur_epsilon : 0.01\n","episode : 749, done reward : 6.0, total_step : 97565, cur_epsilon : 0.01\n","episode : 750, done reward : 8.0, total_step : 97710, cur_epsilon : 0.01\n","episode : 751, done reward : 13.0, total_step : 97885, cur_epsilon : 0.01\n","synced target net\n","episode : 752, done reward : 6.0, total_step : 98013, cur_epsilon : 0.01\n","episode : 753, done reward : 4.0, total_step : 98100, cur_epsilon : 0.01\n","episode : 754, done reward : 7.0, total_step : 98227, cur_epsilon : 0.01\n","episode : 755, done reward : 3.0, total_step : 98304, cur_epsilon : 0.01\n","episode : 756, done reward : 8.0, total_step : 98400, cur_epsilon : 0.01\n","episode : 757, done reward : 13.0, total_step : 98549, cur_epsilon : 0.01\n","episode : 758, done reward : 9.0, total_step : 98697, cur_epsilon : 0.01\n","episode : 759, done reward : 7.0, total_step : 98818, cur_epsilon : 0.01\n","synced target net\n","episode : 760, done reward : 12.0, total_step : 99016, cur_epsilon : 0.01\n","episode : 761, done reward : 5.0, total_step : 99126, cur_epsilon : 0.01\n","episode : 762, done reward : 9.0, total_step : 99280, cur_epsilon : 0.01\n","episode : 763, done reward : 7.0, total_step : 99410, cur_epsilon : 0.01\n","episode : 764, done reward : 9.0, total_step : 99578, cur_epsilon : 0.01\n","episode : 765, done reward : 10.0, total_step : 99737, cur_epsilon : 0.01\n","episode : 766, done reward : 10.0, total_step : 99920, cur_epsilon : 0.01\n","synced target net\n","episode : 767, done reward : 3.0, total_step : 100002, cur_epsilon : 0.01\n","episode : 768, done reward : 11.0, total_step : 100193, cur_epsilon : 0.01\n","episode : 769, done reward : 10.0, total_step : 100366, cur_epsilon : 0.01\n","episode : 770, done reward : 6.0, total_step : 100482, cur_epsilon : 0.01\n","episode : 771, done reward : 4.0, total_step : 100575, cur_epsilon : 0.01\n","episode : 772, done reward : 7.0, total_step : 100797, cur_epsilon : 0.01\n","episode : 773, done reward : 8.0, total_step : 100945, cur_epsilon : 0.01\n","synced target net\n","episode : 774, done reward : 11.0, total_step : 101144, cur_epsilon : 0.01\n","episode : 775, done reward : 11.0, total_step : 101323, cur_epsilon : 0.01\n","episode : 776, done reward : 8.0, total_step : 101476, cur_epsilon : 0.01\n","episode : 777, done reward : 5.0, total_step : 101580, cur_epsilon : 0.01\n","episode : 778, done reward : 7.0, total_step : 101719, cur_epsilon : 0.01\n","episode : 779, done reward : 11.0, total_step : 101935, cur_epsilon : 0.01\n","synced target net\n","episode : 780, done reward : 9.0, total_step : 102351, cur_epsilon : 0.01\n","episode : 781, done reward : 7.0, total_step : 102871, cur_epsilon : 0.01\n","synced target net\n","episode : 782, done reward : 11.0, total_step : 103062, cur_epsilon : 0.01\n","episode : 783, done reward : 11.0, total_step : 103232, cur_epsilon : 0.01\n","episode : 784, done reward : 15.0, total_step : 103417, cur_epsilon : 0.01\n","episode : 785, done reward : 6.0, total_step : 103552, cur_epsilon : 0.01\n","episode : 786, done reward : 4.0, total_step : 103652, cur_epsilon : 0.01\n","episode : 787, done reward : 8.0, total_step : 103812, cur_epsilon : 0.01\n","episode : 788, done reward : 8.0, total_step : 103951, cur_epsilon : 0.01\n","synced target net\n","episode : 789, done reward : 7.0, total_step : 104077, cur_epsilon : 0.01\n","episode : 790, done reward : 9.0, total_step : 104231, cur_epsilon : 0.01\n","episode : 791, done reward : 10.0, total_step : 104393, cur_epsilon : 0.01\n","episode : 792, done reward : 6.0, total_step : 104506, cur_epsilon : 0.01\n","episode : 793, done reward : 5.0, total_step : 104722, cur_epsilon : 0.01\n","episode : 794, done reward : 9.0, total_step : 104889, cur_epsilon : 0.01\n","synced target net\n","episode : 795, done reward : 26.0, total_step : 105097, cur_epsilon : 0.01\n","episode : 796, done reward : 10.0, total_step : 105280, cur_epsilon : 0.01\n","episode : 797, done reward : 5.0, total_step : 105388, cur_epsilon : 0.01\n","episode : 798, done reward : 7.0, total_step : 105532, cur_epsilon : 0.01\n","episode : 799, done reward : 14.0, total_step : 105758, cur_epsilon : 0.01\n","episode : 800, done reward : 14.0, total_step : 105945, cur_epsilon : 0.01\n","synced target net\n","episode : 801, done reward : 11.0, total_step : 106367, cur_epsilon : 0.01\n","episode : 802, done reward : 6.0, total_step : 106488, cur_epsilon : 0.01\n","episode : 803, done reward : 11.0, total_step : 106673, cur_epsilon : 0.01\n","episode : 804, done reward : 2.0, total_step : 106734, cur_epsilon : 0.01\n","episode : 805, done reward : 10.0, total_step : 106895, cur_epsilon : 0.01\n","synced target net\n","episode : 806, done reward : 7.0, total_step : 107021, cur_epsilon : 0.01\n","episode : 807, done reward : 9.0, total_step : 107187, cur_epsilon : 0.01\n","episode : 808, done reward : 9.0, total_step : 107346, cur_epsilon : 0.01\n","episode : 809, done reward : 6.0, total_step : 107472, cur_epsilon : 0.01\n","episode : 810, done reward : 8.0, total_step : 107642, cur_epsilon : 0.01\n","episode : 811, done reward : 7.0, total_step : 107774, cur_epsilon : 0.01\n","episode : 812, done reward : 9.0, total_step : 107927, cur_epsilon : 0.01\n","synced target net\n","episode : 813, done reward : 9.0, total_step : 108085, cur_epsilon : 0.01\n","episode : 814, done reward : 14.0, total_step : 108272, cur_epsilon : 0.01\n","episode : 815, done reward : 5.0, total_step : 108390, cur_epsilon : 0.01\n","episode : 816, done reward : 15.0, total_step : 108585, cur_epsilon : 0.01\n","episode : 817, done reward : 11.0, total_step : 108897, cur_epsilon : 0.01\n","episode : 818, done reward : 4.0, total_step : 108991, cur_epsilon : 0.01\n","synced target net\n","episode : 819, done reward : 7.0, total_step : 109115, cur_epsilon : 0.01\n","episode : 820, done reward : 11.0, total_step : 109288, cur_epsilon : 0.01\n","episode : 821, done reward : 8.0, total_step : 109390, cur_epsilon : 0.01\n","episode : 822, done reward : 14.0, total_step : 109576, cur_epsilon : 0.01\n","episode : 823, done reward : 11.0, total_step : 109757, cur_epsilon : 0.01\n","episode : 824, done reward : 6.0, total_step : 109893, cur_epsilon : 0.01\n","episode : 825, done reward : 4.0, total_step : 109989, cur_epsilon : 0.01\n","synced target net\n","episode : 826, done reward : 11.0, total_step : 110161, cur_epsilon : 0.01\n","episode : 827, done reward : 7.0, total_step : 110311, cur_epsilon : 0.01\n","episode : 828, done reward : 7.0, total_step : 110446, cur_epsilon : 0.01\n","episode : 829, done reward : 4.0, total_step : 110540, cur_epsilon : 0.01\n","episode : 830, done reward : 8.0, total_step : 110687, cur_epsilon : 0.01\n","episode : 831, done reward : 8.0, total_step : 110832, cur_epsilon : 0.01\n","episode : 832, done reward : 3.0, total_step : 110930, cur_epsilon : 0.01\n","synced target net\n","episode : 833, done reward : 9.0, total_step : 111078, cur_epsilon : 0.01\n","episode : 834, done reward : 5.0, total_step : 111193, cur_epsilon : 0.01\n","episode : 835, done reward : 8.0, total_step : 111341, cur_epsilon : 0.01\n","episode : 836, done reward : 7.0, total_step : 111464, cur_epsilon : 0.01\n","episode : 837, done reward : 6.0, total_step : 111652, cur_epsilon : 0.01\n","episode : 838, done reward : 6.0, total_step : 111774, cur_epsilon : 0.01\n","episode : 839, done reward : 5.0, total_step : 111913, cur_epsilon : 0.01\n","synced target net\n","episode : 840, done reward : 7.0, total_step : 112054, cur_epsilon : 0.01\n","episode : 841, done reward : 12.0, total_step : 112227, cur_epsilon : 0.01\n","episode : 842, done reward : 10.0, total_step : 112394, cur_epsilon : 0.01\n","episode : 843, done reward : 3.0, total_step : 112473, cur_epsilon : 0.01\n","episode : 844, done reward : 9.0, total_step : 112661, cur_epsilon : 0.01\n","episode : 845, done reward : 8.0, total_step : 112851, cur_epsilon : 0.01\n","episode : 846, done reward : 7.0, total_step : 112944, cur_epsilon : 0.01\n","synced target net\n","episode : 847, done reward : 15.0, total_step : 113144, cur_epsilon : 0.01\n","episode : 848, done reward : 11.0, total_step : 113328, cur_epsilon : 0.01\n","episode : 849, done reward : 5.0, total_step : 113426, cur_epsilon : 0.01\n","episode : 850, done reward : 9.0, total_step : 113593, cur_epsilon : 0.01\n","episode : 851, done reward : 10.0, total_step : 113767, cur_epsilon : 0.01\n","episode : 852, done reward : 5.0, total_step : 113897, cur_epsilon : 0.01\n","synced target net\n","episode : 853, done reward : 9.0, total_step : 114061, cur_epsilon : 0.01\n","episode : 854, done reward : 6.0, total_step : 114202, cur_epsilon : 0.01\n","episode : 855, done reward : 6.0, total_step : 114344, cur_epsilon : 0.01\n","episode : 856, done reward : 9.0, total_step : 114492, cur_epsilon : 0.01\n","episode : 857, done reward : 5.0, total_step : 114600, cur_epsilon : 0.01\n","episode : 858, done reward : 7.0, total_step : 114735, cur_epsilon : 0.01\n","episode : 859, done reward : 7.0, total_step : 114868, cur_epsilon : 0.01\n","synced target net\n","episode : 860, done reward : 10.0, total_step : 115055, cur_epsilon : 0.01\n","episode : 861, done reward : 8.0, total_step : 115194, cur_epsilon : 0.01\n","episode : 862, done reward : 8.0, total_step : 115339, cur_epsilon : 0.01\n","episode : 863, done reward : 7.0, total_step : 115476, cur_epsilon : 0.01\n","episode : 864, done reward : 5.0, total_step : 115580, cur_epsilon : 0.01\n","episode : 865, done reward : 10.0, total_step : 115749, cur_epsilon : 0.01\n","episode : 866, done reward : 11.0, total_step : 115949, cur_epsilon : 0.01\n","synced target net\n","episode : 867, done reward : 13.0, total_step : 116152, cur_epsilon : 0.01\n","episode : 868, done reward : 8.0, total_step : 116304, cur_epsilon : 0.01\n","episode : 869, done reward : 7.0, total_step : 116453, cur_epsilon : 0.01\n","episode : 870, done reward : 11.0, total_step : 116638, cur_epsilon : 0.01\n","episode : 871, done reward : 3.0, total_step : 116713, cur_epsilon : 0.01\n","episode : 872, done reward : 9.0, total_step : 116920, cur_epsilon : 0.01\n","synced target net\n","episode : 873, done reward : 7.0, total_step : 117062, cur_epsilon : 0.01\n","episode : 874, done reward : 11.0, total_step : 117247, cur_epsilon : 0.01\n","episode : 875, done reward : 10.0, total_step : 117415, cur_epsilon : 0.01\n"]}]},{"cell_type":"code","source":["# env = gym.make(\"Breakout-v0\")\n","# env = SkipFrame(env, skip=4)\n","# env = GrayScaleObservation(env)\n","# env = ResizeObservation(env, shape=84)\n","# env = FrameStack(env, num_stack=4)\n","# env = LazyFramesToNumpy(env)\n","# exp_buffer = NStepPriorityReplayBuffer(\n","#     max_size=30000,\n","#     prob_alpha=0.6,\n","#     beta_start=0.4,\n","#     beta_frames=20000, #100000,\n","#     n_step=4,\n","#     gamma=0.99,\n","# )\n","# agent = Agent(\n","#     env=env,\n","#     exp_buffer=exp_buffer,\n","#     net=net,\n","#     epsilon_start=0.5,\n","#     epsilon_final=0.01,\n","#     epsilon_decay_last_step=20000, #200000,\n","#     tgt_sync_steps=1000,\n","#     learning_rate=1e-4,\n","#     device=device\n","# )\n","\n","episode = 0\n","\n","while True:\n","\n","    for stp in range(100):\n","        done_reward = agent.play_step()\n","        if done_reward is not None:\n","            print(f'episode : {episode}, done reward : {done_reward}, total_step : {agent._total_step}, cur_epsilon : {agent._epsilon}')\n","            episode += 1\n","    \n","    agent.train(n_iter=100, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_pdG4a3ZtRup","executionInfo":{"status":"error","timestamp":1670779423065,"user_tz":-540,"elapsed":2156641,"user":{"displayName":"Yoshihiro Matsumoto","userId":"05765613951479945662"}},"outputId":"94db17ba-a038-4be7-e7ed-25ce8cfe457a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["episode : 0, done reward : 0.0, total_step : 12, cur_epsilon : 0.4994\n","episode : 1, done reward : 0.0, total_step : 55, cur_epsilon : 0.49725\n","episode : 2, done reward : 2.0, total_step : 119, cur_epsilon : 0.49405\n","episode : 3, done reward : 2.0, total_step : 185, cur_epsilon : 0.49075\n","episode : 4, done reward : 0.0, total_step : 241, cur_epsilon : 0.48795\n","episode : 5, done reward : 3.0, total_step : 333, cur_epsilon : 0.48335\n","episode : 6, done reward : 1.0, total_step : 387, cur_epsilon : 0.48065\n","episode : 7, done reward : 3.0, total_step : 478, cur_epsilon : 0.4761\n","episode : 8, done reward : 2.0, total_step : 561, cur_epsilon : 0.47195\n","episode : 9, done reward : 2.0, total_step : 666, cur_epsilon : 0.4667\n","episode : 10, done reward : 3.0, total_step : 763, cur_epsilon : 0.46185\n","episode : 11, done reward : 3.0, total_step : 873, cur_epsilon : 0.45635\n","episode : 12, done reward : 0.0, total_step : 941, cur_epsilon : 0.45295\n","synced target net\n","episode : 13, done reward : 2.0, total_step : 1078, cur_epsilon : 0.4461\n","episode : 14, done reward : 0.0, total_step : 1145, cur_epsilon : 0.44275\n","episode : 15, done reward : 0.0, total_step : 1212, cur_epsilon : 0.4394\n","episode : 16, done reward : 0.0, total_step : 1267, cur_epsilon : 0.43665\n","episode : 17, done reward : 1.0, total_step : 1326, cur_epsilon : 0.4337\n","episode : 18, done reward : 0.0, total_step : 1368, cur_epsilon : 0.4316\n","episode : 19, done reward : 1.0, total_step : 1427, cur_epsilon : 0.42865\n","episode : 20, done reward : 3.0, total_step : 1544, cur_epsilon : 0.4228\n","episode : 21, done reward : 1.0, total_step : 1605, cur_epsilon : 0.41975\n","episode : 22, done reward : 3.0, total_step : 1687, cur_epsilon : 0.41565\n","episode : 23, done reward : 0.0, total_step : 1735, cur_epsilon : 0.41325\n","episode : 24, done reward : 2.0, total_step : 1856, cur_epsilon : 0.4072\n","episode : 25, done reward : 1.0, total_step : 1956, cur_epsilon : 0.4022\n","synced target net\n","episode : 26, done reward : 0.0, total_step : 2027, cur_epsilon : 0.39865\n","episode : 27, done reward : 2.0, total_step : 2142, cur_epsilon : 0.3929\n","episode : 28, done reward : 0.0, total_step : 2184, cur_epsilon : 0.3908\n","episode : 29, done reward : 0.0, total_step : 2237, cur_epsilon : 0.38815\n","episode : 30, done reward : 0.0, total_step : 2298, cur_epsilon : 0.3851\n","episode : 31, done reward : 1.0, total_step : 2422, cur_epsilon : 0.3789\n","episode : 32, done reward : 0.0, total_step : 2470, cur_epsilon : 0.3765\n","episode : 33, done reward : 2.0, total_step : 2537, cur_epsilon : 0.37315\n","episode : 34, done reward : 2.0, total_step : 2610, cur_epsilon : 0.3695\n","episode : 35, done reward : 0.0, total_step : 2682, cur_epsilon : 0.3659\n","episode : 36, done reward : 1.0, total_step : 2768, cur_epsilon : 0.36160000000000003\n","episode : 37, done reward : 0.0, total_step : 2823, cur_epsilon : 0.35885\n","episode : 38, done reward : 4.0, total_step : 2961, cur_epsilon : 0.35195\n","synced target net\n","episode : 39, done reward : 2.0, total_step : 3035, cur_epsilon : 0.34825\n","episode : 40, done reward : 1.0, total_step : 3102, cur_epsilon : 0.3449\n","episode : 41, done reward : 4.0, total_step : 3215, cur_epsilon : 0.33925\n","episode : 42, done reward : 1.0, total_step : 3292, cur_epsilon : 0.33540000000000003\n","episode : 43, done reward : 1.0, total_step : 3359, cur_epsilon : 0.33205\n","episode : 44, done reward : 3.0, total_step : 3459, cur_epsilon : 0.32705\n","episode : 45, done reward : 2.0, total_step : 3532, cur_epsilon : 0.3234\n","episode : 46, done reward : 3.0, total_step : 3641, cur_epsilon : 0.31795\n","episode : 47, done reward : 1.0, total_step : 3762, cur_epsilon : 0.3119\n","episode : 48, done reward : 1.0, total_step : 3907, cur_epsilon : 0.30465\n","episode : 49, done reward : 0.0, total_step : 3999, cur_epsilon : 0.30005000000000004\n","synced target net\n","episode : 50, done reward : 3.0, total_step : 4097, cur_epsilon : 0.29515\n","episode : 51, done reward : 1.0, total_step : 4163, cur_epsilon : 0.29185\n","episode : 52, done reward : 5.0, total_step : 4309, cur_epsilon : 0.28454999999999997\n","episode : 53, done reward : 4.0, total_step : 4412, cur_epsilon : 0.2794\n","episode : 54, done reward : 4.0, total_step : 4507, cur_epsilon : 0.27465\n","episode : 55, done reward : 4.0, total_step : 4598, cur_epsilon : 0.2701\n","episode : 56, done reward : 2.0, total_step : 4665, cur_epsilon : 0.26675\n","episode : 57, done reward : 4.0, total_step : 4764, cur_epsilon : 0.26180000000000003\n","episode : 58, done reward : 3.0, total_step : 4847, cur_epsilon : 0.25765\n","synced target net\n","episode : 59, done reward : 7.0, total_step : 5008, cur_epsilon : 0.2496\n","episode : 60, done reward : 2.0, total_step : 5070, cur_epsilon : 0.2465\n","episode : 61, done reward : 3.0, total_step : 5147, cur_epsilon : 0.24264999999999998\n","episode : 62, done reward : 6.0, total_step : 5270, cur_epsilon : 0.2365\n","episode : 63, done reward : 1.0, total_step : 5322, cur_epsilon : 0.2339\n","episode : 64, done reward : 8.0, total_step : 5433, cur_epsilon : 0.22835\n","episode : 65, done reward : 4.0, total_step : 5533, cur_epsilon : 0.22335\n","episode : 66, done reward : 5.0, total_step : 5649, cur_epsilon : 0.21755000000000002\n","episode : 67, done reward : 6.0, total_step : 5762, cur_epsilon : 0.21189999999999998\n","episode : 68, done reward : 7.0, total_step : 5896, cur_epsilon : 0.2052\n","synced target net\n","episode : 69, done reward : 8.0, total_step : 6030, cur_epsilon : 0.1985\n","episode : 70, done reward : 3.0, total_step : 6106, cur_epsilon : 0.19469999999999998\n","episode : 71, done reward : 8.0, total_step : 6249, cur_epsilon : 0.18755\n","episode : 72, done reward : 4.0, total_step : 6343, cur_epsilon : 0.18285\n","episode : 73, done reward : 4.0, total_step : 6435, cur_epsilon : 0.17825000000000002\n","episode : 74, done reward : 5.0, total_step : 6539, cur_epsilon : 0.17304999999999998\n","episode : 75, done reward : 4.0, total_step : 6626, cur_epsilon : 0.16870000000000002\n","episode : 76, done reward : 7.0, total_step : 6747, cur_epsilon : 0.16265000000000002\n","episode : 77, done reward : 6.0, total_step : 6856, cur_epsilon : 0.1572\n","episode : 78, done reward : 5.0, total_step : 6986, cur_epsilon : 0.1507\n","synced target net\n","episode : 79, done reward : 5.0, total_step : 7103, cur_epsilon : 0.14484999999999998\n","episode : 80, done reward : 2.0, total_step : 7173, cur_epsilon : 0.14134999999999998\n","episode : 81, done reward : 8.0, total_step : 7311, cur_epsilon : 0.13445000000000001\n","episode : 82, done reward : 10.0, total_step : 7489, cur_epsilon : 0.12555\n","episode : 83, done reward : 8.0, total_step : 7683, cur_epsilon : 0.11585000000000001\n","episode : 84, done reward : 5.0, total_step : 7835, cur_epsilon : 0.10825000000000001\n","episode : 85, done reward : 4.0, total_step : 7928, cur_epsilon : 0.10360000000000003\n","synced target net\n","episode : 86, done reward : 3.0, total_step : 8000, cur_epsilon : 0.09999999999999998\n","episode : 87, done reward : 5.0, total_step : 8107, cur_epsilon : 0.09465000000000001\n","episode : 88, done reward : 5.0, total_step : 8211, cur_epsilon : 0.08944999999999997\n","episode : 89, done reward : 7.0, total_step : 8347, cur_epsilon : 0.08265\n","episode : 90, done reward : 6.0, total_step : 8462, cur_epsilon : 0.07690000000000002\n","episode : 91, done reward : 8.0, total_step : 8606, cur_epsilon : 0.06969999999999998\n","episode : 92, done reward : 8.0, total_step : 8920, cur_epsilon : 0.05399999999999999\n","synced target net\n","episode : 93, done reward : 4.0, total_step : 9003, cur_epsilon : 0.049850000000000005\n","episode : 94, done reward : 9.0, total_step : 9161, cur_epsilon : 0.04194999999999999\n","episode : 95, done reward : 4.0, total_step : 9264, cur_epsilon : 0.0368\n","episode : 96, done reward : 9.0, total_step : 9427, cur_epsilon : 0.02865000000000001\n","episode : 97, done reward : 6.0, total_step : 9547, cur_epsilon : 0.022650000000000003\n","episode : 98, done reward : 3.0, total_step : 9617, cur_epsilon : 0.01915\n","episode : 99, done reward : 8.0, total_step : 9767, cur_epsilon : 0.011649999999999994\n","episode : 100, done reward : 3.0, total_step : 9840, cur_epsilon : 0.01\n","episode : 101, done reward : 7.0, total_step : 9969, cur_epsilon : 0.01\n","synced target net\n","episode : 102, done reward : 3.0, total_step : 10041, cur_epsilon : 0.01\n","episode : 103, done reward : 4.0, total_step : 10134, cur_epsilon : 0.01\n","episode : 104, done reward : 6.0, total_step : 10260, cur_epsilon : 0.01\n","episode : 105, done reward : 11.0, total_step : 10444, cur_epsilon : 0.01\n","episode : 106, done reward : 3.0, total_step : 10514, cur_epsilon : 0.01\n","episode : 107, done reward : 3.0, total_step : 10591, cur_epsilon : 0.01\n","episode : 108, done reward : 10.0, total_step : 10857, cur_epsilon : 0.01\n","episode : 109, done reward : 6.0, total_step : 10968, cur_epsilon : 0.01\n","synced target net\n","episode : 110, done reward : 6.0, total_step : 11089, cur_epsilon : 0.01\n","episode : 111, done reward : 8.0, total_step : 11226, cur_epsilon : 0.01\n","episode : 112, done reward : 8.0, total_step : 11373, cur_epsilon : 0.01\n","episode : 113, done reward : 6.0, total_step : 11500, cur_epsilon : 0.01\n","episode : 114, done reward : 5.0, total_step : 11647, cur_epsilon : 0.01\n","episode : 115, done reward : 9.0, total_step : 11957, cur_epsilon : 0.01\n","synced target net\n","episode : 116, done reward : 7.0, total_step : 12089, cur_epsilon : 0.01\n","episode : 117, done reward : 7.0, total_step : 12232, cur_epsilon : 0.01\n","episode : 118, done reward : 6.0, total_step : 12333, cur_epsilon : 0.01\n","episode : 119, done reward : 6.0, total_step : 12455, cur_epsilon : 0.01\n","episode : 120, done reward : 7.0, total_step : 12592, cur_epsilon : 0.01\n","episode : 121, done reward : 5.0, total_step : 12691, cur_epsilon : 0.01\n","episode : 122, done reward : 6.0, total_step : 12809, cur_epsilon : 0.01\n","episode : 123, done reward : 9.0, total_step : 12960, cur_epsilon : 0.01\n","synced target net\n","episode : 124, done reward : 5.0, total_step : 13058, cur_epsilon : 0.01\n","episode : 125, done reward : 6.0, total_step : 13172, cur_epsilon : 0.01\n","episode : 126, done reward : 7.0, total_step : 13298, cur_epsilon : 0.01\n","episode : 127, done reward : 7.0, total_step : 13430, cur_epsilon : 0.01\n","episode : 128, done reward : 3.0, total_step : 13501, cur_epsilon : 0.01\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-d36ddcad3cf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdone_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone_reward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'episode : {episode}, done reward : {done_reward}, total_step : {agent._total_step}, cur_epsilon : {agent._epsilon}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-82285d194ef3>\u001b[0m in \u001b[0;36mplay_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mstate_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mstate_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mq_vals_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_vals_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-ea3c02ac8f65>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# conv_out = self._conv(x / norm).view(x.size()[0], -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0madv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fc_adv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fc_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-756853f1dc3b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"iafBRU21u-W0"},"execution_count":null,"outputs":[]}]}