{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d84112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.envs.unity_gym_env import UnityToGymWrapper\n",
    "from mlagents_envs.environment import ActionTuple, UnityEnvironment\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import \\\n",
    "    EngineConfigurationChannel\n",
    "from mlagents_envs.exception import (\n",
    "    UnityEnvironmentException,\n",
    "    UnityCommunicationException,\n",
    "    UnityCommunicatorStoppedException,\n",
    ")\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb67672-0ea7-4b5d-9214-e89c4b9a828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ym/.cache/pypoetry/virtualenvs/mlagent-learn-20-test-54-2MrXv-py3.9/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from typing import Union\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from fastprogress import progress_bar as pb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44769aae-635a-4f94-b6ee-1f4f5af973c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpBuffer:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_size: int = 20000,\n",
    "        prob_alpha: float = 0.6,\n",
    "        beta_start: float = 0.4,\n",
    "        beta_frames: float = 100000,\n",
    "        n_step: int = 4,\n",
    "        gamma: float = 0.99,\n",
    "    ):\n",
    "        self._prob_alpha = prob_alpha\n",
    "        self._max_size = max_size\n",
    "        self._buf = []\n",
    "        self._pos = 0\n",
    "        self._beta_start = beta_start\n",
    "        self._beta = beta_start\n",
    "        self._beta_frames = beta_frames\n",
    "        self._n_step = n_step\n",
    "        self._gamma = gamma\n",
    "        self._total_discounted_rewards = np.array([np.nan]*max_size)\n",
    "        self._last_states = [np.nan]*max_size\n",
    "\n",
    "    def update_bata(self, idx) -> None:\n",
    "        beta = self._beta_start + idx * (1.0 - self._beta_start) / self._beta_frames\n",
    "        self._beta = min(1.0, beta)\n",
    "        return self._beta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._buf)\n",
    "\n",
    "    def append(\n",
    "        self,\n",
    "        state: np.ndarray,\n",
    "        action: int,\n",
    "        reward: Union[int, float],\n",
    "        done: bool,\n",
    "        next_state: np.ndarray,\n",
    "    ) -> None:\n",
    "        if len(self._buf) < self._max_size:\n",
    "            self._buf.append(\n",
    "                (state, action, reward, done, next_state)\n",
    "            )\n",
    "        else:\n",
    "            self._buf[self._pos] = (state, action, reward, done, next_state)\n",
    "\n",
    "        if len(self._buf) >= self._n_step:\n",
    "            dis_r = 0.0\n",
    "            last_state = self._buf[self._pos][0]\n",
    "            for i in range(self._n_step):\n",
    "                state, _, r, done, _ = self._buf[self._pos - i]\n",
    "                dis_r = r + self._gamma * dis_r\n",
    "                if done:\n",
    "                    last_state = state\n",
    "                    dis_r = r  # ※\n",
    "                self._total_discounted_rewards[self._pos - i] = dis_r\n",
    "                self._last_states[self._pos - i] = last_state\n",
    "            \n",
    "            for i in range(self._n_step-1):\n",
    "                done = self._buf[self._pos - i][3]\n",
    "                if done:\n",
    "                    break\n",
    "                self._total_discounted_rewards[self._pos - i] = np.nan\n",
    "                self._last_states[self._pos - i] = np.nan\n",
    "\n",
    "        self._pos = (self._pos + 1) % self._max_size\n",
    "\n",
    "    def get_latest_n(self, n: int):\n",
    "        if len(self._buf) < self._max_size:\n",
    "            if len(self._buf) < n+self._n_step:\n",
    "                raise RuntimeError('get_latest_n : len(self._buf) < n+self._n_step')\n",
    "            s_idx = self._pos - self._n_step - n \n",
    "            e_idx = self._pos - self._n_step\n",
    "            latest_exps = self._buf[s_idx:e_idx]\n",
    "            latest_total_rewards = self._total_discounted_rewards[s_idx:e_idx]\n",
    "            latest_last_states = self._last_states[s_idx:e_idx]\n",
    "        else:\n",
    "            s_idx = self._pos + self._max_size - self._n_step - n\n",
    "            e_idx = self._pos + self._max_size - self._n_step\n",
    "            latest_exps = (self._buf*2)[s_idx:e_idx]\n",
    "            latest_total_rewards = np.concatenate([self._total_discounted_rewards]*2)[s_idx:e_idx]\n",
    "            latest_last_states = (self._last_states*2)[s_idx:e_idx]\n",
    "        if len(latest_total_rewards) != n:\n",
    "            print(f'{s_idx} : {e_idx} : {e_idx-s_idx} : {len((self._total_discounted_rewards*2))}')\n",
    "        assert len(latest_exps) == n\n",
    "        assert len(latest_total_rewards) == n\n",
    "        assert len(latest_last_states) == n\n",
    "        states, actions, rewards, dones, next_states = zip(*latest_exps)\n",
    "        states = np.array(states)\n",
    "        actions = np.array(actions)\n",
    "        rewards = np.array(rewards)\n",
    "        dones = np.array(dones)\n",
    "        next_states = np.array(next_states)\n",
    "        last_states = np.stack(latest_last_states)\n",
    "        return states, actions, rewards, dones, latest_total_rewards, last_states\n",
    "\n",
    "    def update_priorities(self, sample_indices: np.ndarray, sample_priorities: np.ndarray) -> None:\n",
    "        self._priorities[sample_indices] = sample_priorities\n",
    "\n",
    "    @property\n",
    "    def gamma(self) -> float:\n",
    "        return self._gamma\n",
    "\n",
    "    @property\n",
    "    def n_step(self) -> float:\n",
    "        return self._n_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f8fc51-3552-4626-842f-180c07e39ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelActor(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_size, act_size, hidden_size: int = 128):\n",
    "        super(ModelActor, self).__init__()\n",
    "\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            # nn.Tanh(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.Tanh(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, act_size),\n",
    "            # nn.BatchNorm1d(act_size),\n",
    "            nn.Softmax(-1),\n",
    "        )\n",
    "        self.logstd = nn.Parameter(torch.zeros(act_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mu(x)\n",
    "\n",
    "    \n",
    "class ModelCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, obs_size, hidden_size: int = 128):\n",
    "        super(ModelCritic, self).__init__()\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e358d7-6ff5-4219-8b34-35d54ae79084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_adv_ref(rewards, dones, net_crt, states_v, gamma, gae_lambda, device=\"cpu\"):\n",
    "    values_v = net_crt(states_v)\n",
    "    values = values_v.squeeze().data.cpu().numpy()\n",
    "\n",
    "    last_gae = 0.0\n",
    "    result_adv = []\n",
    "    result_ref = []\n",
    "    for val, next_val, reward, done in zip(reversed(values[:-1]),\n",
    "                                     reversed(values[1:]),\n",
    "                                     reversed(rewards[:-1]),\n",
    "                                     reversed(dones[:-1])):\n",
    "        if done:\n",
    "            delta = reward - val\n",
    "            last_gae = delta\n",
    "        else:\n",
    "            delta = reward + gamma * next_val - val\n",
    "            last_gae = delta + gamma * gae_lambda * last_gae\n",
    "        result_adv.append(last_gae)\n",
    "        result_ref.append(last_gae + val)\n",
    "\n",
    "    adv_v = torch.FloatTensor(list(reversed(result_adv)))\n",
    "    ref_v = torch.FloatTensor(list(reversed(result_ref)))\n",
    "    return adv_v.to(device), ref_v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22bc0590-2a12-4855-98af-d6165fd5884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logprob(mu_v, logstd_v, actions_v):\n",
    "    p1 = - ((mu_v - actions_v) ** 2) / (2*torch.exp(logstd_v).clamp(min=1e-3))\n",
    "    p2 = - torch.log(torch.sqrt(2 * math.pi * torch.exp(logstd_v)))\n",
    "    return p1 + p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d1bb68-b63d-4a97-92f9-a3ca9b40d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        agent_id: int,\n",
    "        exp_buffer: ExpBuffer,\n",
    "        act_net: nn.Module,\n",
    "        crt_net: nn.Module,\n",
    "        epsilon_start: float = 1.0,\n",
    "        epsilon_final: float = 0.01,\n",
    "        epsilon_decay_last_step: int = 200000,\n",
    "        act_learning_rate: float = 1e-5,\n",
    "        crt_learning_rate: float = 1e-4,\n",
    "        adam_eps: float = None,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        trajectory_size: int = 2049,\n",
    "        ppo_eps: float = 0.2,\n",
    "        gae_lambda: float = 0.95,\n",
    "    ):\n",
    "        self._env = env\n",
    "        self._agent_id = agent_id\n",
    "        self._exp_buffer = exp_buffer\n",
    "        self._act_net = act_net\n",
    "        self._crt_net = crt_net\n",
    "        self._epsilon_start = epsilon_start\n",
    "        self._epsilon_final = epsilon_final\n",
    "        self._epsilon_decay_last_step = epsilon_decay_last_step\n",
    "        self._epsilon = epsilon_start\n",
    "        self._device = device\n",
    "        self._total_step = 0\n",
    "        self._total_trained_samples = 0\n",
    "        # self._tgt_sync_steps = tgt_sync_steps\n",
    "        adam_kwargs = {}\n",
    "        if adam_eps is not None:\n",
    "            adam_kwargs['eps'] = adam_eps\n",
    "        self._act_optimizer = torch.optim.Adam(self._act_net.parameters(), lr=act_learning_rate, **adam_kwargs)\n",
    "        self._crt_optimizer = torch.optim.Adam(self._crt_net.parameters(), lr=crt_learning_rate, **adam_kwargs)\n",
    "        self.reset_episode()\n",
    "        # self._use_sync_net = use_sync_net\n",
    "        self._episode = 0\n",
    "        self._trajectory_size = trajectory_size\n",
    "        self._ppo_eps = ppo_eps\n",
    "        self._gae_lambda = gae_lambda\n",
    "        self._episode_rewards = []\n",
    "\n",
    "    def reset_episode(self):\n",
    "        agent_ids, states, rewards, dones = self._env.get_state()\n",
    "        idx = np.where(agent_ids==self._agent_id)[0][0]\n",
    "        self._state = states[idx]\n",
    "        self._total_reward = 0.0\n",
    "\n",
    "    def set_action(self, continuous_action: np.ndarray = None, discrete_action: np.ndarray = None):\n",
    "        self._env.set_action(self._agent_id, continuous_action, discrete_action)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def decide_action_and_set(self, epsilon: Optional[float] = None, sync_target: bool = True):\n",
    "        self._act_net.eval()\n",
    "        self._crt_net.eval()\n",
    "        if epsilon is None:\n",
    "            epsilon = self._epsilon\n",
    "        done_reward = None\n",
    "\n",
    "        if np.random.random() < epsilon:\n",
    "            c_acts, d_acts = self._env.random_action()\n",
    "        else:\n",
    "            state_a = np.array([self._state], copy=False)\n",
    "            state_v = torch.tensor(state_a).float().to(self._device)\n",
    "            prob_v = self._act_net(state_v)\n",
    "#             action = prob_v.squeeze(dim=0).argmax().data.cpu().numpy()\n",
    "            prob = prob_v.squeeze(dim=0).data.cpu().numpy()\n",
    "            d_acts = np.random.choice(range(len(prob)), size=1, p=prob).astype(int)\n",
    "            c_acts = None\n",
    "#             print(action)\n",
    "#             action = np.clip(action, -1, 1)\n",
    "\n",
    "        self.set_action(c_acts, d_acts)\n",
    "        return d_acts\n",
    "\n",
    "    def update_experience(self, agent_ids, next_states, rewards, dones, action, update_params = True):\n",
    "        idx = np.where(agent_ids==self._agent_id)[0][0]\n",
    "        next_state, reward, done = next_states[idx], rewards[idx], dones[idx]\n",
    "\n",
    "        self._total_reward += reward\n",
    "        self._exp_buffer.append(\n",
    "            self._state, action, reward, done, next_state\n",
    "        )\n",
    "        self._state = next_state\n",
    "        if done:\n",
    "            done_reward = self._total_reward\n",
    "            self._episode_rewards.append(done_reward)\n",
    "            # self.reset_episode()\n",
    "\n",
    "        if update_params:\n",
    "            self._total_step += 1\n",
    "            self._update_epsilon(self._total_step)\n",
    "            self._exp_buffer.update_bata(self._total_step)\n",
    "\n",
    "        # if self._total_step % self._tgt_sync_steps == 0 and sync_target:\n",
    "        #     self._tgt_net.load_state_dict(self._net.state_dict())\n",
    "        #     print(f'synced target net')\n",
    "\n",
    "    def train(self, ppo_epoch: int = 10, batch_size: int = 32) -> None:\n",
    "        self._act_net.train()\n",
    "        self._crt_net.train()\n",
    "        n_step_gamma = self._exp_buffer.gamma ** self._exp_buffer.n_step\n",
    "\n",
    "        # for stp in range(self._trajectory_size):\n",
    "        #     done_reward = self.play_step()\n",
    "        #     if done_reward is not None:\n",
    "        #         print(f'episode : {self._episode}, done reward : {done_reward}, total_step : {self._total_step}, cur_epsilon : {self._epsilon}')\n",
    "        #         self._episode += 1\n",
    "        traj_states, traj_actions, traj_rewards, traj_dones, traj_total_discounted_rewards, \\\n",
    "            traj_last_states = self._exp_buffer.get_latest_n(self._trajectory_size)\n",
    "        traj_states_v = torch.tensor(traj_states).float().to(self._device)\n",
    "        traj_actions_v = torch.tensor(traj_actions).to(self._device)\n",
    "        traj_discounted_rewards_v = torch.tensor(traj_total_discounted_rewards).to(self._device)\n",
    "        traj_done_mask = torch.BoolTensor(traj_dones).to(self._device)\n",
    "        # weights_v = torch.tensor(weights).to(self._device)\n",
    "\n",
    "        traj_adv_v, traj_ref_v = calc_adv_ref(\n",
    "            traj_total_discounted_rewards, traj_dones, self._crt_net, traj_states_v, gamma=n_step_gamma, gae_lambda=self._gae_lambda, device=self._device  # reards or total_discounted_rewards ?\n",
    "        )\n",
    "        traj_prob_v = self._act_net(traj_states_v)\n",
    "#         old_logprob_v = calc_logprob(mu_v, self._act_net.logstd, traj_actions_v)\n",
    "#         action_prob_v = prob_v.max(1)[0]\n",
    "        traj_action_prob_v = traj_prob_v.gather(1, traj_actions_v.unsqueeze(-1))\n",
    "        old_logprob_v = torch.log(traj_action_prob_v)\n",
    "\n",
    "        # normalize advantages\n",
    "        traj_adv_v = traj_adv_v - torch.mean(traj_adv_v)\n",
    "        traj_adv_v /= torch.std(traj_adv_v)\n",
    "\n",
    "        # drop last entry from the trajectory, an our adv and ref value calculated without it\n",
    "        # trajectory = trajectory[:-1]\n",
    "        old_logprob_v = old_logprob_v[:-1].detach()\n",
    "\n",
    "        sum_loss_value = 0.0\n",
    "        sum_loss_policy = 0.0\n",
    "        count_steps = 0\n",
    "\n",
    "        for epoch in range(ppo_epoch):\n",
    "            for batch_ofs in range(0, self._trajectory_size-1, batch_size):\n",
    "                batch_l = batch_ofs + batch_size\n",
    "                states_v = traj_states_v[batch_ofs:batch_l]\n",
    "                actions_v = traj_actions_v[batch_ofs:batch_l]\n",
    "                batch_adv_v = traj_adv_v[batch_ofs:batch_l]\n",
    "                batch_adv_v = batch_adv_v.unsqueeze(-1)\n",
    "                batch_ref_v = traj_ref_v[batch_ofs:batch_l]\n",
    "                batch_old_logprob_v = old_logprob_v[batch_ofs:batch_l]\n",
    "\n",
    "                # critic training\n",
    "                self._crt_optimizer.zero_grad()\n",
    "                value_v = self._crt_net(states_v)\n",
    "                loss_value_v = F.mse_loss(value_v.squeeze(-1), batch_ref_v)\n",
    "                loss_value_v.backward()\n",
    "                self._crt_optimizer.step()\n",
    "\n",
    "                # actor training\n",
    "                self._act_optimizer.zero_grad()\n",
    "                prob_v = self._act_net(states_v)\n",
    "#                 action_prob_v = prob_v.max(1)[0]\n",
    "                action_prob_v = prob_v.gather(1, actions_v.unsqueeze(-1))\n",
    "#                 logprob_pi_v = calc_logprob(mu_v, self._act_net.logstd, actions_v)\n",
    "                logprob_pi_v = torch.log(action_prob_v)\n",
    "                ratio_v = torch.exp(logprob_pi_v - batch_old_logprob_v)\n",
    "                surr_obj_v = batch_adv_v * ratio_v\n",
    "                c_ratio_v = torch.clamp(ratio_v, 1.0 - self._ppo_eps, 1.0 + self._ppo_eps)\n",
    "                clipped_surr_v = batch_adv_v * c_ratio_v\n",
    "                loss_policy_v = -torch.min(surr_obj_v, clipped_surr_v).mean()\n",
    "                loss_policy_v.backward()\n",
    "                self._act_optimizer.step()\n",
    "\n",
    "                sum_loss_value += loss_value_v.item()\n",
    "                sum_loss_policy += loss_policy_v.item()\n",
    "                count_steps += 1\n",
    "\n",
    "        # self._exp_buffer.update_priorities(sampled_indices, prios)\n",
    "        self._total_trained_samples += batch_size\n",
    "\n",
    "#     def initial_exploration(self, n_steps: int = 10000, epsilon: float = 1.0) -> None:\n",
    "#         eps_bak = self._epsilon\n",
    "#         total_step_bak = self._total_step\n",
    "#         for i in pb(range(n_steps)):\n",
    "#             self._epsilon = epsilon\n",
    "#             self.play_step(sync_target=False)\n",
    "#         self._total_step = total_step_bak\n",
    "#         self._epsilon = eps_bak\n",
    "\n",
    "#     def simulate_episode(self) -> float:\n",
    "#         eps_bak = self._epsilon\n",
    "#         total_step_bak = self._total_step\n",
    "#         while True:\n",
    "#             self._epsilon = 0.0\n",
    "#             done_reward = self.play_step(sync_target=False)\n",
    "#             if done_reward is not None:\n",
    "#                 break\n",
    "#         self._total_step = total_step_bak\n",
    "#         self._epsilon = eps_bak\n",
    "#         return done_reward\n",
    "\n",
    "    def _update_epsilon(self, step_index: int) -> None:\n",
    "        self._epsilon = max(\n",
    "            self._epsilon_final,\n",
    "            self._epsilon_start - step_index / self._epsilon_decay_last_step\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656b4346-709a-4a64-a726-b9a57abfdc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvWrapper:\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self._env = env\n",
    "        behavior_names = list(env.behavior_specs.keys())\n",
    "        behavior_spec = env.behavior_specs[behavior_names[0]]\n",
    "        self._behavior_name = list(env.behavior_specs.keys())[0]\n",
    "        self._action_continuous_dim = behavior_spec.action_spec.continuous_size\n",
    "        self._action_discrete_dim = len(behavior_spec.action_spec.discrete_branches)\n",
    "        self._n_discrete_actions = behavior_spec.action_spec.discrete_branches\n",
    "        self._OBSERVATION_IDX = 0\n",
    "        decision_steps, terminal_steps = env.get_steps(behavior_names[0])\n",
    "        self._n_agents = len(decision_steps.obs[0])\n",
    "\n",
    "    def set_action(self, agent_id, continuous_action: np.ndarray = None, discrete_action: np.ndarray = None):\n",
    "        if continuous_action is None and discrete_action is None:\n",
    "            raise ValueError('either continuous_action or discrete_action must be specified')\n",
    "        action_tuple = self.format_action(continuous_action, discrete_action)\n",
    "        self._env.set_action_for_agent(self._behavior_name, agent_id, action_tuple)\n",
    "\n",
    "    def format_action(self, continuous_action: np.ndarray, discrete_action: np.ndarray):\n",
    "        if continuous_action is not None:\n",
    "            assert continuous_action.ndim == 1\n",
    "            assert len(continuous_action) == self._action_continuous_dim\n",
    "        if discrete_action is not None:\n",
    "            assert discrete_action.ndim == 1\n",
    "            assert len(discrete_action) == self._action_discrete_dim\n",
    "        return ActionTuple(\n",
    "            continuous=continuous_action.reshape(1, self._action_continuous_dim) if continuous_action is not None else None,\n",
    "            discrete=discrete_action.reshape(1, self._action_discrete_dim) if discrete_action is not None else None\n",
    "        )\n",
    "\n",
    "    def get_state(self):\n",
    "        decision_steps, terminal_steps = self._env.get_steps(self._behavior_name)\n",
    "        \n",
    "        agent_id_diff = list(set(decision_steps.agent_id)-set(terminal_steps.agent_id))\n",
    "        agent_id_filt = [ai in agent_id_diff for ai in decision_steps.agent_id]\n",
    "\n",
    "        states = np.concatenate([\n",
    "            decision_steps.obs[self._OBSERVATION_IDX][agent_id_filt],\n",
    "            terminal_steps.obs[self._OBSERVATION_IDX]\n",
    "        ], axis=0)\n",
    "        agent_ids = np.concatenate([decision_steps.agent_id[agent_id_filt], terminal_steps.agent_id], axis=0)\n",
    "        rewards = np.concatenate([decision_steps.reward[agent_id_filt], terminal_steps.reward], axis=0)\n",
    "        dones = [False]*len(decision_steps.reward[agent_id_filt]) + [True]*len(terminal_steps.reward)\n",
    "\n",
    "        assert states.shape[0] == self._n_agents\n",
    "        assert len(rewards) == self._n_agents\n",
    "        assert len(dones) == self._n_agents\n",
    "\n",
    "        return agent_ids, states, rewards, dones\n",
    "\n",
    "    def step(self):\n",
    "        self._env.step()\n",
    "        agent_ids, states, rewards, dones = self.get_state()\n",
    "        return agent_ids, states, rewards, dones\n",
    "    \n",
    "    def reset(self):\n",
    "        self._env.reset()\n",
    "        agent_ids, states, rewards, dones = self.get_state()\n",
    "        return states\n",
    "\n",
    "    def random_action(self):\n",
    "        return (\n",
    "            2.0*np.random.rand(self._action_continuous_dim) - 1.0 if self._action_continuous_dim > 0 else None,\n",
    "            np.array([np.random.randint(0, n_act) for n_act in self._n_discrete_actions]) if self._action_discrete_dim > 0 else None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d4c6b-88d7-44d1-861c-7fb857c04dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c15017fd-d76d-4f69-90b4-1b840f5368de",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    env.close()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ec14e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    env.close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "env = UnityEnvironment(file_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "82bc3045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavior_names: ['My Behavior?team=0']\n",
      "\n",
      "== BehaviorSpecの情報の確認 ==\n",
      "observation_specs: [ObservationSpec(shape=(11,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size11')]\n",
      "action_spec: Continuous: 0, Discrete: (6,)\n"
     ]
    }
   ],
   "source": [
    "# Unity環境のリセット\n",
    "env.reset()\n",
    "\n",
    "# BehaviorNameのリストの取得\n",
    "behavior_names = list(env.behavior_specs.keys())\n",
    "print('behavior_names:', behavior_names)\n",
    "\n",
    "# BehaviorSpecの取得\n",
    "behavior_spec = env.behavior_specs[behavior_names[0]]\n",
    "\n",
    "# BehaviorSpecの情報の確認\n",
    "print('\\n== BehaviorSpecの情報の確認 ==')\n",
    "print('observation_specs:', behavior_spec.observation_specs)\n",
    "print('action_spec:', behavior_spec.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "65c48188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BehaviorSpec(observation_specs=[ObservationSpec(shape=(11,), dimension_property=(<DimensionProperty.NONE: 1>,), observation_type=<ObservationType.DEFAULT: 0>, name='VectorSensor_size11')], action_spec=ActionSpec(continuous_size=0, discrete_branches=(6,)))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e6fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24473caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "049cd29c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== DecisionStepsの情報の確認 ==\n",
      "obj: [array([[-6.8766326e-01,  2.4140062e-02, -4.7013798e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.3462344e-01, -8.6798507e-01, -2.7777109e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.2641124e-01, -3.7685615e-01, -2.3980264e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.4409685e-01, -7.2322822e-01,  3.4911957e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 5.8415622e-01, -1.3864968e+00, -2.2136469e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.5949337e-01, -1.1931936e+00, -3.2588819e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.0329245e-01, -6.4220816e-01,  3.5530299e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 6.0922796e-01, -8.0559099e-01, -6.8424302e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.4159642e-01, -1.0564756e+00, -2.0504952e-03,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-7.6566035e-01, -3.1931812e-01, -5.0199068e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.2444438e-01, -1.0168089e+00,  7.3927534e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 9.3934536e-02, -3.8648972e-01, -6.8775290e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 7.6593703e-01,  1.4928634e-01,  2.3108919e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.1409589e-02, -6.6747999e-01,  7.8605574e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.2509691e-01, -5.4808503e-01, -4.1777152e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-7.5312215e-01, -1.3489598e+00,  7.8034401e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 5.3155673e-01, -3.7403214e-01, -4.1840076e-02,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.2762890e-01,  1.1396763e-01,  6.4691758e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-6.0505867e-03, -6.6047513e-01,  1.3128252e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.3297845e-01, -1.4563687e+00, -7.2191566e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.6084174e-01, -9.8994666e-01,  1.4302253e-03,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.4227887e-02, -4.7809228e-01, -2.2674656e-02,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.6423789e-01,  6.4626567e-02,  1.9891806e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.5080853e-01, -1.1993364e+00, -2.7755499e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-6.9252777e-01,  1.4067602e-01, -6.7854726e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.2980272e-01, -1.2784626e+00, -5.5748653e-02,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.6656988e-01, -8.1543314e-01, -4.4299603e-02,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.9206842e-01, -9.1351014e-01,  2.1928155e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 3.1424999e-02, -1.6184750e-01,  7.7093339e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.3441048e-01, -8.3898705e-01,  2.5412366e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.3380356e-01, -1.4730960e+00,  5.9951532e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.7807477e-01, -7.0013458e-01,  4.7265929e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.0595418e-01, -3.4000733e-01, -3.5872892e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.4844065e-01, -1.1825712e+00, -7.6733118e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 5.2231580e-01, -1.4426227e+00,  6.7187768e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.1554602e-01, -6.4404178e-01, -6.8989623e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.0667096e-01,  2.5688028e-02,  4.8596841e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.0923138e-02, -2.3971158e-01,  6.0894525e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.8931627e-01, -4.4205391e-01,  4.7031003e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.5778573e-01, -1.3285702e-01,  1.4588451e-02,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-4.2021275e-02, -6.5703493e-01, -6.4245933e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-1.9906035e-01, -8.3396715e-01,  5.8834648e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 6.0893309e-01, -4.0471536e-01,  2.8382588e-02,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 1.7617902e-01, -3.0807409e-01, -5.7364905e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.4855703e-01,  1.3434547e-01, -5.0298440e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 2.0974977e-01,  1.3781276e-01,  6.0547811e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 4.5416735e-02, -9.6801221e-01,  2.5290677e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.0359298e-01, -3.5162148e-01, -4.6820277e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-5.7485867e-01, -1.2569927e+00,  1.5623236e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-6.8098551e-01, -5.1801282e-01,  1.5904894e-01,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)]\n",
      "reward: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n",
      "agent_id: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "action_mask: [array([[False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False],\n",
      "       [False, False, False, False, False, False]])]\n",
      "\n",
      "== TerminalStepsの情報の確認 ==\n",
      "obs: [array([], shape=(0, 11), dtype=float32)]\n",
      "reward: []\n",
      "agent_id: []\n",
      "interrupted: []\n"
     ]
    }
   ],
   "source": [
    "# 現在のステップの情報の取得\n",
    "decision_steps, terminal_steps = env.get_steps(behavior_names[0])\n",
    "\n",
    "# DecisionStepsの情報の確認\n",
    "print('\\n== DecisionStepsの情報の確認 ==')\n",
    "print('obj:', decision_steps.obs)\n",
    "print('reward:', decision_steps.reward)\n",
    "print('agent_id:', decision_steps.agent_id)\n",
    "print('action_mask:', decision_steps.action_mask)\n",
    "\n",
    "# TerminalStepsの情報の確認\n",
    "print('\\n== TerminalStepsの情報の確認 ==')\n",
    "print('obs:', terminal_steps.obs)\n",
    "print('reward:', terminal_steps.reward)\n",
    "print('agent_id:', terminal_steps.agent_id)\n",
    "print('interrupted:', terminal_steps.interrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f591e623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decision_steps.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2f5cb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 11)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_steps.obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3554a8ab-4a46-4923-bb3a-716231963249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5841562 , -1.3864968 , -0.22136469,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_steps.obs[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cdd2969d-6b55-453f-8318-06dc3312c62f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[195], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdecision_steps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "decision_steps.obs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fbfab3e5-268b-4589-9c5b-dac2ce30877a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 11)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([decision_steps.obs[0], terminal_steps.obs[0]], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ac136e93-b502-40f8-a1be-800da1620a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminal_steps.obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "679b930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_AGENTS = len(decision_steps.obs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bb2f18f5-3533-447b-b090-7bfedadd56e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f48d65df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_steps.reward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8ea7b358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_steps.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6a14ec09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_steps.agent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "57903f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False]])]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_steps.action_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "83566d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminal_steps.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ce68c62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminal_steps.agent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5f1add65-bc7c-4b6e-92c4-4a2549c10363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], shape=(0, 11), dtype=float32)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminal_steps.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f90f3ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActionSpec(continuous_size=0, discrete_branches=(6,))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_spec.action_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e5cb6883-0043-4866-8a0a-62c051476f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_spec.action_spec.discrete_branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ba179d51-a4cc-49b7-94d5-6cab468214a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(behavior_spec.action_spec.discrete_branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9b6c3af7-caca-49fa-bd64-3bae77146479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_spec.action_spec.continuous_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260123f-29c9-458c-9bd8-159ade1eb123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9b43a2a6-d614-4835-b91d-60ee3a306ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_AGENTS, OBS_DIM = decision_steps.obs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4d6ac615-afcd-42f9-9ba9-2f24a0b9248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 11)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_AGENTS, OBS_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "817706ff-e9f3-49b2-9013-c62f67e9165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ACTIONS = behavior_spec.action_spec.discrete_branches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1cf37e54-1b5f-4d75-aa65-be8c51377603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6deb29c-e059-4a0d-99b2-b247d5b7d681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2656191b-4a6a-4f12-a857-22a315167b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.set_action_for_agent(behavior_names[0], 0, ActionTuple(continuous=np.zeros(3).reshape(1, 3), discrete=np.array([0]).reshape(1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc7ff3-445c-4514-b30d-23ffbbcbbc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69df90-cd67-4557-807e-a43d5a81a22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "44f16c88-940e-48a3-8b47-40759d22c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Agent:\n",
    "    \n",
    "#     def __init__(self, w_env, agent_id):\n",
    "#         self._w_env = w_env\n",
    "#         self._agent_id = agent_id\n",
    "\n",
    "#     def set_action(self, continuous_action: np.ndarray = None, discrete_action: np.ndarray = None):\n",
    "#         self._w_env.set_action(self._agent_id, continuous_action, discrete_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "54ae6b18-9096-4c32-b75a-b720de97bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_env = EnvWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858cacff-4393-45e3-9780-b658c66b36d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2d9acc5b-f530-4388-81bf-a343bb631845",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_acts, d_acts = w_env.random_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5f6d9eb4-39a7-48a8-9d33-4ab0da732c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3714a3e4-2285-46e7-bf19-48c61f9e2834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d392af-b2ca-4eaf-9adf-354f56e49673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f85dd34c-1a0f-48fd-89f8-788171c2e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 77\n",
    "device = 'cuda'\n",
    "TRAJECTORY_SIZE = 2049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "054b7ea2-abcc-4521-937f-f880d58f78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {}\n",
    "\n",
    "for agent_id in range(N_AGENTS):\n",
    "    act_net = ModelActor(\n",
    "        obs_size=OBS_DIM,\n",
    "        act_size=N_ACTIONS\n",
    "    ).to(device)\n",
    "    crt_net = ModelCritic(\n",
    "        obs_size=OBS_DIM,\n",
    "    ).to(device)\n",
    "    exp_buffer = ExpBuffer(\n",
    "        max_size=2500,\n",
    "        prob_alpha=0.6,\n",
    "        beta_start=0.4,\n",
    "        beta_frames=30000, #100000,\n",
    "        # n_step=1,\n",
    "        n_step=6,\n",
    "        gamma=0.99,\n",
    "    )\n",
    "    agent = Agent(\n",
    "        env=w_env,\n",
    "        agent_id=agent_id,\n",
    "        exp_buffer=exp_buffer,\n",
    "        crt_net=crt_net,\n",
    "        act_net=act_net,\n",
    "        epsilon_start=0.6,\n",
    "        epsilon_final=0.002,\n",
    "        epsilon_decay_last_step=30000, #200000,\n",
    "        # tgt_sync_steps=1000,\n",
    "        act_learning_rate=1e-5,\n",
    "        crt_learning_rate=1e-4,\n",
    "        device=device,\n",
    "        trajectory_size=TRAJECTORY_SIZE,\n",
    "        ppo_eps=0.2,\n",
    "        gae_lambda=0.95,\n",
    "    )\n",
    "    agents[agent_id] = agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e74274-50f4-49f8-93ea-a7086436c164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6f2667ee-ebf1-4c0a-a9c7-c7aec134a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_EXPLORATION_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "21e09c70-f21c-480e-a014-4beec4c63a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:11<00:00,  8.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(INITIAL_EXPLORATION_STEPS)):\n",
    "    actions = {}\n",
    "    for agent_id, agent in agents.items():\n",
    "        action = agent.decide_action_and_set(epsilon=1.0)\n",
    "        actions[agent_id] = action[0]\n",
    "    agent_ids, states, rewards, dones = w_env.step()\n",
    "    for agent_id, agent in agents.items():\n",
    "        agent.update_experience(agent_ids, states, rewards, dones, actions[agent_id], update_params=False)\n",
    "    if any(dones):\n",
    "        _, _ = w_env.reset()\n",
    "        for agent_id, agent in agents.items():\n",
    "            agent.reset_episode()\n",
    "            print(agent._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fd3647c3-4738-48fa-a47f-96bb3501e77b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.20008695e-01,  4.32969965e-02, -1.92020133e-01,\n",
       "         9.66164172e-02, -8.33965279e-03,  7.09424820e-03,\n",
       "         1.00000000e+00,  4.13073570e-01,  3.09089869e-01,\n",
       "        -4.11497504e-02, -1.80316567e-01],\n",
       "       [ 1.46613210e-01, -1.37132978e+00, -5.89059368e-02,\n",
       "         1.65653899e-01, -2.31060475e-01,  2.16044076e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-3.14154774e-01, -3.51978987e-01,  1.95269644e-01,\n",
       "        -1.52869076e-01,  2.25625083e-01,  3.99244010e-01,\n",
       "         1.00000000e+00,  3.02992731e-01, -8.96618485e-01,\n",
       "         3.37645710e-01,  1.62894085e-01],\n",
       "       [-1.91399381e-01, -5.02456903e-01,  1.85836136e-01,\n",
       "         8.68628472e-02,  5.34674451e-02,  4.50740941e-03,\n",
       "         1.00000000e+00,  2.40483269e-01, -1.25606954e-01,\n",
       "         1.08228721e-01,  1.86272502e-01],\n",
       "       [ 6.17727637e-01, -1.15252256e+00, -1.54935256e-01,\n",
       "         2.10049823e-02,  3.19858529e-02,  2.60195695e-03,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.17624905e-02, -1.29775679e+00,  6.62391931e-02,\n",
       "         7.69198406e-03, -2.86623323e-03,  7.26651633e-03,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.09986526e-01, -6.26073241e-01,  7.63182163e-01,\n",
       "        -1.81477703e-02,  1.96120609e-02,  2.98938178e-03,\n",
       "         1.00000000e+00,  2.78853118e-01,  1.00387490e+00,\n",
       "        -1.09880842e-01,  3.11233371e-01],\n",
       "       [ 2.90374875e-01, -9.20245945e-01, -1.78584963e-01,\n",
       "        -5.28215850e-03,  1.99303962e-03, -1.93755073e-03,\n",
       "         1.00000000e+00,  2.05209851e-01, -1.25606954e-01,\n",
       "         1.08228721e-01,  1.86272502e-01],\n",
       "       [ 3.14822793e-01, -9.85629499e-01,  1.10565729e-01,\n",
       "        -2.20926523e-01, -6.64620280e-01, -2.95397401e-01,\n",
       "         1.00000000e+00,  1.07712746e-01,  2.63079889e-02,\n",
       "        -1.85748741e-01, -1.06631813e-03],\n",
       "       [-8.56517553e-01, -3.45988460e-02, -6.42645657e-01,\n",
       "         3.03715050e-01, -4.27908808e-01, -5.47611117e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.49215445e-01, -1.17096722e+00,  9.29023743e-01,\n",
       "        -1.02032721e-01,  1.26754701e-01,  4.92783263e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-5.90901077e-02, -1.27404839e-01, -6.69093251e-01,\n",
       "        -3.81757058e-02, -2.34039634e-01,  1.53889164e-01,\n",
       "         1.00000000e+00,  3.29100370e-01, -2.25804880e-01,\n",
       "        -7.25653693e-02,  7.85782784e-02],\n",
       "       [ 7.76494086e-01,  4.14562179e-03,  3.21823895e-01,\n",
       "        -7.20447535e-03, -3.65895107e-02, -2.27253865e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 6.54275537e-01, -4.81994718e-01,  8.50640237e-01,\n",
       "         5.53131342e-01,  2.14988038e-01, -3.69357765e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.14119124e-01, -4.56974119e-01,  4.66531888e-03,\n",
       "         2.33079433e-01,  1.34300683e-02,  2.82215893e-01,\n",
       "         1.00000000e+00,  4.12450492e-01,  5.53131342e-01,\n",
       "         2.14988038e-01, -3.69357765e-01],\n",
       "       [-4.72926557e-01, -1.10039091e+00,  8.46268535e-01,\n",
       "         1.13093175e-01, -2.95999497e-01, -7.75858983e-02,\n",
       "         1.00000000e+00,  1.94768295e-01, -2.05276124e-02,\n",
       "         1.10837305e-02,  1.34379389e-02],\n",
       "       [ 2.64781773e-01, -6.51424646e-01,  1.51169181e-01,\n",
       "        -1.25606954e-01,  1.08228721e-01,  1.86272502e-01,\n",
       "         1.00000000e+00,  3.75183642e-01,  2.95995660e-02,\n",
       "        -7.07859769e-02,  1.86015800e-01],\n",
       "       [-5.18917561e-01, -1.40282633e-02,  8.81164551e-01,\n",
       "        -9.64843407e-02, -4.94895317e-02,  1.29809469e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-3.76366466e-01, -7.29472756e-01,  9.87611525e-03,\n",
       "         2.16215372e-01, -4.12784815e-01,  2.67024636e-01,\n",
       "         1.00000000e+00,  3.17262709e-01,  7.69198406e-03,\n",
       "        -2.86623323e-03,  7.26651633e-03],\n",
       "       [-9.51183021e-01, -1.31379008e+00, -5.09290934e-01,\n",
       "        -2.69885689e-01, -5.55287823e-02,  2.42847472e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-4.32911456e-01, -8.81718278e-01,  2.71596581e-01,\n",
       "         6.53442442e-02,  3.57200593e-01,  4.19910252e-01,\n",
       "         1.00000000e+00,  3.45648587e-01,  2.51335260e-02,\n",
       "        -3.07540178e-01,  8.41417462e-02],\n",
       "       [-1.63711086e-01, -3.96172017e-01,  3.01750839e-01,\n",
       "        -2.97168400e-02,  5.80500960e-02,  1.64612010e-01,\n",
       "         1.00000000e+00,  2.93838203e-01,  5.71641088e-01,\n",
       "        -4.55024153e-01,  5.66467047e-02],\n",
       "       [-4.20773216e-02, -1.30280793e-01,  7.63704240e-01,\n",
       "         2.95995660e-02, -7.07859769e-02,  1.86015800e-01,\n",
       "         1.00000000e+00,  4.93890882e-01, -1.02032721e-01,\n",
       "         1.26754701e-01,  4.92783263e-02],\n",
       "       [-7.65760720e-01, -9.95820701e-01,  3.23020965e-01,\n",
       "        -2.06225496e-02,  6.08221516e-02,  2.06428207e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-3.33487660e-01,  3.33236577e-03, -2.66062558e-01,\n",
       "         1.42060548e-01,  4.92051467e-02,  5.73169589e-02,\n",
       "         1.00000000e+00,  5.52678704e-01, -7.20447535e-03,\n",
       "        -3.65895107e-02, -2.27253865e-02],\n",
       "       [ 5.01487494e-01, -1.30599535e+00,  3.35525542e-01,\n",
       "        -1.88988283e-01, -4.36907232e-01,  6.33536637e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.81004792e-01, -1.00665236e+00,  4.22556311e-01,\n",
       "         2.62612216e-02, -1.25784710e-01,  1.23060368e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.69240117e-01, -1.13894963e+00,  1.65485054e-01,\n",
       "         2.63079889e-02, -1.85748741e-01, -1.06631813e-03,\n",
       "         1.00000000e+00,  3.92165571e-01, -2.05276124e-02,\n",
       "         1.10837305e-02,  1.34379389e-02],\n",
       "       [ 9.70174372e-02, -1.73600495e-01,  9.39775407e-01,\n",
       "         1.00387490e+00, -1.09880842e-01,  3.11233371e-01,\n",
       "         1.00000000e+00,  1.47722349e-01,  8.30384530e-03,\n",
       "         2.63078902e-02, -2.40985658e-02],\n",
       "       [-8.18782032e-01, -1.10718000e+00,  5.06476462e-01,\n",
       "        -9.23082680e-02,  5.06942198e-02,  2.52611458e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.73024237e-01, -1.41835117e+00,  9.27733243e-01,\n",
       "        -2.05276124e-02,  1.10837305e-02,  1.34379389e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-6.92478955e-01, -7.36178994e-01,  9.23371911e-01,\n",
       "        -5.03602400e-02, -1.16498813e-01, -6.04136847e-03,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 3.49158376e-01, -3.99917990e-01,  3.86850797e-02,\n",
       "        -1.26737310e-02,  2.05598911e-03,  1.66783407e-02,\n",
       "         1.00000000e+00,  3.24942619e-01,  2.59835184e-01,\n",
       "        -2.84890413e-01,  1.75606403e-02],\n",
       "       [ 1.29930303e-02, -1.08389521e+00, -7.57260442e-01,\n",
       "        -2.93143034e-01, -1.49460703e-01,  4.53159392e-01,\n",
       "         1.00000000e+00,  4.92787540e-01, -2.69885689e-01,\n",
       "        -5.55287823e-02,  2.42847472e-01],\n",
       "       [ 5.17617047e-01, -1.17264354e+00,  4.75379080e-01,\n",
       "         3.46248522e-02, -3.16095978e-01, -1.56220794e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-7.34631181e-01, -8.59752476e-01, -1.70809746e-01,\n",
       "        -9.31521207e-02,  2.04921275e-01,  3.71450275e-01,\n",
       "         1.00000000e+00,  5.44966698e-01, -8.96618485e-01,\n",
       "         3.37645710e-01,  1.62894085e-01],\n",
       "       [ 4.24245954e-01, -1.52306497e-01,  8.95801067e-01,\n",
       "         8.30384530e-03,  2.63078902e-02, -2.40985658e-02,\n",
       "         1.00000000e+00,  5.44009686e-01, -1.02032721e-01,\n",
       "         1.26754701e-01,  4.92783263e-02],\n",
       "       [ 8.37527290e-02,  9.16870218e-03,  7.61475682e-01,\n",
       "         5.71641088e-01, -4.55024153e-01,  5.66467047e-02,\n",
       "         1.00000000e+00,  1.07418843e-01,  1.47864193e-01,\n",
       "        -2.67356932e-01,  3.47611755e-01],\n",
       "       [ 6.21088268e-03, -5.32714166e-02,  1.91565782e-01,\n",
       "         3.09089869e-01, -4.11497504e-02, -1.80316567e-01,\n",
       "         1.00000000e+00,  3.85759354e-01, -7.20447535e-03,\n",
       "        -3.65895107e-02, -2.27253865e-02],\n",
       "       [-2.50499576e-01, -1.53694674e-01,  5.06523848e-01,\n",
       "         2.51335260e-02, -3.07540178e-01,  8.41417462e-02,\n",
       "         1.00000000e+00,  2.05418840e-01, -1.69240117e-01,\n",
       "         4.14137930e-01,  5.46477437e-01],\n",
       "       [-3.20856348e-02, -5.61405480e-01, -1.23312570e-01,\n",
       "        -2.25804880e-01, -7.25653693e-02,  7.85782784e-02,\n",
       "         1.00000000e+00,  1.99825779e-01,  2.16215372e-01,\n",
       "        -4.12784815e-01,  2.67024636e-01],\n",
       "       [ 3.78316432e-01, -5.34435868e-01,  7.28449166e-01,\n",
       "         2.59835184e-01, -2.84890413e-01,  1.75606403e-02,\n",
       "         1.00000000e+00,  4.99059632e-02, -1.81477703e-02,\n",
       "         1.96120609e-02,  2.98938178e-03],\n",
       "       [ 5.21715999e-01, -1.71085030e-01,  7.84426749e-01,\n",
       "         6.80120438e-02,  8.83814469e-02,  1.45926088e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.21234789e-01, -2.73309976e-01,  5.50282337e-02,\n",
       "         2.08942622e-01, -6.05043769e-01,  2.23536938e-01,\n",
       "         1.00000000e+00,  2.04319045e-01, -1.25606954e-01,\n",
       "         1.08228721e-01,  1.86272502e-01],\n",
       "       [-1.49565890e-01, -2.01143082e-02, -3.17053139e-01,\n",
       "         3.21017876e-02,  4.71652523e-02,  8.88425261e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.64755756e-01, -1.23814449e-01,  7.64676690e-01,\n",
       "         1.47864193e-01, -2.67356932e-01,  3.47611755e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-2.89738148e-01, -5.94662488e-01,  3.82486343e-01,\n",
       "        -1.69240117e-01,  4.14137930e-01,  5.46477437e-01,\n",
       "         1.00000000e+00,  2.88253993e-01, -8.96618485e-01,\n",
       "         3.37645710e-01,  1.62894085e-01],\n",
       "       [-2.18661502e-01, -2.35328123e-01,  2.27450076e-02,\n",
       "        -1.39264166e-01, -9.21108120e-04,  4.29739773e-01,\n",
       "         1.00000000e+00,  2.15993121e-01,  2.51335260e-02,\n",
       "        -3.07540178e-01,  8.41417462e-02],\n",
       "       [-7.32083380e-01, -1.40782285e+00,  2.73049325e-01,\n",
       "        -1.35330424e-01, -6.33429527e-01,  3.93118598e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-6.27258837e-01, -1.92660183e-01,  7.05401361e-01,\n",
       "        -8.96618485e-01,  3.37645710e-01,  1.62894085e-01,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "905243bc-540d-46f6-9c5a-6caaf784c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards, dones, next_states = zip(*agents[4]._exp_buffer._buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5702e95c-526c-452f-a29b-42874b9866a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4714f00f40>]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(rewards[:200])\n",
    "plt.plot(agents[4]._exp_buffer._total_discounted_rewards[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32677946-80a3-47a8-aeb2-0991d02fd4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "3c5abf1f-ae4c-44de-ab02-2539bab10838",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = w_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a71bc-39cc-4b55-8535-e7ba79501868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "71892ce2-4de6-435e-a5b1-eaa101bbf755",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnityCommunicatorStoppedException",
     "evalue": "Communicator has exited.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityCommunicatorStoppedException\u001b[0m         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mdecide_action_and_set()\n\u001b[1;32m      9\u001b[0m     actions[agent_id] \u001b[38;5;241m=\u001b[39m action[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m agent_ids, states, rewards, dones \u001b[38;5;241m=\u001b[39m \u001b[43mw_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_id, agent \u001b[38;5;129;01min\u001b[39;00m agents\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     12\u001b[0m     agent\u001b[38;5;241m.\u001b[39mupdate_experience(agent_ids, states, rewards, dones, actions[agent_id])\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36mEnvWrapper.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     agent_ids, states, rewards, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent_ids, states, rewards, dones\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/timers.py:305\u001b[0m, in \u001b[0;36mtimed.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/environment.py:350\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicator\u001b[38;5;241m.\u001b[39mexchange(step_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_process)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnityCommunicatorStoppedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunicator has exited.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_behavior_specs(outputs)\n\u001b[1;32m    352\u001b[0m rl_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mrl_output\n",
      "\u001b[0;31mUnityCommunicatorStoppedException\u001b[0m: Communicator has exited."
     ]
    }
   ],
   "source": [
    "episode = 1\n",
    "\n",
    "while True:\n",
    "    # exploration\n",
    "    for step in range(TRAJECTORY_SIZE):\n",
    "        actions = {}\n",
    "        for agent_id, agent in agents.items():\n",
    "            action = agent.decide_action_and_set()\n",
    "            actions[agent_id] = action[0]\n",
    "        agent_ids, states, rewards, dones = w_env.step()\n",
    "        for agent_id, agent in agents.items():\n",
    "            agent.update_experience(agent_ids, states, rewards, dones, actions[agent_id])\n",
    "        if any(dones):\n",
    "            print(f'episode {episode} done')\n",
    "            _ = w_env.reset()\n",
    "            all_agents_rewards = []\n",
    "            for agent_id, agent in agents.items():\n",
    "                agent.reset_episode()\n",
    "                print(f'[ep{episode}] episode_rewards for agent {agent_id} : {agent._episode_rewards[-1]}')\n",
    "                all_agents_rewards.append(agent._episode_rewards[-1])\n",
    "            print(f'[ep{episode}] mean episode reward : {sum(all_agents_rewards) / len(all_agents_rewards)}')\n",
    "            episode += 1\n",
    "    # train\n",
    "    for agent_id, agent in agents.items():\n",
    "        agent.train(ppo_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "09d18102-b986-4e5d-9ed3-453e2c4e60c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mdecide_action_and_set()\n\u001b[1;32m      7\u001b[0m     actions[agent_id] \u001b[38;5;241m=\u001b[39m action[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m agent_ids, states, rewards, dones \u001b[38;5;241m=\u001b[39m \u001b[43mw_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_id, agent \u001b[38;5;129;01min\u001b[39;00m agents\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     agent\u001b[38;5;241m.\u001b[39mupdate_experience(agent_ids, states, rewards, dones, actions[agent_id])\n",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m, in \u001b[0;36mEnvWrapper.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     agent_ids, states, rewards, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent_ids, states, rewards, dones\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/timers.py:305\u001b[0m, in \u001b[0;36mtimed.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/environment.py:348\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m step_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_step_input(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env_actions)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunicator.exchange\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexchange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnityCommunicatorStoppedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunicator has exited.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/rpc_communicator.py:142\u001b[0m, in \u001b[0;36mRpcCommunicator.exchange\u001b[0;34m(self, inputs, poll_callback)\u001b[0m\n\u001b[1;32m    140\u001b[0m message\u001b[38;5;241m.\u001b[39munity_input\u001b[38;5;241m.\u001b[39mCopyFrom(inputs)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munity_to_external\u001b[38;5;241m.\u001b[39mparent_conn\u001b[38;5;241m.\u001b[39msend(message)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll_for_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munity_to_external\u001b[38;5;241m.\u001b[39mparent_conn\u001b[38;5;241m.\u001b[39mrecv()\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/rpc_communicator.py:106\u001b[0m, in \u001b[0;36mRpcCommunicator.poll_for_timeout\u001b[0;34m(self, poll_callback)\u001b[0m\n\u001b[1;32m    104\u001b[0m callback_timeout_wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout_wait \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m<\u001b[39m deadline:\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munity_to_external\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback_timeout_wait\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;66;03m# Got an acknowledgment from the connection\u001b[39;00m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m poll_callback:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# Fire the callback - if it detects something wrong, it should raise an exception.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    # exploration\n",
    "    for step in range(TRAJECTORY_SIZE):\n",
    "        actions = {}\n",
    "        for agent_id, agent in agents.items():\n",
    "            action = agent.decide_action_and_set()\n",
    "            actions[agent_id] = action[0]\n",
    "        agent_ids, states, rewards, dones = w_env.step()\n",
    "        for agent_id, agent in agents.items():\n",
    "            agent.update_experience(agent_ids, states, rewards, dones, actions[agent_id])\n",
    "        if any(dones):\n",
    "            print(f'episode {episode} done')\n",
    "            _ = w_env.reset()\n",
    "            all_agents_rewards = []\n",
    "            for agent_id, agent in agents.items():\n",
    "                agent.reset_episode()\n",
    "                print(f'[ep{episode}] episode_rewards for agent {agent_id} : {agent._episode_rewards[-1]}')\n",
    "                all_agents_rewards.append(agent._episode_rewards[-1])\n",
    "            print(f'[ep{episode}] mean episode reward : {sum(all_agents_rewards) / len(all_agents_rewards)}')\n",
    "            episode += 1\n",
    "    # train\n",
    "    for agent_id, agent in agents.items():\n",
    "        agent.train(ppo_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5074757a-9d7b-4624-941c-42d7d5b97e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "642b3cd5-9800-4f67-86c2-b6baa011fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dicts = {}\n",
    "\n",
    "# for agent_id, agent in agents.items():\n",
    "#     state_dicts[f'crt_{agent_id}'] = agent._crt_net.state_dict()\n",
    "#     state_dicts[f'act_{agent_id}'] = agent._act_net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "efbc4889-f2c0-4e1d-b33d-3f9595e1ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(state_dicts, './tmp_foid_multiagent_1269ep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855291bf-fc1c-44e5-93f6-4aac236ebc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7b231-411f-4aa2-8944-01b3723d6953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8840faa9-9a2e-439b-a028-2454ac753223",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1 done\n",
      "[ep1] episode_rewards for agent 0 : -21.921998978592455\n",
      "[ep1] episode_rewards for agent 1 : -40.05599792022258\n",
      "[ep1] episode_rewards for agent 2 : -27.72399866487831\n",
      "[ep1] episode_rewards for agent 3 : -10.13199975900352\n",
      "[ep1] episode_rewards for agent 4 : -44.28799757733941\n",
      "[ep1] episode_rewards for agent 5 : -43.07599766366184\n",
      "[ep1] episode_rewards for agent 6 : -38.303998006507754\n",
      "[ep1] episode_rewards for agent 7 : -25.31599887367338\n",
      "[ep1] episode_rewards for agent 8 : -25.55999868363142\n",
      "[ep1] episode_rewards for agent 9 : -18.32799939252436\n",
      "[ep1] mean episode reward : -29.4705985520035\n",
      "episode 2 done\n",
      "[ep2] episode_rewards for agent 0 : -15.029999407939613\n",
      "[ep2] episode_rewards for agent 1 : -2.3480003410950303\n",
      "[ep2] episode_rewards for agent 2 : -36.807998130097985\n",
      "[ep2] episode_rewards for agent 3 : -33.21999821532518\n",
      "[ep2] episode_rewards for agent 4 : -36.12399821728468\n",
      "[ep2] episode_rewards for agent 5 : -45.407997554168105\n",
      "[ep2] episode_rewards for agent 6 : -27.05199884623289\n",
      "[ep2] episode_rewards for agent 7 : -17.031999364495277\n",
      "[ep2] episode_rewards for agent 8 : -42.87199784908444\n",
      "[ep2] episode_rewards for agent 9 : -40.29199784900993\n",
      "[ep2] mean episode reward : -29.618598577473314\n",
      "episode 3 done\n",
      "[ep3] episode_rewards for agent 0 : -35.18199835345149\n",
      "[ep3] episode_rewards for agent 1 : -43.251997612416744\n",
      "[ep3] episode_rewards for agent 2 : -42.1399978287518\n",
      "[ep3] episode_rewards for agent 3 : -36.515998400747776\n",
      "[ep3] episode_rewards for agent 4 : -33.62799825426191\n",
      "[ep3] episode_rewards for agent 5 : -17.607999252155423\n",
      "[ep3] episode_rewards for agent 6 : -38.91999810561538\n",
      "[ep3] episode_rewards for agent 7 : -17.75199931114912\n",
      "[ep3] episode_rewards for agent 8 : -45.151997541077435\n",
      "[ep3] episode_rewards for agent 9 : -45.80399737972766\n",
      "[ep3] mean episode reward : -35.595398203935474\n",
      "episode 4 done\n",
      "[ep4] episode_rewards for agent 0 : -38.3459980674088\n",
      "[ep4] episode_rewards for agent 1 : -47.16799751203507\n",
      "[ep4] episode_rewards for agent 2 : -26.43199882656336\n",
      "[ep4] episode_rewards for agent 3 : -33.183998545631766\n",
      "[ep4] episode_rewards for agent 4 : -54.13199698459357\n",
      "[ep4] episode_rewards for agent 5 : -33.38399847783148\n",
      "[ep4] episode_rewards for agent 6 : -52.21999713033438\n",
      "[ep4] episode_rewards for agent 7 : -17.687999395653605\n",
      "[ep4] episode_rewards for agent 8 : -46.75199757143855\n",
      "[ep4] episode_rewards for agent 9 : -42.6439976869151\n",
      "[ep4] mean episode reward : -39.19499801984057\n",
      "episode 5 done\n",
      "[ep5] episode_rewards for agent 0 : -13.529999510385096\n",
      "[ep5] episode_rewards for agent 1 : -59.787996450439095\n",
      "[ep5] episode_rewards for agent 2 : -29.02399867400527\n",
      "[ep5] episode_rewards for agent 3 : -37.57999829854816\n",
      "[ep5] episode_rewards for agent 4 : 25.5359979653731\n",
      "[ep5] episode_rewards for agent 5 : -6.947999814525247\n",
      "[ep5] episode_rewards for agent 6 : -46.64799760747701\n",
      "[ep5] episode_rewards for agent 7 : -39.98399777058512\n",
      "[ep5] episode_rewards for agent 8 : -36.27199814468622\n",
      "[ep5] episode_rewards for agent 9 : -23.91999892424792\n",
      "[ep5] mean episode reward : -26.815798722952604\n",
      "episode 6 done\n",
      "[ep6] episode_rewards for agent 0 : -25.389998850412667\n",
      "[ep6] episode_rewards for agent 1 : -47.23199734464288\n",
      "[ep6] episode_rewards for agent 2 : -21.471999225206673\n",
      "[ep6] episode_rewards for agent 3 : -37.3759982008487\n",
      "[ep6] episode_rewards for agent 4 : -50.76799727603793\n",
      "[ep6] episode_rewards for agent 5 : 12.423998717218637\n",
      "[ep6] episode_rewards for agent 6 : -40.74799798429012\n",
      "[ep6] episode_rewards for agent 7 : -54.81199684552848\n",
      "[ep6] episode_rewards for agent 8 : -36.46799826808274\n",
      "[ep6] episode_rewards for agent 9 : -14.231999445706606\n",
      "[ep6] mean episode reward : -31.607398472353815\n",
      "episode 7 done\n",
      "[ep7] episode_rewards for agent 0 : 1.9859995227307081\n",
      "[ep7] episode_rewards for agent 1 : -54.48399694170803\n",
      "[ep7] episode_rewards for agent 2 : -5.73200015258044\n",
      "[ep7] episode_rewards for agent 3 : -29.92399863805622\n",
      "[ep7] episode_rewards for agent 4 : -10.043999686837196\n",
      "[ep7] episode_rewards for agent 5 : 0.23599946685135365\n",
      "[ep7] episode_rewards for agent 6 : -40.70799805782735\n",
      "[ep7] episode_rewards for agent 7 : -49.731997285969555\n",
      "[ep7] episode_rewards for agent 8 : -38.16399792581797\n",
      "[ep7] episode_rewards for agent 9 : -38.795997858047485\n",
      "[ep7] mean episode reward : -26.536198755726218\n",
      "episode 8 done\n",
      "[ep8] episode_rewards for agent 0 : -10.361999701708555\n",
      "[ep8] episode_rewards for agent 1 : -47.81199742760509\n",
      "[ep8] episode_rewards for agent 2 : -30.439998446032405\n",
      "[ep8] episode_rewards for agent 3 : -37.1039982419461\n",
      "[ep8] episode_rewards for agent 4 : -25.351998961530626\n",
      "[ep8] episode_rewards for agent 5 : 16.743998559191823\n",
      "[ep8] episode_rewards for agent 6 : -36.523998155258596\n",
      "[ep8] episode_rewards for agent 7 : -25.503999188542366\n",
      "[ep8] episode_rewards for agent 8 : -53.55599696747959\n",
      "[ep8] episode_rewards for agent 9 : -25.57999877166003\n",
      "[ep8] mean episode reward : -27.548998730257154\n",
      "episode 9 done\n",
      "[ep9] episode_rewards for agent 0 : -1.850000474601984\n",
      "[ep9] episode_rewards for agent 1 : -48.51599732879549\n",
      "[ep9] episode_rewards for agent 2 : -23.38399895373732\n",
      "[ep9] episode_rewards for agent 3 : -39.14399815350771\n",
      "[ep9] episode_rewards for agent 4 : -0.3120002802461386\n",
      "[ep9] episode_rewards for agent 5 : 4.683999288827181\n",
      "[ep9] episode_rewards for agent 6 : -54.29999689478427\n",
      "[ep9] episode_rewards for agent 7 : -55.891996793448925\n",
      "[ep9] episode_rewards for agent 8 : -46.659997534006834\n",
      "[ep9] episode_rewards for agent 9 : -10.399999743327498\n",
      "[ep9] mean episode reward : -27.577398686762898\n",
      "episode 10 done\n",
      "[ep10] episode_rewards for agent 0 : -19.937999344430864\n",
      "[ep10] episode_rewards for agent 1 : -51.159997168928385\n",
      "[ep10] episode_rewards for agent 2 : -52.94799705315381\n",
      "[ep10] episode_rewards for agent 3 : -29.179998924955726\n",
      "[ep10] episode_rewards for agent 4 : -8.292000019922853\n",
      "[ep10] episode_rewards for agent 5 : -5.216000497341156\n",
      "[ep10] episode_rewards for agent 6 : -53.759997013024986\n",
      "[ep10] episode_rewards for agent 7 : -37.08399797603488\n",
      "[ep10] episode_rewards for agent 8 : -50.279997220262885\n",
      "[ep10] episode_rewards for agent 9 : 52.68399649485946\n",
      "[ep10] mean episode reward : -25.51739887231961\n",
      "episode 11 done\n",
      "[ep11] episode_rewards for agent 0 : -25.91799894347787\n",
      "[ep11] episode_rewards for agent 1 : -38.60399810783565\n",
      "[ep11] episode_rewards for agent 2 : -24.555998967029154\n",
      "[ep11] episode_rewards for agent 3 : -44.06799769774079\n",
      "[ep11] episode_rewards for agent 4 : -14.11599944345653\n",
      "[ep11] episode_rewards for agent 5 : -24.847998900339007\n",
      "[ep11] episode_rewards for agent 6 : -40.763998066075146\n",
      "[ep11] episode_rewards for agent 7 : -25.99999895878136\n",
      "[ep11] episode_rewards for agent 8 : -36.49599828757346\n",
      "[ep11] episode_rewards for agent 9 : -24.49599885288626\n",
      "[ep11] mean episode reward : -29.986598622519523\n",
      "episode 12 done\n",
      "[ep12] episode_rewards for agent 0 : 35.761997386813164\n",
      "[ep12] episode_rewards for agent 1 : -44.58799745608121\n",
      "[ep12] episode_rewards for agent 2 : -20.195999174378812\n",
      "[ep12] episode_rewards for agent 3 : -33.611998435109854\n",
      "[ep12] episode_rewards for agent 4 : 92.82799404207617\n",
      "[ep12] episode_rewards for agent 5 : 61.32799587678164\n",
      "[ep12] episode_rewards for agent 6 : -35.559998374432325\n",
      "[ep12] episode_rewards for agent 7 : -51.443997181952\n",
      "[ep12] episode_rewards for agent 8 : -54.20399691723287\n",
      "[ep12] episode_rewards for agent 9 : 44.287996959872544\n",
      "[ep12] mean episode reward : -0.5398003273643553\n",
      "episode 13 done\n",
      "[ep13] episode_rewards for agent 0 : -42.64999791793525\n",
      "[ep13] episode_rewards for agent 1 : -44.12399768549949\n",
      "[ep13] episode_rewards for agent 2 : -44.943997617810965\n",
      "[ep13] episode_rewards for agent 3 : -34.44399864599109\n",
      "[ep13] episode_rewards for agent 4 : -7.856000226922333\n",
      "[ep13] episode_rewards for agent 5 : 76.82399479206651\n",
      "[ep13] episode_rewards for agent 6 : -48.007997469976544\n",
      "[ep13] episode_rewards for agent 7 : -56.93599667213857\n",
      "[ep13] episode_rewards for agent 8 : -45.9759975373745\n",
      "[ep13] episode_rewards for agent 9 : -15.983999695628881\n",
      "[ep13] mean episode reward : -26.40979886772111\n",
      "episode 14 done\n",
      "[ep14] episode_rewards for agent 0 : 17.297998383641243\n",
      "[ep14] episode_rewards for agent 1 : -43.547997570596635\n",
      "[ep14] episode_rewards for agent 2 : -50.53599706944078\n",
      "[ep14] episode_rewards for agent 3 : -35.16399839054793\n",
      "[ep14] episode_rewards for agent 4 : 29.0679978961125\n",
      "[ep14] episode_rewards for agent 5 : 107.78399309143424\n",
      "[ep14] episode_rewards for agent 6 : -35.831998305395246\n",
      "[ep14] episode_rewards for agent 7 : -48.77599732764065\n",
      "[ep14] episode_rewards for agent 8 : -48.73999734967947\n",
      "[ep14] episode_rewards for agent 9 : 35.37599757499993\n",
      "[ep14] mean episode reward : -7.3069999067112805\n",
      "episode 15 done\n",
      "[ep15] episode_rewards for agent 0 : -29.793998582288623\n",
      "[ep15] episode_rewards for agent 1 : -59.10799650661647\n",
      "[ep15] episode_rewards for agent 2 : -35.01199842616916\n",
      "[ep15] episode_rewards for agent 3 : -41.72399790585041\n",
      "[ep15] episode_rewards for agent 4 : -34.475998408161104\n",
      "[ep15] episode_rewards for agent 5 : 45.83199676964432\n",
      "[ep15] episode_rewards for agent 6 : -37.27199826948345\n",
      "[ep15] episode_rewards for agent 7 : -45.25599761400372\n",
      "[ep15] episode_rewards for agent 8 : -51.343997224234045\n",
      "[ep15] episode_rewards for agent 9 : 140.2919913046062\n",
      "[ep15] mean episode reward : -14.786199486255645\n",
      "episode 16 done\n",
      "[ep16] episode_rewards for agent 0 : 7.689998907968402\n",
      "[ep16] episode_rewards for agent 1 : -51.57599707785994\n",
      "[ep16] episode_rewards for agent 2 : -59.843996442854404\n",
      "[ep16] episode_rewards for agent 3 : -43.26399789750576\n",
      "[ep16] episode_rewards for agent 4 : -21.0599995655939\n",
      "[ep16] episode_rewards for agent 5 : -41.11199817992747\n",
      "[ep16] episode_rewards for agent 6 : -38.707998029887676\n",
      "[ep16] episode_rewards for agent 7 : -47.24799753911793\n",
      "[ep16] episode_rewards for agent 8 : -47.83999754395336\n",
      "[ep16] episode_rewards for agent 9 : 66.4319956721738\n",
      "[ep16] mean episode reward : -27.652998769655824\n",
      "episode 17 done\n",
      "[ep17] episode_rewards for agent 0 : -7.262000109069049\n",
      "[ep17] episode_rewards for agent 1 : -51.543997164815664\n",
      "[ep17] episode_rewards for agent 2 : -26.55599906295538\n",
      "[ep17] episode_rewards for agent 3 : 4.839999013580382\n",
      "[ep17] episode_rewards for agent 4 : 13.031998716294765\n",
      "[ep17] episode_rewards for agent 5 : -33.61999876331538\n",
      "[ep17] episode_rewards for agent 6 : -48.65599729772657\n",
      "[ep17] episode_rewards for agent 7 : -46.7719974918291\n",
      "[ep17] episode_rewards for agent 8 : -45.55599755421281\n",
      "[ep17] episode_rewards for agent 9 : 35.94799742102623\n",
      "[ep17] mean episode reward : -20.614599229302257\n",
      "episode 18 done\n",
      "[ep18] episode_rewards for agent 0 : 6.1579993031919\n",
      "[ep18] episode_rewards for agent 1 : -32.02399830240756\n",
      "[ep18] episode_rewards for agent 2 : -36.81199802458286\n",
      "[ep18] episode_rewards for agent 3 : -20.727999142371118\n",
      "[ep18] episode_rewards for agent 4 : 5.287999387830496\n",
      "[ep18] episode_rewards for agent 5 : 4.603998844511807\n",
      "[ep18] episode_rewards for agent 6 : -25.647999024018645\n",
      "[ep18] episode_rewards for agent 7 : -35.73999836854637\n",
      "[ep18] episode_rewards for agent 8 : -53.735996909439564\n",
      "[ep18] episode_rewards for agent 9 : 9.567998880520463\n",
      "[ep18] mean episode reward : -17.906999335531147\n",
      "episode 19 done\n",
      "[ep19] episode_rewards for agent 0 : 61.50199598632753\n",
      "[ep19] episode_rewards for agent 1 : -38.687997840344906\n",
      "[ep19] episode_rewards for agent 2 : -29.095998767763376\n",
      "[ep19] episode_rewards for agent 3 : -34.06799870543182\n",
      "[ep19] episode_rewards for agent 4 : 34.935997404158115\n",
      "[ep19] episode_rewards for agent 5 : 39.77599695511162\n",
      "[ep19] episode_rewards for agent 6 : -40.12799801491201\n",
      "[ep19] episode_rewards for agent 7 : -26.639998745173216\n",
      "[ep19] episode_rewards for agent 8 : -53.251996936276555\n",
      "[ep19] episode_rewards for agent 9 : 8.32399907708168\n",
      "[ep19] mean episode reward : -7.733399958722293\n",
      "episode 20 done\n",
      "[ep20] episode_rewards for agent 0 : -3.698000321164727\n",
      "[ep20] episode_rewards for agent 1 : -47.57199746277183\n",
      "[ep20] episode_rewards for agent 2 : -37.887997863814235\n",
      "[ep20] episode_rewards for agent 3 : -21.183999553322792\n",
      "[ep20] episode_rewards for agent 4 : 33.623997521586716\n",
      "[ep20] episode_rewards for agent 5 : 72.95599520392716\n",
      "[ep20] episode_rewards for agent 6 : -51.45599711313844\n",
      "[ep20] episode_rewards for agent 7 : -34.31999857444316\n",
      "[ep20] episode_rewards for agent 8 : -55.76399677898735\n",
      "[ep20] episode_rewards for agent 9 : 50.047996503300965\n",
      "[ep20] mean episode reward : -9.52539984388277\n",
      "episode 21 done\n",
      "[ep21] episode_rewards for agent 0 : 43.00599689222872\n",
      "[ep21] episode_rewards for agent 1 : -41.2559977741912\n",
      "[ep21] episode_rewards for agent 2 : -19.795999156311154\n",
      "[ep21] episode_rewards for agent 3 : -29.599998614750803\n",
      "[ep21] episode_rewards for agent 4 : 18.98399835359305\n",
      "[ep21] episode_rewards for agent 5 : -0.6640004236251116\n",
      "[ep21] episode_rewards for agent 6 : -52.15599711891264\n",
      "[ep21] episode_rewards for agent 7 : -51.41199717577547\n",
      "[ep21] episode_rewards for agent 8 : -42.091998079791665\n",
      "[ep21] episode_rewards for agent 9 : 47.07199671771377\n",
      "[ep21] mean episode reward : -12.791399637982249\n",
      "episode 22 done\n",
      "[ep22] episode_rewards for agent 0 : 23.03399811591953\n",
      "[ep22] episode_rewards for agent 1 : -54.5799968643114\n",
      "[ep22] episode_rewards for agent 2 : -31.923998639918864\n",
      "[ep22] episode_rewards for agent 3 : -27.02399929240346\n",
      "[ep22] episode_rewards for agent 4 : 24.027997877448797\n",
      "[ep22] episode_rewards for agent 5 : -44.88399766385555\n",
      "[ep22] episode_rewards for agent 6 : -52.65199712570757\n",
      "[ep22] episode_rewards for agent 7 : -42.183998016640544\n",
      "[ep22] episode_rewards for agent 8 : -47.415997450239956\n",
      "[ep22] episode_rewards for agent 9 : 10.39999901689589\n",
      "[ep22] mean episode reward : -24.320199004281314\n",
      "episode 23 done\n",
      "[ep23] episode_rewards for agent 0 : -27.965998734347522\n",
      "[ep23] episode_rewards for agent 1 : -47.96399732027203\n",
      "[ep23] episode_rewards for agent 2 : -37.203998050652444\n",
      "[ep23] episode_rewards for agent 3 : -21.45199951622635\n",
      "[ep23] episode_rewards for agent 4 : 34.86399753112346\n",
      "[ep23] episode_rewards for agent 5 : 89.49999413825572\n",
      "[ep23] episode_rewards for agent 6 : -38.31599827297032\n",
      "[ep23] episode_rewards for agent 7 : -45.65999773237854\n",
      "[ep23] episode_rewards for agent 8 : -51.23599717207253\n",
      "[ep23] episode_rewards for agent 9 : 98.21599364187568\n",
      "[ep23] mean episode reward : -4.721800148766488\n",
      "episode 24 done\n",
      "[ep24] episode_rewards for agent 0 : 36.78599705453962\n",
      "[ep24] episode_rewards for agent 1 : -46.043997700326145\n",
      "[ep24] episode_rewards for agent 2 : -30.451998364180326\n",
      "[ep24] episode_rewards for agent 3 : -32.05599866807461\n",
      "[ep24] episode_rewards for agent 4 : 22.595998287200928\n",
      "[ep24] episode_rewards for agent 5 : -16.739999269135296\n",
      "[ep24] episode_rewards for agent 6 : -32.923998459242284\n",
      "[ep24] episode_rewards for agent 7 : -36.66799846570939\n",
      "[ep24] episode_rewards for agent 8 : -48.8679973334074\n",
      "[ep24] episode_rewards for agent 9 : 68.1799954995513\n",
      "[ep24] mean episode reward : -11.61899974187836\n",
      "episode 25 done\n",
      "[ep25] episode_rewards for agent 0 : 47.87399662844837\n",
      "[ep25] episode_rewards for agent 1 : -8.547999640926719\n",
      "[ep25] episode_rewards for agent 2 : -42.671997646801174\n",
      "[ep25] episode_rewards for agent 3 : -28.03599875047803\n",
      "[ep25] episode_rewards for agent 4 : 25.579997955821455\n",
      "[ep25] episode_rewards for agent 5 : -7.180000068619847\n",
      "[ep25] episode_rewards for agent 6 : -44.19599787518382\n",
      "[ep25] episode_rewards for agent 7 : -51.32799721322954\n",
      "[ep25] episode_rewards for agent 8 : -53.999996926635504\n",
      "[ep25] episode_rewards for agent 9 : 83.92799458745867\n",
      "[ep25] mean episode reward : -7.8577998950146135\n",
      "episode 26 done\n",
      "[ep26] episode_rewards for agent 0 : 95.08999391272664\n",
      "[ep26] episode_rewards for agent 1 : -59.50799647253007\n",
      "[ep26] episode_rewards for agent 2 : 37.25599693413824\n",
      "[ep26] episode_rewards for agent 3 : -25.267999479547143\n",
      "[ep26] episode_rewards for agent 4 : -15.055999657139182\n",
      "[ep26] episode_rewards for agent 5 : 87.41199441812932\n",
      "[ep26] episode_rewards for agent 6 : -50.45999725535512\n",
      "[ep26] episode_rewards for agent 7 : -40.31999809388071\n",
      "[ep26] episode_rewards for agent 8 : -44.2599978428334\n",
      "[ep26] episode_rewards for agent 9 : 68.67999554146081\n",
      "[ep26] mean episode reward : 5.356599200516939\n",
      "episode 27 done\n",
      "[ep27] episode_rewards for agent 0 : 6.473999242298305\n",
      "[ep27] episode_rewards for agent 1 : -46.15999765601009\n",
      "[ep27] episode_rewards for agent 2 : -15.431999746710062\n",
      "[ep27] episode_rewards for agent 3 : -26.071999365463853\n",
      "[ep27] episode_rewards for agent 4 : 8.079998985864222\n",
      "[ep27] episode_rewards for agent 5 : 86.8679941855371\n",
      "[ep27] episode_rewards for agent 6 : -54.1919969515875\n",
      "[ep27] episode_rewards for agent 7 : -31.915998722426593\n",
      "[ep27] episode_rewards for agent 8 : -55.18399683572352\n",
      "[ep27] episode_rewards for agent 9 : 17.323998532257974\n",
      "[ep27] mean episode reward : -11.020999833196402\n",
      "episode 28 done\n",
      "[ep28] episode_rewards for agent 0 : 39.02999714296311\n",
      "[ep28] episode_rewards for agent 1 : -49.351997279562056\n",
      "[ep28] episode_rewards for agent 2 : -25.75999863818288\n",
      "[ep28] episode_rewards for agent 3 : -35.567998265847564\n",
      "[ep28] episode_rewards for agent 4 : -4.23200025036931\n",
      "[ep28] episode_rewards for agent 5 : 52.691996194422245\n",
      "[ep28] episode_rewards for agent 6 : -40.427997971884906\n",
      "[ep28] episode_rewards for agent 7 : -33.49199865292758\n",
      "[ep28] episode_rewards for agent 8 : -48.583997406065464\n",
      "[ep28] episode_rewards for agent 9 : 11.479998918250203\n",
      "[ep28] mean episode reward : -13.42139962092042\n",
      "episode 29 done\n",
      "[ep29] episode_rewards for agent 0 : 15.70999867003411\n",
      "[ep29] episode_rewards for agent 1 : -47.007997397333384\n",
      "[ep29] episode_rewards for agent 2 : -30.81199840735644\n",
      "[ep29] episode_rewards for agent 3 : -28.887999307364225\n",
      "[ep29] episode_rewards for agent 4 : 28.523998010903597\n",
      "[ep29] episode_rewards for agent 5 : -9.731999708339572\n",
      "[ep29] episode_rewards for agent 6 : -41.815998014993966\n",
      "[ep29] episode_rewards for agent 7 : -24.95599917601794\n",
      "[ep29] episode_rewards for agent 8 : -55.61199683602899\n",
      "[ep29] episode_rewards for agent 9 : 67.98799542058259\n",
      "[ep29] mean episode reward : -12.660199674591421\n",
      "episode 30 done\n",
      "[ep30] episode_rewards for agent 0 : 66.6059956876561\n",
      "[ep30] episode_rewards for agent 1 : -58.707996557466686\n",
      "[ep30] episode_rewards for agent 2 : -30.859998697414994\n",
      "[ep30] episode_rewards for agent 3 : -32.539998987689614\n",
      "[ep30] episode_rewards for agent 4 : 28.24799779523164\n",
      "[ep30] episode_rewards for agent 5 : -4.044000414200127\n",
      "[ep30] episode_rewards for agent 6 : -57.0599966943264\n",
      "[ep30] episode_rewards for agent 7 : -35.91199822630733\n",
      "[ep30] episode_rewards for agent 8 : -50.22799729369581\n",
      "[ep30] episode_rewards for agent 9 : 37.855997344478965\n",
      "[ep30] mean episode reward : -13.664199604373426\n",
      "episode 31 done\n",
      "[ep31] episode_rewards for agent 0 : 25.773997746407986\n",
      "[ep31] episode_rewards for agent 1 : -44.63599753193557\n",
      "[ep31] episode_rewards for agent 2 : -48.81599727459252\n",
      "[ep31] episode_rewards for agent 3 : -52.65599711518735\n",
      "[ep31] episode_rewards for agent 4 : 32.83199758641422\n",
      "[ep31] episode_rewards for agent 5 : 55.29199627041817\n",
      "[ep31] episode_rewards for agent 6 : -33.395998758263886\n",
      "[ep31] episode_rewards for agent 7 : -30.89999871328473\n",
      "[ep31] episode_rewards for agent 8 : -33.97199878003448\n",
      "[ep31] episode_rewards for agent 9 : 39.555997209623456\n",
      "[ep31] mean episode reward : -9.092199936043471\n",
      "episode 32 done\n",
      "[ep32] episode_rewards for agent 0 : -22.337999037466943\n",
      "[ep32] episode_rewards for agent 1 : -43.643997645005584\n",
      "[ep32] episode_rewards for agent 2 : -30.339998696930707\n",
      "[ep32] episode_rewards for agent 3 : -35.46399837732315\n",
      "[ep32] episode_rewards for agent 4 : 22.683997972868383\n",
      "[ep32] episode_rewards for agent 5 : 76.09199510328472\n",
      "[ep32] episode_rewards for agent 6 : -46.375997574068606\n",
      "[ep32] episode_rewards for agent 7 : -46.179997579194605\n",
      "[ep32] episode_rewards for agent 8 : -52.25599706824869\n",
      "[ep32] episode_rewards for agent 9 : 55.77199626713991\n",
      "[ep32] mean episode reward : -12.204999663494528\n",
      "episode 33 done\n",
      "[ep33] episode_rewards for agent 0 : 24.565997906029224\n",
      "[ep33] episode_rewards for agent 1 : -54.64399683382362\n",
      "[ep33] episode_rewards for agent 2 : -53.787996888160706\n",
      "[ep33] episode_rewards for agent 3 : -35.043998619541526\n",
      "[ep33] episode_rewards for agent 4 : 30.403997563757002\n",
      "[ep33] episode_rewards for agent 5 : 40.48399705067277\n",
      "[ep33] episode_rewards for agent 6 : -26.967998857609928\n",
      "[ep33] episode_rewards for agent 7 : -37.67199828568846\n",
      "[ep33] episode_rewards for agent 8 : -42.84399791713804\n",
      "[ep33] episode_rewards for agent 9 : 3.067999519407749\n",
      "[ep33] mean episode reward : -15.243799536209554\n",
      "episode 34 done\n",
      "[ep34] episode_rewards for agent 0 : 31.233997587114573\n",
      "[ep34] episode_rewards for agent 1 : -42.727997825481\n",
      "[ep34] episode_rewards for agent 2 : -48.60799722094089\n",
      "[ep34] episode_rewards for agent 3 : -35.65199848823249\n",
      "[ep34] episode_rewards for agent 4 : 8.155999070033431\n",
      "[ep34] episode_rewards for agent 5 : 30.03199756052345\n",
      "[ep34] episode_rewards for agent 6 : -51.995997155085206\n",
      "[ep34] episode_rewards for agent 7 : -43.647997685708106\n",
      "[ep34] episode_rewards for agent 8 : -46.89599750749767\n",
      "[ep34] episode_rewards for agent 9 : 67.32799542881548\n",
      "[ep34] mean episode reward : -13.277799623645842\n",
      "episode 35 done\n",
      "[ep35] episode_rewards for agent 0 : 94.95399383362383\n",
      "[ep35] episode_rewards for agent 1 : -57.90799661818892\n",
      "[ep35] episode_rewards for agent 2 : 1.0599996587261558\n",
      "[ep35] episode_rewards for agent 3 : -41.82799811381847\n",
      "[ep35] episode_rewards for agent 4 : 71.82799503579736\n",
      "[ep35] episode_rewards for agent 5 : 129.89599183853716\n",
      "[ep35] episode_rewards for agent 6 : -36.71199856232852\n",
      "[ep35] episode_rewards for agent 7 : -43.08399799186736\n",
      "[ep35] episode_rewards for agent 8 : -47.29999751318246\n",
      "[ep35] episode_rewards for agent 9 : 51.71999645419419\n",
      "[ep35] mean episode reward : 12.262598802149295\n",
      "episode 36 done\n",
      "[ep36] episode_rewards for agent 0 : 17.88999825809151\n",
      "[ep36] episode_rewards for agent 1 : -56.57599668297917\n",
      "[ep36] episode_rewards for agent 2 : -46.0759974103421\n",
      "[ep36] episode_rewards for agent 3 : -32.04799885582179\n",
      "[ep36] episode_rewards for agent 4 : 43.19599694851786\n",
      "[ep36] episode_rewards for agent 5 : 5.983999012969434\n",
      "[ep36] episode_rewards for agent 6 : -44.11199793126434\n",
      "[ep36] episode_rewards for agent 7 : -34.47999857831746\n",
      "[ep36] episode_rewards for agent 8 : -43.87999770604074\n",
      "[ep36] episode_rewards for agent 9 : 70.2759952833876\n",
      "[ep36] mean episode reward : -11.98259976617992\n",
      "episode 37 done\n",
      "[ep37] episode_rewards for agent 0 : 45.59799668379128\n",
      "[ep37] episode_rewards for agent 1 : -56.69999673124403\n",
      "[ep37] episode_rewards for agent 2 : -51.003997126594186\n",
      "[ep37] episode_rewards for agent 3 : -31.059999069198966\n",
      "[ep37] episode_rewards for agent 4 : 34.4999973224476\n",
      "[ep37] episode_rewards for agent 5 : 21.675998193211854\n",
      "[ep37] episode_rewards for agent 6 : -43.14799791201949\n",
      "[ep37] episode_rewards for agent 7 : -38.675998088903725\n",
      "[ep37] episode_rewards for agent 8 : -48.02799744531512\n",
      "[ep37] episode_rewards for agent 9 : 53.53999634645879\n",
      "[ep37] mean episode reward : -11.3301997827366\n",
      "episode 38 done\n",
      "[ep38] episode_rewards for agent 0 : 24.46999808959663\n",
      "[ep38] episode_rewards for agent 1 : -52.14399713743478\n",
      "[ep38] episode_rewards for agent 2 : -27.307998668402433\n",
      "[ep38] episode_rewards for agent 3 : -38.167998349294066\n",
      "[ep38] episode_rewards for agent 4 : 3.1279992423951626\n",
      "[ep38] episode_rewards for agent 5 : 0.14399983454495668\n",
      "[ep38] episode_rewards for agent 6 : -28.63199898507446\n",
      "[ep38] episode_rewards for agent 7 : -54.16799691412598\n",
      "[ep38] episode_rewards for agent 8 : -30.819999075494707\n",
      "[ep38] episode_rewards for agent 9 : 63.69199573714286\n",
      "[ep38] mean episode reward : -13.980599622614681\n",
      "episode 39 done\n",
      "[ep39] episode_rewards for agent 0 : -10.129999834112823\n",
      "[ep39] episode_rewards for agent 1 : -41.695998144336045\n",
      "[ep39] episode_rewards for agent 2 : -13.167999483644962\n",
      "[ep39] episode_rewards for agent 3 : -36.93199840467423\n",
      "[ep39] episode_rewards for agent 4 : -12.791999658569694\n",
      "[ep39] episode_rewards for agent 5 : 106.71599335223436\n",
      "[ep39] episode_rewards for agent 6 : -42.9199978755787\n",
      "[ep39] episode_rewards for agent 7 : -33.80799823720008\n",
      "[ep39] episode_rewards for agent 8 : -46.31599757820368\n",
      "[ep39] episode_rewards for agent 9 : -21.671999223530293\n",
      "[ep39] mean episode reward : -15.271799508761614\n",
      "episode 40 done\n",
      "[ep40] episode_rewards for agent 0 : 58.87399595603347\n",
      "[ep40] episode_rewards for agent 1 : -48.36399736814201\n",
      "[ep40] episode_rewards for agent 2 : 42.751997145824134\n",
      "[ep40] episode_rewards for agent 3 : -37.21599854063243\n",
      "[ep40] episode_rewards for agent 4 : 22.923998263664544\n",
      "[ep40] episode_rewards for agent 5 : 70.1479954579845\n",
      "[ep40] episode_rewards for agent 6 : -41.835997795686126\n",
      "[ep40] episode_rewards for agent 7 : -44.38399777933955\n",
      "[ep40] episode_rewards for agent 8 : -49.05999742168933\n",
      "[ep40] episode_rewards for agent 9 : 104.80399338249117\n",
      "[ep40] mean episode reward : 7.864199130050838\n",
      "episode 41 done\n",
      "[ep41] episode_rewards for agent 0 : 42.26199685037136\n",
      "[ep41] episode_rewards for agent 1 : -46.40799754485488\n",
      "[ep41] episode_rewards for agent 2 : 7.499999067746103\n",
      "[ep41] episode_rewards for agent 3 : -31.623998755589128\n",
      "[ep41] episode_rewards for agent 4 : 9.855998958460987\n",
      "[ep41] episode_rewards for agent 5 : -18.907999231480062\n",
      "[ep41] episode_rewards for agent 6 : -25.83599904924631\n",
      "[ep41] episode_rewards for agent 7 : -47.799997463822365\n",
      "[ep41] episode_rewards for agent 8 : -41.283997908234596\n",
      "[ep41] episode_rewards for agent 9 : 105.44399321265519\n",
      "[ep41] mean episode reward : -4.679800186399371\n",
      "episode 42 done\n",
      "[ep42] episode_rewards for agent 0 : 17.405998448841274\n",
      "[ep42] episode_rewards for agent 1 : -51.219997125677764\n",
      "[ep42] episode_rewards for agent 2 : 9.807999186217785\n",
      "[ep42] episode_rewards for agent 3 : -20.92799965571612\n",
      "[ep42] episode_rewards for agent 4 : 17.16399845853448\n",
      "[ep42] episode_rewards for agent 5 : 65.35599584784359\n",
      "[ep42] episode_rewards for agent 6 : -27.09599904064089\n",
      "[ep42] episode_rewards for agent 7 : -26.64799944497645\n",
      "[ep42] episode_rewards for agent 8 : -46.43199762981385\n",
      "[ep42] episode_rewards for agent 9 : 11.939998934045434\n",
      "[ep42] mean episode reward : -5.065000202134252\n",
      "episode 43 done\n",
      "[ep43] episode_rewards for agent 0 : 33.557997525669634\n",
      "[ep43] episode_rewards for agent 1 : -52.85999708715826\n",
      "[ep43] episode_rewards for agent 2 : -22.615999028086662\n",
      "[ep43] episode_rewards for agent 3 : -22.363999490626156\n",
      "[ep43] episode_rewards for agent 4 : 3.843999220058322\n",
      "[ep43] episode_rewards for agent 5 : 114.29999285005033\n",
      "[ep43] episode_rewards for agent 6 : -26.89599916897714\n",
      "[ep43] episode_rewards for agent 7 : -58.66799654439092\n",
      "[ep43] episode_rewards for agent 8 : -51.25599714368582\n",
      "[ep43] episode_rewards for agent 9 : 40.51999705005437\n",
      "[ep43] mean episode reward : -4.24380018170923\n",
      "episode 44 done\n",
      "[ep44] episode_rewards for agent 0 : 8.805999111384153\n",
      "[ep44] episode_rewards for agent 1 : -49.00399726070464\n",
      "[ep44] episode_rewards for agent 2 : -47.51999725960195\n",
      "[ep44] episode_rewards for agent 3 : -33.391998619772494\n",
      "[ep44] episode_rewards for agent 4 : 31.843997691757977\n",
      "[ep44] episode_rewards for agent 5 : 15.771998574025929\n",
      "[ep44] episode_rewards for agent 6 : -33.97599860653281\n",
      "[ep44] episode_rewards for agent 7 : -39.179998121224344\n",
      "[ep44] episode_rewards for agent 8 : -45.095997710712254\n",
      "[ep44] episode_rewards for agent 9 : 75.84799495898187\n",
      "[ep44] mean episode reward : -11.589799724239857\n",
      "episode 45 done\n",
      "[ep45] episode_rewards for agent 0 : 37.18999709933996\n",
      "[ep45] episode_rewards for agent 1 : -58.15599660295993\n",
      "[ep45] episode_rewards for agent 2 : 26.323998097330332\n",
      "[ep45] episode_rewards for agent 3 : -32.17199860140681\n",
      "[ep45] episode_rewards for agent 4 : 6.491999107412994\n",
      "[ep45] episode_rewards for agent 5 : 45.73999688774347\n",
      "[ep45] episode_rewards for agent 6 : -19.57199953403324\n",
      "[ep45] episode_rewards for agent 7 : -45.891997651197016\n",
      "[ep45] episode_rewards for agent 8 : -59.17599649634212\n",
      "[ep45] episode_rewards for agent 9 : 27.751997904852033\n",
      "[ep45] mean episode reward : -7.146999978926033\n",
      "episode 46 done\n",
      "[ep46] episode_rewards for agent 0 : 48.82599678821862\n",
      "[ep46] episode_rewards for agent 1 : -55.307996798306704\n",
      "[ep46] episode_rewards for agent 2 : -3.180000299587846\n",
      "[ep46] episode_rewards for agent 3 : -34.8719983343035\n",
      "[ep46] episode_rewards for agent 4 : 52.39199625514448\n",
      "[ep46] episode_rewards for agent 5 : 58.679995957762\n",
      "[ep46] episode_rewards for agent 6 : -19.68399978708476\n",
      "[ep46] episode_rewards for agent 7 : -42.087997779250145\n",
      "[ep46] episode_rewards for agent 8 : -54.01199689414352\n",
      "[ep46] episode_rewards for agent 9 : 83.6279945988208\n",
      "[ep46] mean episode reward : 3.438199370726943\n",
      "episode 47 done\n",
      "[ep47] episode_rewards for agent 0 : 58.02999597042799\n",
      "[ep47] episode_rewards for agent 1 : -53.19999695662409\n",
      "[ep47] episode_rewards for agent 2 : -48.2399973757565\n",
      "[ep47] episode_rewards for agent 3 : -37.09999820031226\n",
      "[ep47] episode_rewards for agent 4 : 15.715998435392976\n",
      "[ep47] episode_rewards for agent 5 : 56.05199633073062\n",
      "[ep47] episode_rewards for agent 6 : -26.455999044701457\n",
      "[ep47] episode_rewards for agent 7 : -54.295996938832104\n",
      "[ep47] episode_rewards for agent 8 : -57.34799662977457\n",
      "[ep47] episode_rewards for agent 9 : 95.31599382590503\n",
      "[ep47] mean episode reward : -5.152600058354437\n",
      "episode 48 done\n",
      "[ep48] episode_rewards for agent 0 : 38.06199724599719\n",
      "[ep48] episode_rewards for agent 1 : -51.07999702729285\n",
      "[ep48] episode_rewards for agent 2 : 16.807998758740723\n",
      "[ep48] episode_rewards for agent 3 : -43.87999779172242\n",
      "[ep48] episode_rewards for agent 4 : 91.19199406076223\n",
      "[ep48] episode_rewards for agent 5 : 32.72399767115712\n",
      "[ep48] episode_rewards for agent 6 : -23.72399922646582\n",
      "[ep48] episode_rewards for agent 7 : -29.52799878641963\n",
      "[ep48] episode_rewards for agent 8 : -49.41599730309099\n",
      "[ep48] episode_rewards for agent 9 : 92.21599401813\n",
      "[ep48] mean episode reward : 7.337399161979556\n",
      "episode 49 done\n",
      "[ep49] episode_rewards for agent 0 : 4.637999073602259\n",
      "[ep49] episode_rewards for agent 1 : -43.97599773015827\n",
      "[ep49] episode_rewards for agent 2 : -41.16799779050052\n",
      "[ep49] episode_rewards for agent 3 : -27.663999121636152\n",
      "[ep49] episode_rewards for agent 4 : -26.47599897813052\n",
      "[ep49] episode_rewards for agent 5 : 30.699997733347118\n",
      "[ep49] episode_rewards for agent 6 : -29.223998981527984\n",
      "[ep49] episode_rewards for agent 7 : -48.11999749392271\n",
      "[ep49] episode_rewards for agent 8 : -41.5559981232509\n",
      "[ep49] episode_rewards for agent 9 : 23.315998268313706\n",
      "[ep49] mean episode reward : -19.952999314386396\n",
      "episode 50 done\n",
      "[ep50] episode_rewards for agent 0 : 0.8979994161054492\n",
      "[ep50] episode_rewards for agent 1 : -53.47599704377353\n",
      "[ep50] episode_rewards for agent 2 : -15.00799937080592\n",
      "[ep50] episode_rewards for agent 3 : -44.14399780612439\n",
      "[ep50] episode_rewards for agent 4 : 7.191998931579292\n",
      "[ep50] episode_rewards for agent 5 : 28.851997673511505\n",
      "[ep50] episode_rewards for agent 6 : -54.53599692881107\n",
      "[ep50] episode_rewards for agent 7 : -45.7679976914078\n",
      "[ep50] episode_rewards for agent 8 : -53.25599698442966\n",
      "[ep50] episode_rewards for agent 9 : 89.12799439299852\n",
      "[ep50] mean episode reward : -14.01179954111576\n",
      "episode 51 done\n",
      "[ep51] episode_rewards for agent 0 : 41.94999709352851\n",
      "[ep51] episode_rewards for agent 1 : -58.975996509194374\n",
      "[ep51] episode_rewards for agent 2 : 136.9959913622588\n",
      "[ep51] episode_rewards for agent 3 : -22.519999352283776\n",
      "[ep51] episode_rewards for agent 4 : 1.5199992945417762\n",
      "[ep51] episode_rewards for agent 5 : 73.67999522574246\n",
      "[ep51] episode_rewards for agent 6 : -44.89999747928232\n",
      "[ep51] episode_rewards for agent 7 : -54.42399695701897\n",
      "[ep51] episode_rewards for agent 8 : -35.063998638652265\n",
      "[ep51] episode_rewards for agent 9 : 98.7999934880063\n",
      "[ep51] mean episode reward : 13.706198752764612\n",
      "episode 52 done\n",
      "[ep52] episode_rewards for agent 0 : 56.72599609103054\n",
      "[ep52] episode_rewards for agent 1 : -54.09199693612754\n",
      "[ep52] episode_rewards for agent 2 : 8.539999443106353\n",
      "[ep52] episode_rewards for agent 3 : -33.43199868872762\n",
      "[ep52] episode_rewards for agent 4 : 44.94799667689949\n",
      "[ep52] episode_rewards for agent 5 : 21.131998353637755\n",
      "[ep52] episode_rewards for agent 6 : -31.007998743094504\n",
      "[ep52] episode_rewards for agent 7 : -57.847996591590345\n",
      "[ep52] episode_rewards for agent 8 : -43.69599785655737\n",
      "[ep52] episode_rewards for agent 9 : 87.69599433522671\n",
      "[ep52] mean episode reward : -0.1034003916196525\n",
      "episode 53 done\n",
      "[ep53] episode_rewards for agent 0 : 23.07399793062359\n",
      "[ep53] episode_rewards for agent 1 : -36.42399859149009\n",
      "[ep53] episode_rewards for agent 2 : 59.06799599248916\n",
      "[ep53] episode_rewards for agent 3 : -35.82399826310575\n",
      "[ep53] episode_rewards for agent 4 : 52.95599608309567\n",
      "[ep53] episode_rewards for agent 5 : 92.6879940778017\n",
      "[ep53] episode_rewards for agent 6 : -40.299998078495264\n",
      "[ep53] episode_rewards for agent 7 : -55.103996767662466\n",
      "[ep53] episode_rewards for agent 8 : -47.51999754086137\n",
      "[ep53] episode_rewards for agent 9 : 62.82399590220302\n",
      "[ep53] mean episode reward : 7.543799074459821\n",
      "episode 54 done\n",
      "[ep54] episode_rewards for agent 0 : 28.48199757374823\n",
      "[ep54] episode_rewards for agent 1 : -52.43599709868431\n",
      "[ep54] episode_rewards for agent 2 : -57.62799665052444\n",
      "[ep54] episode_rewards for agent 3 : -30.471998951397836\n",
      "[ep54] episode_rewards for agent 4 : 11.711998639628291\n",
      "[ep54] episode_rewards for agent 5 : 58.47199603077024\n",
      "[ep54] episode_rewards for agent 6 : -40.191998169757426\n",
      "[ep54] episode_rewards for agent 7 : -53.94399699661881\n",
      "[ep54] episode_rewards for agent 8 : -21.779999940656126\n",
      "[ep54] episode_rewards for agent 9 : 73.03199500683695\n",
      "[ep54] mean episode reward : -8.475400055665522\n",
      "episode 55 done\n",
      "[ep55] episode_rewards for agent 0 : 91.75799405109137\n",
      "[ep55] episode_rewards for agent 1 : -54.35999694187194\n",
      "[ep55] episode_rewards for agent 2 : -53.347997029311955\n",
      "[ep55] episode_rewards for agent 3 : -31.15999907720834\n",
      "[ep55] episode_rewards for agent 4 : 34.827997440472245\n",
      "[ep55] episode_rewards for agent 5 : 44.65199696086347\n",
      "[ep55] episode_rewards for agent 6 : -52.58399695530534\n",
      "[ep55] episode_rewards for agent 7 : -50.903997239656746\n",
      "[ep55] episode_rewards for agent 8 : -35.30399868451059\n",
      "[ep55] episode_rewards for agent 9 : 49.75199653208256\n",
      "[ep55] mean episode reward : -5.667000094335526\n",
      "episode 56 done\n",
      "[ep56] episode_rewards for agent 0 : 67.12999524641782\n",
      "[ep56] episode_rewards for agent 1 : -55.54399677924812\n",
      "[ep56] episode_rewards for agent 2 : 111.21599297970533\n",
      "[ep56] episode_rewards for agent 3 : -27.231999445706606\n",
      "[ep56] episode_rewards for agent 4 : 24.93599790520966\n",
      "[ep56] episode_rewards for agent 5 : 19.215998589992523\n",
      "[ep56] episode_rewards for agent 6 : -31.087998777627945\n",
      "[ep56] episode_rewards for agent 7 : -35.88399855233729\n",
      "[ep56] episode_rewards for agent 8 : -44.959997633472085\n",
      "[ep56] episode_rewards for agent 9 : 50.411996512673795\n",
      "[ep56] mean episode reward : 7.820199004560709\n",
      "episode 57 done\n",
      "[ep57] episode_rewards for agent 0 : 1.161999466829002\n",
      "[ep57] episode_rewards for agent 1 : -53.7799970023334\n",
      "[ep57] episode_rewards for agent 2 : 6.775998743250966\n",
      "[ep57] episode_rewards for agent 3 : -32.24399863369763\n",
      "[ep57] episode_rewards for agent 4 : 54.99599628895521\n",
      "[ep57] episode_rewards for agent 5 : 34.695997507311404\n",
      "[ep57] episode_rewards for agent 6 : -33.62799844145775\n",
      "[ep57] episode_rewards for agent 7 : -36.08399844169617\n",
      "[ep57] episode_rewards for agent 8 : -51.95599711313844\n",
      "[ep57] episode_rewards for agent 9 : 69.48399539198726\n",
      "[ep57] mean episode reward : -4.057800223398954\n",
      "episode 58 done\n",
      "[ep58] episode_rewards for agent 0 : 71.46999509911984\n",
      "[ep58] episode_rewards for agent 1 : -47.78799732681364\n",
      "[ep58] episode_rewards for agent 2 : 15.259998622350395\n",
      "[ep58] episode_rewards for agent 3 : -44.79999758861959\n",
      "[ep58] episode_rewards for agent 4 : 45.579996859654784\n",
      "[ep58] episode_rewards for agent 5 : 77.16799487825483\n",
      "[ep58] episode_rewards for agent 6 : -31.211998748593032\n",
      "[ep58] episode_rewards for agent 7 : -43.44399791304022\n",
      "[ep58] episode_rewards for agent 8 : -58.7159965550527\n",
      "[ep58] episode_rewards for agent 9 : 85.06799446698278\n",
      "[ep58] mean episode reward : 6.8585991794243455\n",
      "episode 59 done\n",
      "[ep59] episode_rewards for agent 0 : 8.181998994201422\n",
      "[ep59] episode_rewards for agent 1 : -56.87999668158591\n",
      "[ep59] episode_rewards for agent 2 : 23.20399829838425\n",
      "[ep59] episode_rewards for agent 3 : -21.907999457791448\n",
      "[ep59] episode_rewards for agent 4 : 40.26399705372751\n",
      "[ep59] episode_rewards for agent 5 : 58.07199625764042\n",
      "[ep59] episode_rewards for agent 6 : -59.02799651771784\n",
      "[ep59] episode_rewards for agent 7 : -57.831996624358\n",
      "[ep59] episode_rewards for agent 8 : -50.355997250415385\n",
      "[ep59] episode_rewards for agent 9 : 57.419996118173\n",
      "[ep59] mean episode reward : -5.886199980974197\n",
      "episode 60 done\n",
      "[ep60] episode_rewards for agent 0 : 30.457997479476035\n",
      "[ep60] episode_rewards for agent 1 : -42.61199767701328\n",
      "[ep60] episode_rewards for agent 2 : 34.575997612439096\n",
      "[ep60] episode_rewards for agent 3 : -35.21599834598601\n",
      "[ep60] episode_rewards for agent 4 : 46.759996719658375\n",
      "[ep60] episode_rewards for agent 5 : 45.28399683814496\n",
      "[ep60] episode_rewards for agent 6 : -25.043998965993524\n",
      "[ep60] episode_rewards for agent 7 : -50.03599732089788\n",
      "[ep60] episode_rewards for agent 8 : -59.37999648600817\n",
      "[ep60] episode_rewards for agent 9 : 88.75999421346933\n",
      "[ep60] mean episode reward : 3.3549994067288935\n",
      "episode 61 done\n",
      "[ep61] episode_rewards for agent 0 : 35.72599741164595\n",
      "[ep61] episode_rewards for agent 1 : -47.151997519657016\n",
      "[ep61] episode_rewards for agent 2 : 24.731998082250357\n",
      "[ep61] episode_rewards for agent 3 : -24.547999241389334\n",
      "[ep61] episode_rewards for agent 4 : 20.907998158596456\n",
      "[ep61] episode_rewards for agent 5 : 87.02399441692978\n",
      "[ep61] episode_rewards for agent 6 : -49.683997325599194\n",
      "[ep61] episode_rewards for agent 7 : -48.39599747862667\n",
      "[ep61] episode_rewards for agent 8 : -43.355997839942575\n",
      "[ep61] episode_rewards for agent 9 : 68.19199553132057\n",
      "[ep61] mean episode reward : 2.344599419552833\n",
      "episode 62 done\n",
      "[ep62] episode_rewards for agent 0 : 6.39399915933609\n",
      "[ep62] episode_rewards for agent 1 : -56.043996788561344\n",
      "[ep62] episode_rewards for agent 2 : 14.715998694300652\n",
      "[ep62] episode_rewards for agent 3 : -27.319998893886805\n",
      "[ep62] episode_rewards for agent 4 : 41.93999704532325\n",
      "[ep62] episode_rewards for agent 5 : 98.24399364553392\n",
      "[ep62] episode_rewards for agent 6 : -34.79999855719507\n",
      "[ep62] episode_rewards for agent 7 : -47.083997597917914\n",
      "[ep62] episode_rewards for agent 8 : -23.047999603673816\n",
      "[ep62] episode_rewards for agent 9 : 38.75199724175036\n",
      "[ep62] mean episode reward : 1.1749994345009327\n",
      "episode 63 done\n",
      "[ep63] episode_rewards for agent 0 : 94.20999383553863\n",
      "[ep63] episode_rewards for agent 1 : -58.259996600449085\n",
      "[ep63] episode_rewards for agent 2 : 31.055997578427196\n",
      "[ep63] episode_rewards for agent 3 : -34.15599868260324\n",
      "[ep63] episode_rewards for agent 4 : 58.82399582210928\n",
      "[ep63] episode_rewards for agent 5 : -13.975999674759805\n",
      "[ep63] episode_rewards for agent 6 : -28.543998970650136\n",
      "[ep63] episode_rewards for agent 7 : -42.48799803014845\n",
      "[ep63] episode_rewards for agent 8 : -49.37199729308486\n",
      "[ep63] episode_rewards for agent 9 : 59.26399603113532\n",
      "[ep63] mean episode reward : 1.655799401551485\n",
      "episode 64 done\n",
      "[ep64] episode_rewards for agent 0 : 63.485995632596314\n",
      "[ep64] episode_rewards for agent 1 : -53.23999688960612\n",
      "[ep64] episode_rewards for agent 2 : 17.3159986352548\n",
      "[ep64] episode_rewards for agent 3 : -36.08399844169617\n",
      "[ep64] episode_rewards for agent 4 : 0.8519995855167508\n",
      "[ep64] episode_rewards for agent 5 : 102.23199343401939\n",
      "[ep64] episode_rewards for agent 6 : -49.11199739668518\n",
      "[ep64] episode_rewards for agent 7 : -54.87999688461423\n",
      "[ep64] episode_rewards for agent 8 : -50.66799725126475\n",
      "[ep64] episode_rewards for agent 9 : 56.41599607653916\n",
      "[ep64] mean episode reward : -0.36820034999400375\n",
      "episode 65 done\n",
      "[ep65] episode_rewards for agent 0 : 55.413996265269816\n",
      "[ep65] episode_rewards for agent 1 : -55.63599683251232\n",
      "[ep65] episode_rewards for agent 2 : -19.215998982079327\n",
      "[ep65] episode_rewards for agent 3 : -29.383998760953546\n",
      "[ep65] episode_rewards for agent 4 : 47.575996566563845\n",
      "[ep65] episode_rewards for agent 5 : 99.41999361198395\n",
      "[ep65] episode_rewards for agent 6 : -38.16399822756648\n",
      "[ep65] episode_rewards for agent 7 : -47.21599752083421\n",
      "[ep65] episode_rewards for agent 8 : -52.7359970593825\n",
      "[ep65] episode_rewards for agent 9 : 43.2279967777431\n",
      "[ep65] mean episode reward : 0.32859958382323384\n",
      "episode 66 done\n",
      "[ep66] episode_rewards for agent 0 : 76.00599488336593\n",
      "[ep66] episode_rewards for agent 1 : -47.783997238613665\n",
      "[ep66] episode_rewards for agent 2 : -36.275998217985034\n",
      "[ep66] episode_rewards for agent 3 : -22.62799950502813\n",
      "[ep66] episode_rewards for agent 4 : 9.00399879924953\n",
      "[ep66] episode_rewards for agent 5 : 51.459996432065964\n",
      "[ep66] episode_rewards for agent 6 : -48.927997348830104\n",
      "[ep66] episode_rewards for agent 7 : -54.447996938601136\n",
      "[ep66] episode_rewards for agent 8 : -41.271998105570674\n",
      "[ep66] episode_rewards for agent 9 : 90.31599401962012\n",
      "[ep66] mean episode reward : -2.4550003220327197\n",
      "episode 67 done\n",
      "[ep67] episode_rewards for agent 0 : -41.99799786508083\n",
      "[ep67] episode_rewards for agent 1 : -53.387996923178434\n",
      "[ep67] episode_rewards for agent 2 : -55.69199681840837\n",
      "[ep67] episode_rewards for agent 3 : -39.69199812691659\n",
      "[ep67] episode_rewards for agent 4 : 19.7399979531765\n",
      "[ep67] episode_rewards for agent 5 : 24.82399786170572\n",
      "[ep67] episode_rewards for agent 6 : -40.85999795701355\n",
      "[ep67] episode_rewards for agent 7 : -49.21599735785276\n",
      "[ep67] episode_rewards for agent 8 : -50.199997269548476\n",
      "[ep67] episode_rewards for agent 9 : 40.495997067540884\n",
      "[ep67] mean episode reward : -24.59859894355759\n",
      "episode 68 done\n",
      "[ep68] episode_rewards for agent 0 : 13.877998606301844\n",
      "[ep68] episode_rewards for agent 1 : -43.81599780730903\n",
      "[ep68] episode_rewards for agent 2 : 32.24799755401909\n",
      "[ep68] episode_rewards for agent 3 : -36.98799847159535\n",
      "[ep68] episode_rewards for agent 4 : 31.851997683756053\n",
      "[ep68] episode_rewards for agent 5 : 162.98398993350565\n",
      "[ep68] episode_rewards for agent 6 : -30.139999056234956\n",
      "[ep68] episode_rewards for agent 7 : -57.415996642783284\n",
      "[ep68] episode_rewards for agent 8 : -46.335997578687966\n",
      "[ep68] episode_rewards for agent 9 : 38.47999724559486\n",
      "[ep68] mean episode reward : 6.474599146656692\n",
      "episode 69 done\n",
      "[ep69] episode_rewards for agent 0 : 31.07799743115902\n",
      "[ep69] episode_rewards for agent 1 : -57.31599669158459\n",
      "[ep69] episode_rewards for agent 2 : -25.05999857094139\n",
      "[ep69] episode_rewards for agent 3 : -34.31999868527055\n",
      "[ep69] episode_rewards for agent 4 : -17.311999578028917\n",
      "[ep69] episode_rewards for agent 5 : 42.10399705450982\n",
      "[ep69] episode_rewards for agent 6 : -44.47599786426872\n",
      "[ep69] episode_rewards for agent 7 : -48.91999750304967\n",
      "[ep69] episode_rewards for agent 8 : -43.64399783778936\n",
      "[ep69] episode_rewards for agent 9 : 56.27999635413289\n",
      "[ep69] mean episode reward : -14.158599589113146\n",
      "episode 70 done\n",
      "[ep70] episode_rewards for agent 0 : 3.3459994615986943\n",
      "[ep70] episode_rewards for agent 1 : -46.903997481800616\n",
      "[ep70] episode_rewards for agent 2 : -26.45599875971675\n",
      "[ep70] episode_rewards for agent 3 : -42.50399779994041\n",
      "[ep70] episode_rewards for agent 4 : 33.539997276850045\n",
      "[ep70] episode_rewards for agent 5 : 15.943998329341412\n",
      "[ep70] episode_rewards for agent 6 : -26.423999022692442\n",
      "[ep70] episode_rewards for agent 7 : -43.89199792407453\n",
      "[ep70] episode_rewards for agent 8 : -52.779996941797435\n",
      "[ep70] episode_rewards for agent 9 : 13.29999883659184\n",
      "[ep70] mean episode reward : -17.28299940256402\n",
      "episode 71 done\n",
      "[ep71] episode_rewards for agent 0 : 87.99399421084672\n",
      "[ep71] episode_rewards for agent 1 : -50.451997151598334\n",
      "[ep71] episode_rewards for agent 2 : 71.68399550393224\n",
      "[ep71] episode_rewards for agent 3 : -37.247998429462314\n",
      "[ep71] episode_rewards for agent 4 : 43.69599695131183\n",
      "[ep71] episode_rewards for agent 5 : 64.43199566937983\n",
      "[ep71] episode_rewards for agent 6 : -42.915997793897986\n",
      "[ep71] episode_rewards for agent 7 : -44.011997597292066\n",
      "[ep71] episode_rewards for agent 8 : -40.93599813710898\n",
      "[ep71] episode_rewards for agent 9 : 19.70799826644361\n",
      "[ep71] mean episode reward : 7.194999149255454\n",
      "episode 72 done\n",
      "[ep72] episode_rewards for agent 0 : 96.67399347759783\n",
      "[ep72] episode_rewards for agent 1 : -48.67199729569256\n",
      "[ep72] episode_rewards for agent 2 : 36.33199752680957\n",
      "[ep72] episode_rewards for agent 3 : -36.38799829687923\n",
      "[ep72] episode_rewards for agent 4 : 65.90799553412944\n",
      "[ep72] episode_rewards for agent 5 : 71.431995337829\n",
      "[ep72] episode_rewards for agent 6 : -27.43999911751598\n",
      "[ep72] episode_rewards for agent 7 : -37.59199839923531\n",
      "[ep72] episode_rewards for agent 8 : -40.36799821816385\n",
      "[ep72] episode_rewards for agent 9 : 93.603994066827\n",
      "[ep72] mean episode reward : 17.34899846157059\n",
      "episode 73 done\n",
      "[ep73] episode_rewards for agent 0 : 75.8819950548932\n",
      "[ep73] episode_rewards for agent 1 : -53.303996990434825\n",
      "[ep73] episode_rewards for agent 2 : 7.391999349929392\n",
      "[ep73] episode_rewards for agent 3 : -43.867997808381915\n",
      "[ep73] episode_rewards for agent 4 : -3.2480005277320743\n",
      "[ep73] episode_rewards for agent 5 : 131.0759917004034\n",
      "[ep73] episode_rewards for agent 6 : -37.399998421780765\n",
      "[ep73] episode_rewards for agent 7 : -51.335997154936194\n",
      "[ep73] episode_rewards for agent 8 : -40.91599790286273\n",
      "[ep73] episode_rewards for agent 9 : 15.019998358562589\n",
      "[ep73] mean episode reward : -0.07020043423399329\n",
      "episode 74 done\n",
      "[ep74] episode_rewards for agent 0 : 25.27399813104421\n",
      "[ep74] episode_rewards for agent 1 : -57.227996692061424\n",
      "[ep74] episode_rewards for agent 2 : 5.271999567747116\n",
      "[ep74] episode_rewards for agent 3 : -31.36799894273281\n",
      "[ep74] episode_rewards for agent 4 : 9.5559988245368\n",
      "[ep74] episode_rewards for agent 5 : 95.43999384064227\n",
      "[ep74] episode_rewards for agent 6 : -30.40799888037145\n",
      "[ep74] episode_rewards for agent 7 : -45.827997690066695\n",
      "[ep74] episode_rewards for agent 8 : -51.93999714311212\n",
      "[ep74] episode_rewards for agent 9 : 52.96799642033875\n",
      "[ep74] mean episode reward : -2.826200256403536\n",
      "episode 75 done\n",
      "[ep75] episode_rewards for agent 0 : -6.902000199072063\n",
      "[ep75] episode_rewards for agent 1 : -56.27999677415937\n",
      "[ep75] episode_rewards for agent 2 : -16.01599925942719\n",
      "[ep75] episode_rewards for agent 3 : -35.78399842046201\n",
      "[ep75] episode_rewards for agent 4 : 55.9039960084483\n",
      "[ep75] episode_rewards for agent 5 : 17.54799865372479\n",
      "[ep75] episode_rewards for agent 6 : -26.54399923980236\n",
      "[ep75] episode_rewards for agent 7 : -50.65599727630615\n",
      "[ep75] episode_rewards for agent 8 : -55.499996822327375\n",
      "[ep75] episode_rewards for agent 9 : 67.78399555757642\n",
      "[ep75] mean episode reward : -10.644599777180701\n",
      "episode 76 done\n",
      "[ep76] episode_rewards for agent 0 : 87.67399420961738\n",
      "[ep76] episode_rewards for agent 1 : -52.28799715265632\n",
      "[ep76] episode_rewards for agent 2 : 36.08799758926034\n",
      "[ep76] episode_rewards for agent 3 : -33.123998766765\n",
      "[ep76] episode_rewards for agent 4 : -2.95600029733032\n",
      "[ep76] episode_rewards for agent 5 : 66.7959956927225\n",
      "[ep76] episode_rewards for agent 6 : -19.171999715268612\n",
      "[ep76] episode_rewards for agent 7 : -57.94799662847072\n",
      "[ep76] episode_rewards for agent 8 : -35.38799847941846\n",
      "[ep76] episode_rewards for agent 9 : 100.015993678011\n",
      "[ep76] mean episode reward : 8.96979901297018\n",
      "episode 77 done\n",
      "[ep77] episode_rewards for agent 0 : 42.54999660514295\n",
      "[ep77] episode_rewards for agent 1 : -59.97999642603099\n",
      "[ep77] episode_rewards for agent 2 : 9.647998963482678\n",
      "[ep77] episode_rewards for agent 3 : -40.76799809187651\n",
      "[ep77] episode_rewards for agent 4 : -15.343999596312642\n",
      "[ep77] episode_rewards for agent 5 : 74.09999533556402\n",
      "[ep77] episode_rewards for agent 6 : -56.70799672976136\n",
      "[ep77] episode_rewards for agent 7 : -39.3919983105734\n",
      "[ep77] episode_rewards for agent 8 : -34.959998635575175\n",
      "[ep77] episode_rewards for agent 9 : 70.41199532989413\n",
      "[ep77] mean episode reward : -5.0442001556046305\n",
      "episode 78 done\n",
      "[ep78] episode_rewards for agent 0 : 56.0579958697781\n",
      "[ep78] episode_rewards for agent 1 : -50.98799728695303\n",
      "[ep78] episode_rewards for agent 2 : -2.276000206358731\n",
      "[ep78] episode_rewards for agent 3 : -44.139997833408415\n",
      "[ep78] episode_rewards for agent 4 : 19.975998231209815\n",
      "[ep78] episode_rewards for agent 5 : 72.08799524232745\n",
      "[ep78] episode_rewards for agent 6 : -50.243997196666896\n",
      "[ep78] episode_rewards for agent 7 : -27.951999195851386\n",
      "[ep78] episode_rewards for agent 8 : -48.487997429445386\n",
      "[ep78] episode_rewards for agent 9 : 31.751997638493776\n",
      "[ep78] mean episode reward : -4.421400216687471\n",
      "episode 79 done\n",
      "[ep79] episode_rewards for agent 0 : 69.34199535753578\n",
      "[ep79] episode_rewards for agent 1 : -45.35199776943773\n",
      "[ep79] episode_rewards for agent 2 : -45.775997476652265\n",
      "[ep79] episode_rewards for agent 3 : -27.195999330841005\n",
      "[ep79] episode_rewards for agent 4 : 9.399999062530696\n",
      "[ep79] episode_rewards for agent 5 : 157.1439904179424\n",
      "[ep79] episode_rewards for agent 6 : -48.84399740304798\n",
      "[ep79] episode_rewards for agent 7 : -49.09999736957252\n",
      "[ep79] episode_rewards for agent 8 : -52.895997046492994\n",
      "[ep79] episode_rewards for agent 9 : 42.403996938839555\n",
      "[ep79] mean episode reward : 0.9125995380803943\n",
      "episode 80 done\n",
      "[ep80] episode_rewards for agent 0 : 26.449997851625085\n",
      "[ep80] episode_rewards for agent 1 : -44.17999783810228\n",
      "[ep80] episode_rewards for agent 2 : -13.599999659694731\n",
      "[ep80] episode_rewards for agent 3 : -36.8279984081164\n",
      "[ep80] episode_rewards for agent 4 : 31.22399772424251\n",
      "[ep80] episode_rewards for agent 5 : 40.97199687920511\n",
      "[ep80] episode_rewards for agent 6 : -53.49599692225456\n",
      "[ep80] episode_rewards for agent 7 : -51.723997158929706\n",
      "[ep80] episode_rewards for agent 8 : -53.86399700678885\n",
      "[ep80] episode_rewards for agent 9 : -20.831999097019434\n",
      "[ep80] mean episode reward : -17.587799363583326\n",
      "episode 81 done\n",
      "[ep81] episode_rewards for agent 0 : 107.96599295549095\n",
      "[ep81] episode_rewards for agent 1 : -50.89999725203961\n",
      "[ep81] episode_rewards for agent 2 : 20.379998522810638\n",
      "[ep81] episode_rewards for agent 3 : -41.49599790293723\n",
      "[ep81] episode_rewards for agent 4 : 65.6399954771623\n",
      "[ep81] episode_rewards for agent 5 : 8.211998775601387\n",
      "[ep81] episode_rewards for agent 6 : -17.659999593161047\n",
      "[ep81] episode_rewards for agent 7 : -47.35599753819406\n",
      "[ep81] episode_rewards for agent 8 : -56.71599673572928\n",
      "[ep81] episode_rewards for agent 9 : 15.991998573765159\n",
      "[ep81] mean episode reward : 0.4061995282769203\n",
      "episode 82 done\n",
      "[ep82] episode_rewards for agent 0 : 54.681996036320925\n",
      "[ep82] episode_rewards for agent 1 : -53.87999695446342\n",
      "[ep82] episode_rewards for agent 2 : 76.37999495305121\n",
      "[ep82] episode_rewards for agent 3 : -34.611998609267175\n",
      "[ep82] episode_rewards for agent 4 : 55.23599611315876\n",
      "[ep82] episode_rewards for agent 5 : 59.30799621436745\n",
      "[ep82] episode_rewards for agent 6 : -46.71199760586023\n",
      "[ep82] episode_rewards for agent 7 : -41.227997998706996\n",
      "[ep82] episode_rewards for agent 8 : -54.49199694301933\n",
      "[ep82] episode_rewards for agent 9 : 70.13599551469088\n",
      "[ep82] mean episode reward : 8.481799072027206\n",
      "episode 83 done\n",
      "[ep83] episode_rewards for agent 0 : -20.133999582380056\n",
      "[ep83] episode_rewards for agent 1 : -55.96399674192071\n",
      "[ep83] episode_rewards for agent 2 : 34.54799743741751\n",
      "[ep83] episode_rewards for agent 3 : -36.57999830134213\n",
      "[ep83] episode_rewards for agent 4 : 39.855997015722096\n",
      "[ep83] episode_rewards for agent 5 : 54.055996369570494\n",
      "[ep83] episode_rewards for agent 6 : -28.29199927765876\n",
      "[ep83] episode_rewards for agent 7 : -51.271997179836035\n",
      "[ep83] episode_rewards for agent 8 : -44.50399770028889\n",
      "[ep83] episode_rewards for agent 9 : 84.81999440211803\n",
      "[ep83] mean episode reward : -2.346600355859846\n",
      "episode 84 done\n",
      "[ep84] episode_rewards for agent 0 : 57.813995987176895\n",
      "[ep84] episode_rewards for agent 1 : -53.08799699321389\n",
      "[ep84] episode_rewards for agent 2 : 38.23199755139649\n",
      "[ep84] episode_rewards for agent 3 : -19.431999779306352\n",
      "[ep84] episode_rewards for agent 4 : 21.59999821241945\n",
      "[ep84] episode_rewards for agent 5 : 81.51199471578002\n",
      "[ep84] episode_rewards for agent 6 : -34.71999858971685\n",
      "[ep84] episode_rewards for agent 7 : -53.951996982097626\n",
      "[ep84] episode_rewards for agent 8 : -56.64399670995772\n",
      "[ep84] episode_rewards for agent 9 : 25.059998051263392\n",
      "[ep84] mean episode reward : 0.6381995463743806\n",
      "episode 85 done\n",
      "[ep85] episode_rewards for agent 0 : 25.67399792186916\n",
      "[ep85] episode_rewards for agent 1 : -54.61599685251713\n",
      "[ep85] episode_rewards for agent 2 : -42.79999787919223\n",
      "[ep85] episode_rewards for agent 3 : -37.14799826964736\n",
      "[ep85] episode_rewards for agent 4 : -36.27999824099243\n",
      "[ep85] episode_rewards for agent 5 : 54.15999613609165\n",
      "[ep85] episode_rewards for agent 6 : -34.33999839890748\n",
      "[ep85] episode_rewards for agent 7 : -39.96399820223451\n",
      "[ep85] episode_rewards for agent 8 : -29.90799913648516\n",
      "[ep85] episode_rewards for agent 9 : -7.987999971956015\n",
      "[ep85] mean episode reward : -20.32099928939715\n",
      "episode 86 done\n",
      "[ep86] episode_rewards for agent 0 : 10.409998960793018\n",
      "[ep86] episode_rewards for agent 1 : -55.92399671301246\n",
      "[ep86] episode_rewards for agent 2 : -18.075999178923666\n",
      "[ep86] episode_rewards for agent 3 : -38.063998139463365\n",
      "[ep86] episode_rewards for agent 4 : -15.47599944844842\n",
      "[ep86] episode_rewards for agent 5 : 45.41999676544219\n",
      "[ep86] episode_rewards for agent 6 : -25.73599892668426\n",
      "[ep86] episode_rewards for agent 7 : -52.96799706015736\n",
      "[ep86] episode_rewards for agent 8 : -47.81599754281342\n",
      "[ep86] episode_rewards for agent 9 : 31.175997680053115\n",
      "[ep86] mean episode reward : -16.70539936032146\n",
      "episode 87 done\n",
      "[ep87] episode_rewards for agent 0 : 12.05799877922982\n",
      "[ep87] episode_rewards for agent 1 : -54.52799689769745\n",
      "[ep87] episode_rewards for agent 2 : -39.17199776601046\n",
      "[ep87] episode_rewards for agent 3 : -25.65999952238053\n",
      "[ep87] episode_rewards for agent 4 : 1.263999592512846\n",
      "[ep87] episode_rewards for agent 5 : 72.13199510797858\n",
      "[ep87] episode_rewards for agent 6 : -36.195998441427946\n",
      "[ep87] episode_rewards for agent 7 : -45.33199759013951\n",
      "[ep87] episode_rewards for agent 8 : -49.515997358597815\n",
      "[ep87] episode_rewards for agent 9 : 35.90399738587439\n",
      "[ep87] mean episode reward : -12.904599671065807\n",
      "episode 88 done\n",
      "[ep88] episode_rewards for agent 0 : 24.297997993417084\n",
      "[ep88] episode_rewards for agent 1 : -53.73199685662985\n",
      "[ep88] episode_rewards for agent 2 : -10.187999687157571\n",
      "[ep88] episode_rewards for agent 3 : -44.647997681982815\n",
      "[ep88] episode_rewards for agent 4 : 50.91999639477581\n",
      "[ep88] episode_rewards for agent 5 : 27.85999796818942\n",
      "[ep88] episode_rewards for agent 6 : -35.543998687528074\n",
      "[ep88] episode_rewards for agent 7 : -39.48399828188121\n",
      "[ep88] episode_rewards for agent 8 : -42.94399781432003\n",
      "[ep88] episode_rewards for agent 9 : 22.44799809716642\n",
      "[ep88] mean episode reward : -10.101399855595082\n",
      "episode 89 done\n",
      "[ep89] episode_rewards for agent 0 : 87.42199423070997\n",
      "[ep89] episode_rewards for agent 1 : -55.67599678598344\n",
      "[ep89] episode_rewards for agent 2 : 8.983999324031174\n",
      "[ep89] episode_rewards for agent 3 : -32.203998662531376\n",
      "[ep89] episode_rewards for agent 4 : 31.27199760917574\n",
      "[ep89] episode_rewards for agent 5 : 53.43199618719518\n",
      "[ep89] episode_rewards for agent 6 : -44.37599776405841\n",
      "[ep89] episode_rewards for agent 7 : -47.075997630134225\n",
      "[ep89] episode_rewards for agent 8 : -33.011998801492155\n",
      "[ep89] episode_rewards for agent 9 : 65.36799563560635\n",
      "[ep89] mean episode reward : 3.4133993342518805\n",
      "episode 90 done\n",
      "[ep90] episode_rewards for agent 0 : 58.537995972670615\n",
      "[ep90] episode_rewards for agent 1 : -55.1959968842566\n",
      "[ep90] episode_rewards for agent 2 : 30.423997978679836\n",
      "[ep90] episode_rewards for agent 3 : -47.45199759211391\n",
      "[ep90] episode_rewards for agent 4 : 42.81199711188674\n",
      "[ep90] episode_rewards for agent 5 : 46.76399672776461\n",
      "[ep90] episode_rewards for agent 6 : -17.715999944135547\n",
      "[ep90] episode_rewards for agent 7 : -55.21599682699889\n",
      "[ep90] episode_rewards for agent 8 : -43.91999783087522\n",
      "[ep90] episode_rewards for agent 9 : -0.8440005155280232\n",
      "[ep90] mean episode reward : -4.180600180290639\n",
      "episode 91 done\n",
      "[ep91] episode_rewards for agent 0 : 79.74199467618018\n",
      "[ep91] episode_rewards for agent 1 : -54.159996926784515\n",
      "[ep91] episode_rewards for agent 2 : -6.715999802574515\n",
      "[ep91] episode_rewards for agent 3 : -33.491998605430126\n",
      "[ep91] episode_rewards for agent 4 : 3.5159994466230273\n",
      "[ep91] episode_rewards for agent 5 : 89.20399419404566\n",
      "[ep91] episode_rewards for agent 6 : -43.29999781772494\n",
      "[ep91] episode_rewards for agent 7 : -54.37199692428112\n",
      "[ep91] episode_rewards for agent 8 : -49.85599715448916\n",
      "[ep91] episode_rewards for agent 9 : 38.85599703527987\n",
      "[ep91] mean episode reward : -3.0578001879155634\n",
      "episode 92 done\n",
      "[ep92] episode_rewards for agent 0 : 65.54199555423111\n",
      "[ep92] episode_rewards for agent 1 : -57.4799966448918\n",
      "[ep92] episode_rewards for agent 2 : 79.20799486525357\n",
      "[ep92] episode_rewards for agent 3 : -42.26399794127792\n",
      "[ep92] episode_rewards for agent 4 : 43.78399683255702\n",
      "[ep92] episode_rewards for agent 5 : 37.68799740169197\n",
      "[ep92] episode_rewards for agent 6 : -13.916000396944582\n",
      "[ep92] episode_rewards for agent 7 : -28.047999332658947\n",
      "[ep92] episode_rewards for agent 8 : -57.11599670071155\n",
      "[ep92] episode_rewards for agent 9 : 32.29599759168923\n",
      "[ep92] mean episode reward : 5.96939912289381\n",
      "episode 93 done\n",
      "[ep93] episode_rewards for agent 0 : 71.88199506979436\n",
      "[ep93] episode_rewards for agent 1 : -52.34799708239734\n",
      "[ep93] episode_rewards for agent 2 : 7.0039991326630116\n",
      "[ep93] episode_rewards for agent 3 : -31.70799881592393\n",
      "[ep93] episode_rewards for agent 4 : 36.71199734508991\n",
      "[ep93] episode_rewards for agent 5 : 44.73999678902328\n",
      "[ep93] episode_rewards for agent 6 : -34.95199867710471\n",
      "[ep93] episode_rewards for agent 7 : -54.107996980659664\n",
      "[ep93] episode_rewards for agent 8 : -53.6559969605878\n",
      "[ep93] episode_rewards for agent 9 : 26.227997864596546\n",
      "[ep93] mean episode reward : -4.020600231550634\n",
      "episode 94 done\n",
      "[ep94] episode_rewards for agent 0 : 87.79799433797598\n",
      "[ep94] episode_rewards for agent 1 : -46.49599749781191\n",
      "[ep94] episode_rewards for agent 2 : -18.85599891934544\n",
      "[ep94] episode_rewards for agent 3 : -31.831998920068145\n",
      "[ep94] episode_rewards for agent 4 : 114.24799287039787\n",
      "[ep94] episode_rewards for agent 5 : -12.523999542929232\n",
      "[ep94] episode_rewards for agent 6 : -34.327998546883464\n",
      "[ep94] episode_rewards for agent 7 : -44.5959977414459\n",
      "[ep94] episode_rewards for agent 8 : -55.17999677173793\n",
      "[ep94] episode_rewards for agent 9 : 111.85599282570183\n",
      "[ep94] mean episode reward : 7.008999209385365\n",
      "episode 95 done\n",
      "[ep95] episode_rewards for agent 0 : 25.72199791762978\n",
      "[ep95] episode_rewards for agent 1 : -56.29199677053839\n",
      "[ep95] episode_rewards for agent 2 : -37.5799980442971\n",
      "[ep95] episode_rewards for agent 3 : -41.78399806842208\n",
      "[ep95] episode_rewards for agent 4 : 39.79599692765623\n",
      "[ep95] episode_rewards for agent 5 : 95.9519938128069\n",
      "[ep95] episode_rewards for agent 6 : -33.12799860723317\n",
      "[ep95] episode_rewards for agent 7 : -55.73199683241546\n",
      "[ep95] episode_rewards for agent 8 : -57.19999661203474\n",
      "[ep95] episode_rewards for agent 9 : 40.57999713905156\n",
      "[ep95] mean episode reward : -7.966599913779646\n",
      "episode 96 done\n",
      "[ep96] episode_rewards for agent 0 : 88.48999405931681\n",
      "[ep96] episode_rewards for agent 1 : -42.51999790593982\n",
      "[ep96] episode_rewards for agent 2 : -34.451998236589134\n",
      "[ep96] episode_rewards for agent 3 : -31.407998693175614\n",
      "[ep96] episode_rewards for agent 4 : 58.45199588313699\n",
      "[ep96] episode_rewards for agent 5 : -0.8200003625825047\n",
      "[ep96] episode_rewards for agent 6 : -17.191999510861933\n",
      "[ep96] episode_rewards for agent 7 : -52.539997084997594\n",
      "[ep96] episode_rewards for agent 8 : -37.20799849834293\n",
      "[ep96] episode_rewards for agent 9 : 42.59599699545652\n",
      "[ep96] mean episode reward : -2.660200335457921\n",
      "episode 97 done\n",
      "[ep97] episode_rewards for agent 0 : 4.24999912455678\n",
      "[ep97] episode_rewards for agent 1 : -57.10399666056037\n",
      "[ep97] episode_rewards for agent 2 : 150.58399053197354\n",
      "[ep97] episode_rewards for agent 3 : -21.66799955163151\n",
      "[ep97] episode_rewards for agent 4 : 62.10399578511715\n",
      "[ep97] episode_rewards for agent 5 : 114.63199289049953\n",
      "[ep97] episode_rewards for agent 6 : -29.451999123208225\n",
      "[ep97] episode_rewards for agent 7 : -48.42799749970436\n",
      "[ep97] episode_rewards for agent 8 : -43.02399766538292\n",
      "[ep97] episode_rewards for agent 9 : 11.211998707614839\n",
      "[ep97] mean episode reward : 14.310598653927446\n",
      "episode 98 done\n",
      "[ep98] episode_rewards for agent 0 : 72.44599528517574\n",
      "[ep98] episode_rewards for agent 1 : -55.65599677711725\n",
      "[ep98] episode_rewards for agent 2 : 23.98799796681851\n",
      "[ep98] episode_rewards for agent 3 : -36.93599849473685\n",
      "[ep98] episode_rewards for agent 4 : 8.651998817920685\n",
      "[ep98] episode_rewards for agent 5 : 40.83199699409306\n",
      "[ep98] episode_rewards for agent 6 : -30.35599876381457\n",
      "[ep98] episode_rewards for agent 7 : -54.215996934100986\n",
      "[ep98] episode_rewards for agent 8 : -51.915997149422765\n",
      "[ep98] episode_rewards for agent 9 : 89.35599427204579\n",
      "[ep98] mean episode reward : 0.6193995216861368\n",
      "episode 99 done\n",
      "[ep99] episode_rewards for agent 0 : 66.79399555549026\n",
      "[ep99] episode_rewards for agent 1 : -58.22399656847119\n",
      "[ep99] episode_rewards for agent 2 : 17.927998462691903\n",
      "[ep99] episode_rewards for agent 3 : -37.27999817673117\n",
      "[ep99] episode_rewards for agent 4 : 25.13599815312773\n",
      "[ep99] episode_rewards for agent 5 : 7.051998906768858\n",
      "[ep99] episode_rewards for agent 6 : -40.83599781990051\n",
      "[ep99] episode_rewards for agent 7 : -4.432000802829862\n",
      "[ep99] episode_rewards for agent 8 : -54.163996995426714\n",
      "[ep99] episode_rewards for agent 9 : 79.31999484356493\n",
      "[ep99] mean episode reward : 0.1293995558284223\n",
      "episode 100 done\n",
      "[ep100] episode_rewards for agent 0 : 90.03399417176843\n",
      "[ep100] episode_rewards for agent 1 : -54.21199685614556\n",
      "[ep100] episode_rewards for agent 2 : -49.39199742954224\n",
      "[ep100] episode_rewards for agent 3 : -39.25199827179313\n",
      "[ep100] episode_rewards for agent 4 : 6.939999110996723\n",
      "[ep100] episode_rewards for agent 5 : 129.78799190931022\n",
      "[ep100] episode_rewards for agent 6 : -37.13599817361683\n",
      "[ep100] episode_rewards for agent 7 : -58.84399653412402\n",
      "[ep100] episode_rewards for agent 8 : -51.66799710504711\n",
      "[ep100] episode_rewards for agent 9 : 103.5879933424294\n",
      "[ep100] mean episode reward : 3.984599416423589\n",
      "episode 101 done\n",
      "[ep101] episode_rewards for agent 0 : 3.8939992608502507\n",
      "[ep101] episode_rewards for agent 1 : -52.25999710056931\n",
      "[ep101] episode_rewards for agent 2 : -52.92799695022404\n",
      "[ep101] episode_rewards for agent 3 : -26.555999359115958\n",
      "[ep101] episode_rewards for agent 4 : 102.34399340488017\n",
      "[ep101] episode_rewards for agent 5 : 64.35599566344172\n",
      "[ep101] episode_rewards for agent 6 : -37.971998118795455\n",
      "[ep101] episode_rewards for agent 7 : -42.92399802058935\n",
      "[ep101] episode_rewards for agent 8 : -58.72399653494358\n",
      "[ep101] episode_rewards for agent 9 : 93.77599378768355\n",
      "[ep101] mean episode reward : -0.6994003967382014\n",
      "episode 102 done\n",
      "[ep102] episode_rewards for agent 0 : 95.20199389848858\n",
      "[ep102] episode_rewards for agent 1 : -46.739997644908726\n",
      "[ep102] episode_rewards for agent 2 : 23.5959984222427\n",
      "[ep102] episode_rewards for agent 3 : -34.10799845773727\n",
      "[ep102] episode_rewards for agent 4 : 42.423996792174876\n",
      "[ep102] episode_rewards for agent 5 : 36.783997340127826\n",
      "[ep102] episode_rewards for agent 6 : -23.25999977812171\n",
      "[ep102] episode_rewards for agent 7 : -52.86799703352153\n",
      "[ep102] episode_rewards for agent 8 : -52.515997026115656\n",
      "[ep102] episode_rewards for agent 9 : 47.279996786266565\n",
      "[ep102] mean episode reward : 3.579399329889566\n",
      "episode 103 done\n",
      "[ep103] episode_rewards for agent 0 : 43.601996913552284\n",
      "[ep103] episode_rewards for agent 1 : -54.955996866337955\n",
      "[ep103] episode_rewards for agent 2 : -0.6440001111477613\n",
      "[ep103] episode_rewards for agent 3 : -25.047999249771237\n",
      "[ep103] episode_rewards for agent 4 : 28.167997704818845\n",
      "[ep103] episode_rewards for agent 5 : 70.85599528066814\n",
      "[ep103] episode_rewards for agent 6 : -36.09199864137918\n",
      "[ep103] episode_rewards for agent 7 : -50.91199718788266\n",
      "[ep103] episode_rewards for agent 8 : -45.95599769894034\n",
      "[ep103] episode_rewards for agent 9 : 32.83599749673158\n",
      "[ep103] mean episode reward : -3.814600235968828\n",
      "episode 104 done\n",
      "[ep104] episode_rewards for agent 0 : 65.85399553366005\n",
      "[ep104] episode_rewards for agent 1 : -50.33999727200717\n",
      "[ep104] episode_rewards for agent 2 : -13.2679996881634\n",
      "[ep104] episode_rewards for agent 3 : -23.69199973810464\n",
      "[ep104] episode_rewards for agent 4 : 48.62799654901028\n",
      "[ep104] episode_rewards for agent 5 : 54.30399617552757\n",
      "[ep104] episode_rewards for agent 6 : -46.85599759314209\n",
      "[ep104] episode_rewards for agent 7 : -36.17999800108373\n",
      "[ep104] episode_rewards for agent 8 : -38.37999816797674\n",
      "[ep104] episode_rewards for agent 9 : 31.187997745350003\n",
      "[ep104] mean episode reward : -0.8742004456929863\n",
      "episode 105 done\n",
      "[ep105] episode_rewards for agent 0 : 77.50599471479654\n",
      "[ep105] episode_rewards for agent 1 : -53.691997029818594\n",
      "[ep105] episode_rewards for agent 2 : 0.20399968326091766\n",
      "[ep105] episode_rewards for agent 3 : -39.12799821794033\n",
      "[ep105] episode_rewards for agent 4 : -14.77999953366816\n",
      "[ep105] episode_rewards for agent 5 : 120.61599244084209\n",
      "[ep105] episode_rewards for agent 6 : -34.563998486846685\n",
      "[ep105] episode_rewards for agent 7 : -58.19999656546861\n",
      "[ep105] episode_rewards for agent 8 : -47.61999743524939\n",
      "[ep105] episode_rewards for agent 9 : 39.823997157625854\n",
      "[ep105] mean episode reward : -0.9834003272466362\n",
      "episode 106 done\n",
      "[ep106] episode_rewards for agent 0 : -0.10200041718780994\n",
      "[ep106] episode_rewards for agent 1 : -57.77199659962207\n",
      "[ep106] episode_rewards for agent 2 : -16.391999670304358\n",
      "[ep106] episode_rewards for agent 3 : -43.45199786964804\n",
      "[ep106] episode_rewards for agent 4 : 46.31999689526856\n",
      "[ep106] episode_rewards for agent 5 : 129.87599184922874\n",
      "[ep106] episode_rewards for agent 6 : -32.167998927645385\n",
      "[ep106] episode_rewards for agent 7 : -56.61199676338583\n",
      "[ep106] episode_rewards for agent 8 : -58.09599661082029\n",
      "[ep106] episode_rewards for agent 9 : 100.2999936984852\n",
      "[ep106] mean episode reward : 1.1901995584368705\n",
      "episode 107 done\n",
      "[ep107] episode_rewards for agent 0 : 114.81799249723554\n",
      "[ep107] episode_rewards for agent 1 : -29.555999123491347\n",
      "[ep107] episode_rewards for agent 2 : -15.643999379128218\n",
      "[ep107] episode_rewards for agent 3 : -18.12799959909171\n",
      "[ep107] episode_rewards for agent 4 : 53.11999625060707\n",
      "[ep107] episode_rewards for agent 5 : 47.11999679449946\n",
      "[ep107] episode_rewards for agent 6 : -42.315997594967484\n",
      "[ep107] episode_rewards for agent 7 : -45.867997645400465\n",
      "[ep107] episode_rewards for agent 8 : -57.41999666765332\n",
      "[ep107] episode_rewards for agent 9 : 75.60399505030364\n",
      "[ep107] mean episode reward : 8.172999058291316\n",
      "episode 108 done\n",
      "[ep108] episode_rewards for agent 0 : 44.7579966718331\n",
      "[ep108] episode_rewards for agent 1 : -46.75599753856659\n",
      "[ep108] episode_rewards for agent 2 : 47.991996716707945\n",
      "[ep108] episode_rewards for agent 3 : -26.64799931459129\n",
      "[ep108] episode_rewards for agent 4 : -19.5759993577376\n",
      "[ep108] episode_rewards for agent 5 : 103.93599340412766\n",
      "[ep108] episode_rewards for agent 6 : -36.455998327583075\n",
      "[ep108] episode_rewards for agent 7 : -57.77599658630788\n",
      "[ep108] episode_rewards for agent 8 : -47.79599752649665\n",
      "[ep108] episode_rewards for agent 9 : 16.543998764827847\n",
      "[ep108] mean episode reward : -2.1778003093786538\n",
      "episode 109 done\n",
      "[ep109] episode_rewards for agent 0 : 18.92199823167175\n",
      "[ep109] episode_rewards for agent 1 : -50.71599727962166\n",
      "[ep109] episode_rewards for agent 2 : -33.35599831677973\n",
      "[ep109] episode_rewards for agent 3 : -21.74799983110279\n",
      "[ep109] episode_rewards for agent 4 : 3.60799930524081\n",
      "[ep109] episode_rewards for agent 5 : 24.30799799412489\n",
      "[ep109] episode_rewards for agent 6 : -42.619997872039676\n",
      "[ep109] episode_rewards for agent 7 : -46.84799764305353\n",
      "[ep109] episode_rewards for agent 8 : -50.26399724185467\n",
      "[ep109] episode_rewards for agent 9 : 31.895997541956604\n",
      "[ep109] mean episode reward : -16.6817995111458\n",
      "episode 110 done\n",
      "[ep110] episode_rewards for agent 0 : 42.20999725814909\n",
      "[ep110] episode_rewards for agent 1 : -53.043997081927955\n",
      "[ep110] episode_rewards for agent 2 : -0.43600025959312916\n",
      "[ep110] episode_rewards for agent 3 : -32.45999890193343\n",
      "[ep110] episode_rewards for agent 4 : -3.772000244818628\n",
      "[ep110] episode_rewards for agent 5 : 23.82799814734608\n",
      "[ep110] episode_rewards for agent 6 : -22.2839995296672\n",
      "[ep110] episode_rewards for agent 7 : -58.731996554881334\n",
      "[ep110] episode_rewards for agent 8 : -45.77999760303646\n",
      "[ep110] episode_rewards for agent 9 : 38.06799724511802\n",
      "[ep110] mean episode reward : -11.240199752524495\n",
      "episode 111 done\n",
      "[ep111] episode_rewards for agent 0 : 30.573997665196657\n",
      "[ep111] episode_rewards for agent 1 : -53.271996981464326\n",
      "[ep111] episode_rewards for agent 2 : 138.083991445601\n",
      "[ep111] episode_rewards for agent 3 : -30.67199882492423\n",
      "[ep111] episode_rewards for agent 4 : 60.72399582527578\n",
      "[ep111] episode_rewards for agent 5 : 81.89199483022094\n",
      "[ep111] episode_rewards for agent 6 : -14.827999741770327\n",
      "[ep111] episode_rewards for agent 7 : -24.667999681085348\n",
      "[ep111] episode_rewards for agent 8 : -44.391997780650854\n",
      "[ep111] episode_rewards for agent 9 : 43.26399692706764\n",
      "[ep111] mean episode reward : 18.670598368346692\n",
      "episode 112 done\n",
      "[ep112] episode_rewards for agent 0 : 59.59399587009102\n",
      "[ep112] episode_rewards for agent 1 : -56.527996690012515\n",
      "[ep112] episode_rewards for agent 2 : 29.483997975476086\n",
      "[ep112] episode_rewards for agent 3 : -6.592000923119485\n",
      "[ep112] episode_rewards for agent 4 : 12.723998688161373\n",
      "[ep112] episode_rewards for agent 5 : 122.12399233318865\n",
      "[ep112] episode_rewards for agent 6 : -42.45999783743173\n",
      "[ep112] episode_rewards for agent 7 : -47.79599737934768\n",
      "[ep112] episode_rewards for agent 8 : -42.51599788758904\n",
      "[ep112] episode_rewards for agent 9 : 74.33599509391934\n",
      "[ep112] mean episode reward : 10.236998924333601\n",
      "episode 113 done\n",
      "[ep113] episode_rewards for agent 0 : 46.729996813461185\n",
      "[ep113] episode_rewards for agent 1 : -41.74799802619964\n",
      "[ep113] episode_rewards for agent 2 : 90.38799433782697\n",
      "[ep113] episode_rewards for agent 3 : -28.41599910520017\n",
      "[ep113] episode_rewards for agent 4 : 48.7559964209795\n",
      "[ep113] episode_rewards for agent 5 : -22.46399914380163\n",
      "[ep113] episode_rewards for agent 6 : -19.25599956419319\n",
      "[ep113] episode_rewards for agent 7 : -48.37599744554609\n",
      "[ep113] episode_rewards for agent 8 : -51.09999726898968\n",
      "[ep113] episode_rewards for agent 9 : 4.567999105900526\n",
      "[ep113] mean episode reward : -2.0918003875762223\n",
      "episode 114 done\n",
      "[ep114] episode_rewards for agent 0 : 36.35799715388566\n",
      "[ep114] episode_rewards for agent 1 : -59.499996457248926\n",
      "[ep114] episode_rewards for agent 2 : -32.815998268313706\n",
      "[ep114] episode_rewards for agent 3 : -39.9279981572181\n",
      "[ep114] episode_rewards for agent 4 : 0.859999374486506\n",
      "[ep114] episode_rewards for agent 5 : 80.47599489428103\n",
      "[ep114] episode_rewards for agent 6 : -30.143998799845576\n",
      "[ep114] episode_rewards for agent 7 : -59.019996487535536\n",
      "[ep114] episode_rewards for agent 8 : -47.923997316509485\n",
      "[ep114] episode_rewards for agent 9 : -16.96799957472831\n",
      "[ep114] mean episode reward : -16.860599363874645\n",
      "episode 115 done\n",
      "[ep115] episode_rewards for agent 0 : 88.72599418181926\n",
      "[ep115] episode_rewards for agent 1 : -50.81599722057581\n",
      "[ep115] episode_rewards for agent 2 : 29.727997777983546\n",
      "[ep115] episode_rewards for agent 3 : -39.35199823696166\n",
      "[ep115] episode_rewards for agent 4 : 50.1479965467006\n",
      "[ep115] episode_rewards for agent 5 : 32.983997540548444\n",
      "[ep115] episode_rewards for agent 6 : -36.6919983997941\n",
      "[ep115] episode_rewards for agent 7 : -41.463998028077185\n",
      "[ep115] episode_rewards for agent 8 : -45.66399769671261\n",
      "[ep115] episode_rewards for agent 9 : 37.2639974206686\n",
      "[ep115] mean episode reward : 2.486199388559908\n",
      "episode 116 done\n",
      "[ep116] episode_rewards for agent 0 : 38.53799705207348\n",
      "[ep116] episode_rewards for agent 1 : -55.099996832199395\n",
      "[ep116] episode_rewards for agent 2 : 53.955996287055314\n",
      "[ep116] episode_rewards for agent 3 : -31.047999104484916\n",
      "[ep116] episode_rewards for agent 4 : 103.65999312326312\n",
      "[ep116] episode_rewards for agent 5 : 69.74399545323104\n",
      "[ep116] episode_rewards for agent 6 : -8.432000012136996\n",
      "[ep116] episode_rewards for agent 7 : -49.815997178666294\n",
      "[ep116] episode_rewards for agent 8 : -38.831998196430504\n",
      "[ep116] episode_rewards for agent 9 : 17.983998601324856\n",
      "[ep116] mean episode reward : 10.06539891930297\n",
      "episode 117 done\n",
      "[ep117] episode_rewards for agent 0 : 45.11799687054008\n",
      "[ep117] episode_rewards for agent 1 : -55.92399676050991\n",
      "[ep117] episode_rewards for agent 2 : 20.647998498752713\n",
      "[ep117] episode_rewards for agent 3 : -20.62799967546016\n",
      "[ep117] episode_rewards for agent 4 : -11.643999705091119\n",
      "[ep117] episode_rewards for agent 5 : 70.4279953604564\n",
      "[ep117] episode_rewards for agent 6 : -26.74799933936447\n",
      "[ep117] episode_rewards for agent 7 : -54.075996993109584\n",
      "[ep117] episode_rewards for agent 8 : -49.98799722176045\n",
      "[ep117] episode_rewards for agent 9 : 13.7359987096861\n",
      "[ep117] mean episode reward : -6.907800025586039\n",
      "episode 118 done\n",
      "[ep118] episode_rewards for agent 0 : 59.449995862320065\n",
      "[ep118] episode_rewards for agent 1 : -56.37599672283977\n",
      "[ep118] episode_rewards for agent 2 : 103.751993175596\n",
      "[ep118] episode_rewards for agent 3 : -11.396000076085329\n",
      "[ep118] episode_rewards for agent 4 : -15.355999514460564\n",
      "[ep118] episode_rewards for agent 5 : 104.18799328245223\n",
      "[ep118] episode_rewards for agent 6 : -38.01199816726148\n",
      "[ep118] episode_rewards for agent 7 : -47.77199756447226\n",
      "[ep118] episode_rewards for agent 8 : -41.71599795296788\n",
      "[ep118] episode_rewards for agent 9 : 14.283998663537204\n",
      "[ep118] mean episode reward : 7.10459909858182\n",
      "episode 119 done\n",
      "[ep119] episode_rewards for agent 0 : 48.79399644676596\n",
      "[ep119] episode_rewards for agent 1 : -54.3399968938902\n",
      "[ep119] episode_rewards for agent 2 : 12.927998865023255\n",
      "[ep119] episode_rewards for agent 3 : -36.44399839360267\n",
      "[ep119] episode_rewards for agent 4 : 29.707997772842646\n",
      "[ep119] episode_rewards for agent 5 : -0.20000046584755182\n",
      "[ep119] episode_rewards for agent 6 : -22.0399997131899\n",
      "[ep119] episode_rewards for agent 7 : -35.19999854080379\n",
      "[ep119] episode_rewards for agent 8 : -49.6519972756505\n",
      "[ep119] episode_rewards for agent 9 : -4.640000218525529\n",
      "[ep119] mean episode reward : -11.108599841687829\n",
      "episode 120 done\n",
      "[ep120] episode_rewards for agent 0 : 65.00999545678496\n",
      "[ep120] episode_rewards for agent 1 : -52.647997099906206\n",
      "[ep120] episode_rewards for agent 2 : 20.41599832754582\n",
      "[ep120] episode_rewards for agent 3 : -39.68399825133383\n",
      "[ep120] episode_rewards for agent 4 : 16.595998583361506\n",
      "[ep120] episode_rewards for agent 5 : 78.38799489475787\n",
      "[ep120] episode_rewards for agent 6 : -35.03599867224693\n",
      "[ep120] episode_rewards for agent 7 : -38.763998387381434\n",
      "[ep120] episode_rewards for agent 8 : -51.60399713367224\n",
      "[ep120] episode_rewards for agent 9 : 8.647999031469226\n",
      "[ep120] mean episode reward : -2.867800325062126\n",
      "episode 121 done\n",
      "[ep121] episode_rewards for agent 0 : 21.77799806278199\n",
      "[ep121] episode_rewards for agent 1 : -59.291996497660875\n",
      "[ep121] episode_rewards for agent 2 : 87.93199431151152\n",
      "[ep121] episode_rewards for agent 3 : -25.491999357938766\n",
      "[ep121] episode_rewards for agent 4 : 27.539997959509492\n",
      "[ep121] episode_rewards for agent 5 : 52.48399649001658\n",
      "[ep121] episode_rewards for agent 6 : -30.5719985794276\n",
      "[ep121] episode_rewards for agent 7 : -34.27199865505099\n",
      "[ep121] episode_rewards for agent 8 : -38.95199824217707\n",
      "[ep121] episode_rewards for agent 9 : 40.18799730576575\n",
      "[ep121] mean episode reward : 4.134199279733002\n",
      "episode 122 done\n",
      "[ep122] episode_rewards for agent 0 : 45.92999652121216\n",
      "[ep122] episode_rewards for agent 1 : -49.667997184209526\n",
      "[ep122] episode_rewards for agent 2 : -24.515998871997\n",
      "[ep122] episode_rewards for agent 3 : -28.259999383240938\n",
      "[ep122] episode_rewards for agent 4 : 28.123997722752392\n",
      "[ep122] episode_rewards for agent 5 : -18.71199955418706\n",
      "[ep122] episode_rewards for agent 6 : 4.755999069660902\n",
      "[ep122] episode_rewards for agent 7 : -53.03599707689136\n",
      "[ep122] episode_rewards for agent 8 : -53.88399690575898\n",
      "[ep122] episode_rewards for agent 9 : 40.95999709144235\n",
      "[ep122] mean episode reward : -10.830599857121706\n",
      "episode 123 done\n",
      "[ep123] episode_rewards for agent 0 : 62.701995740644634\n",
      "[ep123] episode_rewards for agent 1 : -55.42399679496884\n",
      "[ep123] episode_rewards for agent 2 : 23.767998406663537\n",
      "[ep123] episode_rewards for agent 3 : -28.51999919489026\n",
      "[ep123] episode_rewards for agent 4 : 5.703998816199601\n",
      "[ep123] episode_rewards for agent 5 : 41.291997112333775\n",
      "[ep123] episode_rewards for agent 6 : -15.795999929308891\n",
      "[ep123] episode_rewards for agent 7 : -58.875996530056\n",
      "[ep123] episode_rewards for agent 8 : -33.207998807542026\n",
      "[ep123] episode_rewards for agent 9 : 10.031998957507312\n",
      "[ep123] mean episode reward : -4.832600222341716\n",
      "episode 124 done\n",
      "[ep124] episode_rewards for agent 0 : 20.99799807742238\n",
      "[ep124] episode_rewards for agent 1 : -53.09999693091959\n",
      "[ep124] episode_rewards for agent 2 : -22.099999023601413\n",
      "[ep124] episode_rewards for agent 3 : -28.475999034941196\n",
      "[ep124] episode_rewards for agent 4 : 31.279997611418366\n",
      "[ep124] episode_rewards for agent 5 : 95.11199394334108\n",
      "[ep124] episode_rewards for agent 6 : -3.316000691615045\n",
      "[ep124] episode_rewards for agent 7 : -12.992000168189406\n",
      "[ep124] episode_rewards for agent 8 : -36.57599837705493\n",
      "[ep124] episode_rewards for agent 9 : -23.87999906297773\n",
      "[ep124] mean episode reward : -3.3050003657117486\n",
      "episode 125 done\n",
      "[ep125] episode_rewards for agent 0 : 1.0099993236362934\n",
      "[ep125] episode_rewards for agent 1 : -42.30799772683531\n",
      "[ep125] episode_rewards for agent 2 : 108.5279932282865\n",
      "[ep125] episode_rewards for agent 3 : -41.851998082362115\n",
      "[ep125] episode_rewards for agent 4 : 83.84799425676465\n",
      "[ep125] episode_rewards for agent 5 : 112.3679929850623\n",
      "[ep125] episode_rewards for agent 6 : -22.93599915970117\n",
      "[ep125] episode_rewards for agent 7 : -45.371997685171664\n",
      "[ep125] episode_rewards for agent 8 : -46.703997566364706\n",
      "[ep125] episode_rewards for agent 9 : 60.379995891824365\n",
      "[ep125] mean episode reward : 16.696198546513916\n",
      "episode 126 done\n",
      "[ep126] episode_rewards for agent 0 : 107.31799318641424\n",
      "[ep126] episode_rewards for agent 1 : -52.03599710483104\n",
      "[ep126] episode_rewards for agent 2 : 1.4319995464757085\n",
      "[ep126] episode_rewards for agent 3 : -39.40799824427813\n",
      "[ep126] episode_rewards for agent 4 : 3.779999219812453\n",
      "[ep126] episode_rewards for agent 5 : 42.04799702577293\n",
      "[ep126] episode_rewards for agent 6 : -40.3199979942292\n",
      "[ep126] episode_rewards for agent 7 : -47.5079974681139\n",
      "[ep126] episode_rewards for agent 8 : -58.90799652040005\n",
      "[ep126] episode_rewards for agent 9 : 3.4239992685616016\n",
      "[ep126] mean episode reward : -8.017799908481539\n",
      "episode 127 done\n",
      "[ep127] episode_rewards for agent 0 : 90.5219940841198\n",
      "[ep127] episode_rewards for agent 1 : -58.755996553227305\n",
      "[ep127] episode_rewards for agent 2 : 78.45199490711093\n",
      "[ep127] episode_rewards for agent 3 : -37.33599837683141\n",
      "[ep127] episode_rewards for agent 4 : 54.715995837934315\n",
      "[ep127] episode_rewards for agent 5 : 102.37999327387661\n",
      "[ep127] episode_rewards for agent 6 : -25.85199928097427\n",
      "[ep127] episode_rewards for agent 7 : -58.60399655159563\n",
      "[ep127] episode_rewards for agent 8 : -32.30799897108227\n",
      "[ep127] episode_rewards for agent 9 : 15.711998673155904\n",
      "[ep127] mean episode reward : 12.892598704248666\n",
      "episode 128 done\n",
      "[ep128] episode_rewards for agent 0 : 62.05399588402361\n",
      "[ep128] episode_rewards for agent 1 : -50.335997310467064\n",
      "[ep128] episode_rewards for agent 2 : -24.10799884237349\n",
      "[ep128] episode_rewards for agent 3 : -39.74799813888967\n",
      "[ep128] episode_rewards for agent 4 : 112.56399275548756\n",
      "[ep128] episode_rewards for agent 5 : 92.4199940348044\n",
      "[ep128] episode_rewards for agent 6 : -25.715998839586973\n",
      "[ep128] episode_rewards for agent 7 : -44.6079978402704\n",
      "[ep128] episode_rewards for agent 8 : -50.7959971986711\n",
      "[ep128] episode_rewards for agent 9 : 8.643999110907316\n",
      "[ep128] mean episode reward : 4.036999361496418\n",
      "episode 129 done\n",
      "[ep129] episode_rewards for agent 0 : -0.8300001788884401\n",
      "[ep129] episode_rewards for agent 1 : -48.375997447408736\n",
      "[ep129] episode_rewards for agent 2 : -17.199999194592237\n",
      "[ep129] episode_rewards for agent 3 : -47.58799757808447\n",
      "[ep129] episode_rewards for agent 4 : -7.268000144511461\n",
      "[ep129] episode_rewards for agent 5 : 40.07599714305252\n",
      "[ep129] episode_rewards for agent 6 : -19.89999962039292\n",
      "[ep129] episode_rewards for agent 7 : -39.62399808689952\n",
      "[ep129] episode_rewards for agent 8 : -53.175996949896216\n",
      "[ep129] episode_rewards for agent 9 : 15.979998636990786\n",
      "[ep129] mean episode reward : -17.790599342063068\n",
      "episode 130 done\n",
      "[ep130] episode_rewards for agent 0 : 88.62599402759224\n",
      "[ep130] episode_rewards for agent 1 : -53.55599695071578\n",
      "[ep130] episode_rewards for agent 2 : 5.047999104484916\n",
      "[ep130] episode_rewards for agent 3 : -33.10399862471968\n",
      "[ep130] episode_rewards for agent 4 : -36.21999865490943\n",
      "[ep130] episode_rewards for agent 5 : 62.419995800592005\n",
      "[ep130] episode_rewards for agent 6 : -25.627999365329742\n",
      "[ep130] episode_rewards for agent 7 : -57.563996645621955\n",
      "[ep130] episode_rewards for agent 8 : -45.56399773992598\n",
      "[ep130] episode_rewards for agent 9 : 39.39999717473984\n",
      "[ep130] mean episode reward : -5.614200187381357\n",
      "episode 131 done\n",
      "[ep131] episode_rewards for agent 0 : 34.893997218459845\n",
      "[ep131] episode_rewards for agent 1 : -50.81599725224078\n",
      "[ep131] episode_rewards for agent 2 : 25.139998231083155\n",
      "[ep131] episode_rewards for agent 3 : -37.40799843147397\n",
      "[ep131] episode_rewards for agent 4 : -38.091997974552214\n",
      "[ep131] episode_rewards for agent 5 : 65.54399558342993\n",
      "[ep131] episode_rewards for agent 6 : -24.899999146349728\n",
      "[ep131] episode_rewards for agent 7 : -53.867997005581856\n",
      "[ep131] episode_rewards for agent 8 : -52.275997082702816\n",
      "[ep131] episode_rewards for agent 9 : 35.91199736390263\n",
      "[ep131] mean episode reward : -9.58699984960258\n",
      "episode 132 done\n",
      "[ep132] episode_rewards for agent 0 : 39.87399712763727\n",
      "[ep132] episode_rewards for agent 1 : -42.54399783629924\n",
      "[ep132] episode_rewards for agent 2 : 32.23999766912311\n",
      "[ep132] episode_rewards for agent 3 : -47.80799756478518\n",
      "[ep132] episode_rewards for agent 4 : 84.57599435932934\n",
      "[ep132] episode_rewards for agent 5 : 74.60399496462196\n",
      "[ep132] episode_rewards for agent 6 : -35.11599841993302\n",
      "[ep132] episode_rewards for agent 7 : -43.423997942358255\n",
      "[ep132] episode_rewards for agent 8 : -46.9119974905625\n",
      "[ep132] episode_rewards for agent 9 : 42.26399705465883\n",
      "[ep132] mean episode reward : 5.775399192143231\n",
      "episode 133 done\n",
      "[ep133] episode_rewards for agent 0 : 19.33399822935462\n",
      "[ep133] episode_rewards for agent 1 : -55.14799678232521\n",
      "[ep133] episode_rewards for agent 2 : -33.77199864573777\n",
      "[ep133] episode_rewards for agent 3 : -34.67999873124063\n",
      "[ep133] episode_rewards for agent 4 : -6.580000496469438\n",
      "[ep133] episode_rewards for agent 5 : 79.77999459579587\n",
      "[ep133] episode_rewards for agent 6 : -34.03999850805849\n",
      "[ep133] episode_rewards for agent 7 : -31.0039987526834\n",
      "[ep133] episode_rewards for agent 8 : -54.73599689640105\n",
      "[ep133] episode_rewards for agent 9 : 69.3639954244718\n",
      "[ep133] mean episode reward : -8.148200056329369\n",
      "episode 134 done\n",
      "[ep134] episode_rewards for agent 0 : 101.79799332842231\n",
      "[ep134] episode_rewards for agent 1 : -59.97999642603099\n",
      "[ep134] episode_rewards for agent 2 : 57.83599609788507\n",
      "[ep134] episode_rewards for agent 3 : -51.0919971363619\n",
      "[ep134] episode_rewards for agent 4 : -4.348000245168805\n",
      "[ep134] episode_rewards for agent 5 : 47.79199649114162\n",
      "[ep134] episode_rewards for agent 6 : -15.00799993891269\n",
      "[ep134] episode_rewards for agent 7 : -58.4079965678975\n",
      "[ep134] episode_rewards for agent 8 : -56.55199673678726\n",
      "[ep134] episode_rewards for agent 9 : 59.03199612442404\n",
      "[ep134] mean episode reward : 2.1069994990713896\n",
      "episode 135 done\n",
      "[ep135] episode_rewards for agent 0 : 2.373999610543251\n",
      "[ep135] episode_rewards for agent 1 : -55.1319968951866\n",
      "[ep135] episode_rewards for agent 2 : 13.663998908363283\n",
      "[ep135] episode_rewards for agent 3 : -33.27199846319854\n",
      "[ep135] episode_rewards for agent 4 : -31.37599839270115\n",
      "[ep135] episode_rewards for agent 5 : 51.29999657999724\n",
      "[ep135] episode_rewards for agent 6 : -20.5759993288666\n",
      "[ep135] episode_rewards for agent 7 : -30.235998997464776\n",
      "[ep135] episode_rewards for agent 8 : -16.324000101536512\n",
      "[ep135] episode_rewards for agent 9 : 32.01599750481546\n",
      "[ep135] mean episode reward : -8.756199957523496\n",
      "episode 136 done\n",
      "[ep136] episode_rewards for agent 0 : 164.4779897853732\n",
      "[ep136] episode_rewards for agent 1 : -58.54799656756222\n",
      "[ep136] episode_rewards for agent 2 : 61.81199580896646\n",
      "[ep136] episode_rewards for agent 3 : -25.703999447636306\n",
      "[ep136] episode_rewards for agent 4 : 76.87199490703642\n",
      "[ep136] episode_rewards for agent 5 : 69.327995499596\n",
      "[ep136] episode_rewards for agent 6 : 16.64799816440791\n",
      "[ep136] episode_rewards for agent 7 : -44.899997807107866\n",
      "[ep136] episode_rewards for agent 8 : -30.73599881492555\n",
      "[ep136] episode_rewards for agent 9 : 77.59999501518905\n",
      "[ep136] mean episode reward : 30.68499765433371\n",
      "episode 137 done\n",
      "[ep137] episode_rewards for agent 0 : 35.809997151605785\n",
      "[ep137] episode_rewards for agent 1 : -53.011997050605714\n",
      "[ep137] episode_rewards for agent 2 : 63.77599537093192\n",
      "[ep137] episode_rewards for agent 3 : -46.483997620642185\n",
      "[ep137] episode_rewards for agent 4 : 68.3599954508245\n",
      "[ep137] episode_rewards for agent 5 : 63.883995852433145\n",
      "[ep137] episode_rewards for agent 6 : -12.915999961085618\n",
      "[ep137] episode_rewards for agent 7 : -54.191996878013015\n",
      "[ep137] episode_rewards for agent 8 : -51.259997149929404\n",
      "[ep137] episode_rewards for agent 9 : 9.351999124512076\n",
      "[ep137] mean episode reward : 2.331799429003149\n",
      "episode 138 done\n",
      "[ep138] episode_rewards for agent 0 : 13.309998657554388\n",
      "[ep138] episode_rewards for agent 1 : -30.2159991459921\n",
      "[ep138] episode_rewards for agent 2 : -17.471999544650316\n",
      "[ep138] episode_rewards for agent 3 : -14.936000142246485\n",
      "[ep138] episode_rewards for agent 4 : 13.39999858662486\n",
      "[ep138] episode_rewards for agent 5 : 69.67599529959261\n",
      "[ep138] episode_rewards for agent 6 : -44.2759978370741\n",
      "[ep138] episode_rewards for agent 7 : -40.963998183608055\n",
      "[ep138] episode_rewards for agent 8 : -55.01199688296765\n",
      "[ep138] episode_rewards for agent 9 : 29.43999783694744\n",
      "[ep138] mean episode reward : -7.70500013558194\n",
      "episode 139 done\n",
      "[ep139] episode_rewards for agent 0 : 63.309995791874826\n",
      "[ep139] episode_rewards for agent 1 : -59.303996491245925\n",
      "[ep139] episode_rewards for agent 2 : 2.2199994903057814\n",
      "[ep139] episode_rewards for agent 3 : -23.639999551698565\n",
      "[ep139] episode_rewards for agent 4 : 14.19199858698994\n",
      "[ep139] episode_rewards for agent 5 : -7.340000133961439\n",
      "[ep139] episode_rewards for agent 6 : -29.943998953327537\n",
      "[ep139] episode_rewards for agent 7 : -42.963997922837734\n",
      "[ep139] episode_rewards for agent 8 : -51.94799716304988\n",
      "[ep139] episode_rewards for agent 9 : 63.83999567013234\n",
      "[ep139] mean episode reward : -7.157800067681819\n",
      "episode 140 done\n",
      "[ep140] episode_rewards for agent 0 : 95.98199378419667\n",
      "[ep140] episode_rewards for agent 1 : -57.13999668043107\n",
      "[ep140] episode_rewards for agent 2 : -4.112000218592584\n",
      "[ep140] episode_rewards for agent 3 : -10.815999901853502\n",
      "[ep140] episode_rewards for agent 4 : 10.16799901239574\n",
      "[ep140] episode_rewards for agent 5 : 82.7959946077317\n",
      "[ep140] episode_rewards for agent 6 : -30.39999871328473\n",
      "[ep140] episode_rewards for agent 7 : -54.48399691656232\n",
      "[ep140] episode_rewards for agent 8 : -57.007996678352356\n",
      "[ep140] episode_rewards for agent 9 : 48.68799675628543\n",
      "[ep140] mean episode reward : 2.3673995051532986\n",
      "episode 141 done\n",
      "[ep141] episode_rewards for agent 0 : 68.08199535496533\n",
      "[ep141] episode_rewards for agent 1 : -46.47199768573046\n",
      "[ep141] episode_rewards for agent 2 : -6.499999898485839\n",
      "[ep141] episode_rewards for agent 3 : -32.267998927272856\n",
      "[ep141] episode_rewards for agent 4 : 11.667998755350709\n",
      "[ep141] episode_rewards for agent 5 : 172.85598934907466\n",
      "[ep141] episode_rewards for agent 6 : -37.443998283706605\n",
      "[ep141] episode_rewards for agent 7 : -26.507999223656952\n",
      "[ep141] episode_rewards for agent 8 : -58.71199651900679\n",
      "[ep141] episode_rewards for agent 9 : -16.879999465309083\n",
      "[ep141] mean episode reward : 2.7821993456222116\n",
      "episode 142 done\n",
      "[ep142] episode_rewards for agent 0 : -9.273999699391425\n",
      "[ep142] episode_rewards for agent 1 : -52.73199710249901\n",
      "[ep142] episode_rewards for agent 2 : -35.71999811474234\n",
      "[ep142] episode_rewards for agent 3 : -24.41999918874353\n",
      "[ep142] episode_rewards for agent 4 : 4.263999077491462\n",
      "[ep142] episode_rewards for agent 5 : -7.664000319316983\n",
      "[ep142] episode_rewards for agent 6 : 9.579998560249805\n",
      "[ep142] episode_rewards for agent 7 : -57.67999661900103\n",
      "[ep142] episode_rewards for agent 8 : -41.51999796368182\n",
      "[ep142] episode_rewards for agent 9 : 4.255999247543514\n",
      "[ep142] mean episode reward : -21.090999212209134\n",
      "episode 143 done\n",
      "[ep143] episode_rewards for agent 0 : 138.16199150215834\n",
      "[ep143] episode_rewards for agent 1 : -56.61999674234539\n",
      "[ep143] episode_rewards for agent 2 : -24.699998812749982\n",
      "[ep143] episode_rewards for agent 3 : -28.099998880177736\n",
      "[ep143] episode_rewards for agent 4 : 43.80399689916521\n",
      "[ep143] episode_rewards for agent 5 : 104.49199334345758\n",
      "[ep143] episode_rewards for agent 6 : -46.91599759273231\n",
      "[ep143] episode_rewards for agent 7 : -40.451998215168715\n",
      "[ep143] episode_rewards for agent 8 : -47.53599741309881\n",
      "[ep143] episode_rewards for agent 9 : -40.48799784388393\n",
      "[ep143] mean episode reward : 0.1645996244624257\n",
      "episode 144 done\n",
      "[ep144] episode_rewards for agent 0 : 80.27799482643604\n",
      "[ep144] episode_rewards for agent 1 : -54.8359968373552\n",
      "[ep144] episode_rewards for agent 2 : -0.012000068090856075\n",
      "[ep144] episode_rewards for agent 3 : -40.207997903227806\n",
      "[ep144] episode_rewards for agent 4 : -38.54799792077392\n",
      "[ep144] episode_rewards for agent 5 : 148.7639907542616\n",
      "[ep144] episode_rewards for agent 6 : -19.903999902307987\n",
      "[ep144] episode_rewards for agent 7 : -52.44799691811204\n",
      "[ep144] episode_rewards for agent 8 : -35.63599870260805\n",
      "[ep144] episode_rewards for agent 9 : -31.88399861846119\n",
      "[ep144] mean episode reward : -4.4434001290239395\n",
      "episode 145 done\n",
      "[ep145] episode_rewards for agent 0 : 110.81399283464998\n",
      "[ep145] episode_rewards for agent 1 : -51.97999712638557\n",
      "[ep145] episode_rewards for agent 2 : 10.087999142706394\n",
      "[ep145] episode_rewards for agent 3 : -48.50799748674035\n",
      "[ep145] episode_rewards for agent 4 : -8.29600003734231\n",
      "[ep145] episode_rewards for agent 5 : 13.807998307049274\n",
      "[ep145] episode_rewards for agent 6 : -16.46399992518127\n",
      "[ep145] episode_rewards for agent 7 : -58.63599655497819\n",
      "[ep145] episode_rewards for agent 8 : -43.69599783793092\n",
      "[ep145] episode_rewards for agent 9 : 30.54799761902541\n",
      "[ep145] mean episode reward : -6.232200106512755\n",
      "episode 146 done\n",
      "[ep146] episode_rewards for agent 0 : 90.82199416030198\n",
      "[ep146] episode_rewards for agent 1 : -49.455997379496694\n",
      "[ep146] episode_rewards for agent 2 : -33.795998042449355\n",
      "[ep146] episode_rewards for agent 3 : -29.163999235257506\n",
      "[ep146] episode_rewards for agent 4 : 70.8559951595962\n",
      "[ep146] episode_rewards for agent 5 : 57.383996036835015\n",
      "[ep146] episode_rewards for agent 6 : -23.599999545142055\n",
      "[ep146] episode_rewards for agent 7 : -46.347997698932886\n",
      "[ep146] episode_rewards for agent 8 : -45.81599765829742\n",
      "[ep146] episode_rewards for agent 9 : 44.047996846958995\n",
      "[ep146] mean episode reward : 3.4929992644116283\n",
      "episode 147 done\n",
      "[ep147] episode_rewards for agent 0 : 55.32199601549655\n",
      "[ep147] episode_rewards for agent 1 : -54.14399696420878\n",
      "[ep147] episode_rewards for agent 2 : -41.227997835725546\n",
      "[ep147] episode_rewards for agent 3 : -28.875999002717435\n",
      "[ep147] episode_rewards for agent 4 : 174.6399891069159\n",
      "[ep147] episode_rewards for agent 5 : -42.50399768259376\n",
      "[ep147] episode_rewards for agent 6 : -36.63999848533422\n",
      "[ep147] episode_rewards for agent 7 : -20.948000012896955\n",
      "[ep147] episode_rewards for agent 8 : -53.33999702055007\n",
      "[ep147] episode_rewards for agent 9 : 42.19999687653035\n",
      "[ep147] mean episode reward : -0.5518005005083978\n",
      "episode 148 done\n",
      "[ep148] episode_rewards for agent 0 : 76.62199487350881\n",
      "[ep148] episode_rewards for agent 1 : -56.49199669715017\n",
      "[ep148] episode_rewards for agent 2 : 56.95999621693045\n",
      "[ep148] episode_rewards for agent 3 : -35.995998417027295\n",
      "[ep148] episode_rewards for agent 4 : -18.25199997238815\n",
      "[ep148] episode_rewards for agent 5 : 155.6599905025214\n",
      "[ep148] episode_rewards for agent 6 : -22.743999537080526\n",
      "[ep148] episode_rewards for agent 7 : -40.07599806599319\n",
      "[ep148] episode_rewards for agent 8 : -51.391997133381665\n",
      "[ep148] episode_rewards for agent 9 : 30.0079979384318\n",
      "[ep148] mean episode reward : 9.429798970837146\n",
      "episode 149 done\n",
      "[ep149] episode_rewards for agent 0 : 92.57399399671704\n",
      "[ep149] episode_rewards for agent 1 : -55.73199670482427\n",
      "[ep149] episode_rewards for agent 2 : 50.84799681883305\n",
      "[ep149] episode_rewards for agent 3 : -39.43999819085002\n",
      "[ep149] episode_rewards for agent 4 : 64.19199524819851\n",
      "[ep149] episode_rewards for agent 5 : 124.40399220958352\n",
      "[ep149] episode_rewards for agent 6 : -28.039999041706324\n",
      "[ep149] episode_rewards for agent 7 : -49.26799742691219\n",
      "[ep149] episode_rewards for agent 8 : -41.8039980083704\n",
      "[ep149] episode_rewards for agent 9 : 27.671997831203043\n",
      "[ep149] mean episode reward : 14.540598673187196\n",
      "episode 150 done\n",
      "[ep150] episode_rewards for agent 0 : 68.33799524232745\n",
      "[ep150] episode_rewards for agent 1 : -59.25999647192657\n",
      "[ep150] episode_rewards for agent 2 : 107.37999332882464\n",
      "[ep150] episode_rewards for agent 3 : -20.160000099800527\n",
      "[ep150] episode_rewards for agent 4 : 74.71599532477558\n",
      "[ep150] episode_rewards for agent 5 : 43.70799672976136\n",
      "[ep150] episode_rewards for agent 6 : -23.36799916625023\n",
      "[ep150] episode_rewards for agent 7 : -18.787999825552106\n",
      "[ep150] episode_rewards for agent 8 : -43.0639977119863\n",
      "[ep150] episode_rewards for agent 9 : -8.679999786429107\n",
      "[ep150] mean episode reward : 12.082198756374419\n",
      "episode 151 done\n",
      "[ep151] episode_rewards for agent 0 : 26.74599816277623\n",
      "[ep151] episode_rewards for agent 1 : -48.00399730168283\n",
      "[ep151] episode_rewards for agent 2 : 32.13999768346548\n",
      "[ep151] episode_rewards for agent 3 : -36.61599820572883\n",
      "[ep151] episode_rewards for agent 4 : 114.1759929349646\n",
      "[ep151] episode_rewards for agent 5 : 88.64799400325865\n",
      "[ep151] episode_rewards for agent 6 : -50.239997290074825\n",
      "[ep151] episode_rewards for agent 7 : -50.623997268266976\n",
      "[ep151] episode_rewards for agent 8 : -39.267998319119215\n",
      "[ep151] episode_rewards for agent 9 : 63.78399589192122\n",
      "[ep151] mean episode reward : 10.07419902915135\n",
      "episode 152 done\n",
      "[ep152] episode_rewards for agent 0 : 5.45799923595041\n",
      "[ep152] episode_rewards for agent 1 : -47.13999759592116\n",
      "[ep152] episode_rewards for agent 2 : -52.82399707566947\n",
      "[ep152] episode_rewards for agent 3 : -21.01199925970286\n",
      "[ep152] episode_rewards for agent 4 : 41.115997112356126\n",
      "[ep152] episode_rewards for agent 5 : 45.76399675104767\n",
      "[ep152] episode_rewards for agent 6 : -19.319999642670155\n",
      "[ep152] episode_rewards for agent 7 : -59.53999646380544\n",
      "[ep152] episode_rewards for agent 8 : -55.89599673356861\n",
      "[ep152] episode_rewards for agent 9 : -0.15600064489990473\n",
      "[ep152] mean episode reward : -16.354999431688338\n",
      "episode 153 done\n",
      "[ep153] episode_rewards for agent 0 : 51.21399646624923\n",
      "[ep153] episode_rewards for agent 1 : -56.5839967103675\n",
      "[ep153] episode_rewards for agent 2 : 23.223998121917248\n",
      "[ep153] episode_rewards for agent 3 : -35.967998361214995\n",
      "[ep153] episode_rewards for agent 4 : 137.2319914996624\n",
      "[ep153] episode_rewards for agent 5 : 44.49999663606286\n",
      "[ep153] episode_rewards for agent 6 : -48.351997289806604\n",
      "[ep153] episode_rewards for agent 7 : -30.043999195098877\n",
      "[ep153] episode_rewards for agent 8 : -59.547996471636\n",
      "[ep153] episode_rewards for agent 9 : 83.71599466633052\n",
      "[ep153] mean episode reward : 10.938998936209828\n",
      "episode 154 done\n",
      "[ep154] episode_rewards for agent 0 : 116.15399259328842\n",
      "[ep154] episode_rewards for agent 1 : -57.00799666903913\n",
      "[ep154] episode_rewards for agent 2 : 63.27999579254538\n",
      "[ep154] episode_rewards for agent 3 : -22.795999340713024\n",
      "[ep154] episode_rewards for agent 4 : 106.91599325835705\n",
      "[ep154] episode_rewards for agent 5 : 92.43599423579872\n",
      "[ep154] episode_rewards for agent 6 : -13.623999748378992\n",
      "[ep154] episode_rewards for agent 7 : -55.055996793322265\n",
      "[ep154] episode_rewards for agent 8 : -9.256000148132443\n",
      "[ep154] episode_rewards for agent 9 : 23.067998219281435\n",
      "[ep154] mean episode reward : 24.411398139968515\n",
      "episode 155 done\n",
      "[ep155] episode_rewards for agent 0 : 31.793997736647725\n",
      "[ep155] episode_rewards for agent 1 : -59.155996507033706\n",
      "[ep155] episode_rewards for agent 2 : 30.23599778022617\n",
      "[ep155] episode_rewards for agent 3 : -53.06799708120525\n",
      "[ep155] episode_rewards for agent 4 : 30.115997620858252\n",
      "[ep155] episode_rewards for agent 5 : 18.54799807537347\n",
      "[ep155] episode_rewards for agent 6 : -23.899999297223985\n",
      "[ep155] episode_rewards for agent 7 : -44.543997823260725\n",
      "[ep155] episode_rewards for agent 8 : -59.71599644981325\n",
      "[ep155] episode_rewards for agent 9 : 3.071999343112111\n",
      "[ep155] mean episode reward : -12.661799660231917\n",
      "episode 156 done\n",
      "[ep156] episode_rewards for agent 0 : 43.57399682700634\n",
      "[ep156] episode_rewards for agent 1 : -53.359997015446424\n",
      "[ep156] episode_rewards for agent 2 : -3.440000199712813\n",
      "[ep156] episode_rewards for agent 3 : -14.244000287726521\n",
      "[ep156] episode_rewards for agent 4 : 58.69199618231505\n",
      "[ep156] episode_rewards for agent 5 : 108.5679929535836\n",
      "[ep156] episode_rewards for agent 6 : -24.3479993166402\n",
      "[ep156] episode_rewards for agent 7 : -52.4839971261099\n",
      "[ep156] episode_rewards for agent 8 : -59.97999642603099\n",
      "[ep156] episode_rewards for agent 9 : -38.327997921034694\n",
      "[ep156] mean episode reward : -3.5350002329796553\n",
      "episode 157 done\n",
      "[ep157] episode_rewards for agent 0 : 11.321998837403953\n",
      "[ep157] episode_rewards for agent 1 : -47.39199741650373\n",
      "[ep157] episode_rewards for agent 2 : 0.8239994943141937\n",
      "[ep157] episode_rewards for agent 3 : -26.831999364309013\n",
      "[ep157] episode_rewards for agent 4 : 79.02399505674839\n",
      "[ep157] episode_rewards for agent 5 : 51.0399962104857\n",
      "[ep157] episode_rewards for agent 6 : -33.347998534329236\n",
      "[ep157] episode_rewards for agent 7 : -57.09599669650197\n",
      "[ep157] episode_rewards for agent 8 : -39.71599812619388\n",
      "[ep157] episode_rewards for agent 9 : -11.339999875053763\n",
      "[ep157] mean episode reward : -7.351400041393935\n",
      "episode 158 done\n",
      "[ep158] episode_rewards for agent 0 : 80.40999482478946\n",
      "[ep158] episode_rewards for agent 1 : -53.959996963851154\n",
      "[ep158] episode_rewards for agent 2 : 18.287998758256435\n",
      "[ep158] episode_rewards for agent 3 : -31.16799886804074\n",
      "[ep158] episode_rewards for agent 4 : 60.28399609494954\n",
      "[ep158] episode_rewards for agent 5 : 56.44799634348601\n",
      "[ep158] episode_rewards for agent 6 : -12.967999953776598\n",
      "[ep158] episode_rewards for agent 7 : -58.463996530510485\n",
      "[ep158] episode_rewards for agent 8 : -43.58399775438011\n",
      "[ep158] episode_rewards for agent 9 : 27.727997878566384\n",
      "[ep158] mean episode reward : 4.301399382948875\n",
      "episode 159 done\n",
      "[ep159] episode_rewards for agent 0 : 96.64999361336231\n",
      "[ep159] episode_rewards for agent 1 : -56.95199668593705\n",
      "[ep159] episode_rewards for agent 2 : 58.72399612702429\n",
      "[ep159] episode_rewards for agent 3 : -32.80799883697182\n",
      "[ep159] episode_rewards for agent 4 : 135.22799151949584\n",
      "[ep159] episode_rewards for agent 5 : 77.37599485460669\n",
      "[ep159] episode_rewards for agent 6 : -36.97199812158942\n",
      "[ep159] episode_rewards for agent 7 : -47.787997445091605\n",
      "[ep159] episode_rewards for agent 8 : -42.21599798742682\n",
      "[ep159] episode_rewards for agent 9 : 18.65999828558415\n",
      "[ep159] mean episode reward : 16.99019853230566\n",
      "episode 160 done\n",
      "[ep160] episode_rewards for agent 0 : 25.365997839719057\n",
      "[ep160] episode_rewards for agent 1 : -58.94799652136862\n",
      "[ep160] episode_rewards for agent 2 : 62.98799577448517\n",
      "[ep160] episode_rewards for agent 3 : -34.81199864950031\n",
      "[ep160] episode_rewards for agent 4 : 47.5559967039153\n",
      "[ep160] episode_rewards for agent 5 : 114.35599291231483\n",
      "[ep160] episode_rewards for agent 6 : -25.307999207638204\n",
      "[ep160] episode_rewards for agent 7 : -46.431997620500624\n",
      "[ep160] episode_rewards for agent 8 : -32.8799986904487\n",
      "[ep160] episode_rewards for agent 9 : 25.243998093530536\n",
      "[ep160] mean episode reward : 7.712999063450843\n",
      "episode 161 done\n",
      "[ep161] episode_rewards for agent 0 : 85.96199433226138\n",
      "[ep161] episode_rewards for agent 1 : -49.62799737043679\n",
      "[ep161] episode_rewards for agent 2 : 87.29599443171173\n",
      "[ep161] episode_rewards for agent 3 : -28.559999329037964\n",
      "[ep161] episode_rewards for agent 4 : 55.89599629212171\n",
      "[ep161] episode_rewards for agent 5 : 113.71999282389879\n",
      "[ep161] episode_rewards for agent 6 : -33.09999858122319\n",
      "[ep161] episode_rewards for agent 7 : -46.72399741131812\n",
      "[ep161] episode_rewards for agent 8 : -45.5679977145046\n",
      "[ep161] episode_rewards for agent 9 : -10.32399961259216\n",
      "[ep161] mean episode reward : 12.89699878608808\n",
      "episode 162 done\n",
      "[ep162] episode_rewards for agent 0 : 62.549995670095086\n",
      "[ep162] episode_rewards for agent 1 : -58.47599656600505\n",
      "[ep162] episode_rewards for agent 2 : 14.475998691283166\n",
      "[ep162] episode_rewards for agent 3 : -30.67999901995063\n",
      "[ep162] episode_rewards for agent 4 : 86.95999444276094\n",
      "[ep162] episode_rewards for agent 5 : 56.13599590398371\n",
      "[ep162] episode_rewards for agent 6 : -35.41999860201031\n",
      "[ep162] episode_rewards for agent 7 : -46.02799759991467\n",
      "[ep162] episode_rewards for agent 8 : -33.53599880076945\n",
      "[ep162] episode_rewards for agent 9 : 15.19599873200059\n",
      "[ep162] mean episode reward : 3.1177992851473393\n",
      "episode 163 done\n",
      "[ep163] episode_rewards for agent 0 : 73.13399523962289\n",
      "[ep163] episode_rewards for agent 1 : -51.211997175589204\n",
      "[ep163] episode_rewards for agent 2 : 20.19999849051237\n",
      "[ep163] episode_rewards for agent 3 : -52.45199704915285\n",
      "[ep163] episode_rewards for agent 4 : 18.807998343370855\n",
      "[ep163] episode_rewards for agent 5 : 54.503996113315225\n",
      "[ep163] episode_rewards for agent 6 : -2.4640005119144917\n",
      "[ep163] episode_rewards for agent 7 : -34.239998801611364\n",
      "[ep163] episode_rewards for agent 8 : -46.75999752897769\n",
      "[ep163] episode_rewards for agent 9 : 71.51999534852803\n",
      "[ep163] mean episode reward : 5.103799246810377\n",
      "episode 164 done\n",
      "[ep164] episode_rewards for agent 0 : 28.10999790020287\n",
      "[ep164] episode_rewards for agent 1 : -59.48399647511542\n",
      "[ep164] episode_rewards for agent 2 : -46.69599751569331\n",
      "[ep164] episode_rewards for agent 3 : -39.187998238019645\n",
      "[ep164] episode_rewards for agent 4 : 40.103997056372464\n",
      "[ep164] episode_rewards for agent 5 : 91.23199393041432\n",
      "[ep164] episode_rewards for agent 6 : -1.428000862710178\n",
      "[ep164] episode_rewards for agent 7 : -12.808000317774713\n",
      "[ep164] episode_rewards for agent 8 : -51.031997149810195\n",
      "[ep164] episode_rewards for agent 9 : 75.8759950818494\n",
      "[ep164] mean episode reward : 2.468599340971559\n",
      "episode 165 done\n",
      "[ep165] episode_rewards for agent 0 : 53.137996218167245\n",
      "[ep165] episode_rewards for agent 1 : -54.89599683508277\n",
      "[ep165] episode_rewards for agent 2 : 37.191997301764786\n",
      "[ep165] episode_rewards for agent 3 : -13.520000282675028\n",
      "[ep165] episode_rewards for agent 4 : 20.91999836731702\n",
      "[ep165] episode_rewards for agent 5 : 83.0079945186153\n",
      "[ep165] episode_rewards for agent 6 : -36.39999827928841\n",
      "[ep165] episode_rewards for agent 7 : -55.23599683959037\n",
      "[ep165] episode_rewards for agent 8 : -56.67999671585858\n",
      "[ep165] episode_rewards for agent 9 : 63.25199572741985\n",
      "[ep165] mean episode reward : 4.077799318078905\n",
      "episode 166 done\n",
      "[ep166] episode_rewards for agent 0 : 39.58999711088836\n",
      "[ep166] episode_rewards for agent 1 : -56.299996769055724\n",
      "[ep166] episode_rewards for agent 2 : 50.6519965082407\n",
      "[ep166] episode_rewards for agent 3 : -30.835999025963247\n",
      "[ep166] episode_rewards for agent 4 : 86.8159942580387\n",
      "[ep166] episode_rewards for agent 5 : 94.92399378307164\n",
      "[ep166] episode_rewards for agent 6 : -21.35599918384105\n",
      "[ep166] episode_rewards for agent 7 : -53.74799703527242\n",
      "[ep166] episode_rewards for agent 8 : -59.43599647656083\n",
      "[ep166] episode_rewards for agent 9 : 76.82399496622384\n",
      "[ep166] mean episode reward : 12.712998813576997\n",
      "episode 167 done\n",
      "[ep167] episode_rewards for agent 0 : 51.37799646053463\n",
      "[ep167] episode_rewards for agent 1 : -51.451997162774205\n",
      "[ep167] episode_rewards for agent 2 : 28.003998056054115\n",
      "[ep167] episode_rewards for agent 3 : -28.26399877667427\n",
      "[ep167] episode_rewards for agent 4 : 109.87999266386032\n",
      "[ep167] episode_rewards for agent 5 : -15.783999657258391\n",
      "[ep167] episode_rewards for agent 6 : -24.855999056249857\n",
      "[ep167] episode_rewards for agent 7 : -40.62399787828326\n",
      "[ep167] episode_rewards for agent 8 : -59.97999642603099\n",
      "[ep167] episode_rewards for agent 9 : -3.108000316657126\n",
      "[ep167] mean episode reward : -3.480600209347904\n",
      "episode 168 done\n",
      "[ep168] episode_rewards for agent 0 : 108.217992936261\n",
      "[ep168] episode_rewards for agent 1 : -50.41999717056751\n",
      "[ep168] episode_rewards for agent 2 : 33.48399747163057\n",
      "[ep168] episode_rewards for agent 3 : -31.5279987975955\n",
      "[ep168] episode_rewards for agent 4 : 88.13199442159384\n",
      "[ep168] episode_rewards for agent 5 : 146.083990810439\n",
      "[ep168] episode_rewards for agent 6 : -20.739999398589134\n",
      "[ep168] episode_rewards for agent 7 : -58.34799656737596\n",
      "[ep168] episode_rewards for agent 8 : -52.27199710998684\n",
      "[ep168] episode_rewards for agent 9 : 27.411997882649302\n",
      "[ep168] mean episode reward : 19.002198447845878\n",
      "episode 169 done\n",
      "[ep169] episode_rewards for agent 0 : 96.41399360727519\n",
      "[ep169] episode_rewards for agent 1 : -55.99999671056867\n",
      "[ep169] episode_rewards for agent 2 : 53.807996675372124\n",
      "[ep169] episode_rewards for agent 3 : -28.715999266132712\n",
      "[ep169] episode_rewards for agent 4 : 36.32399718556553\n",
      "[ep169] episode_rewards for agent 5 : 134.4559917030856\n",
      "[ep169] episode_rewards for agent 6 : -16.087999501265585\n",
      "[ep169] episode_rewards for agent 7 : -40.695997927337885\n",
      "[ep169] episode_rewards for agent 8 : -45.48399749863893\n",
      "[ep169] episode_rewards for agent 9 : 53.19999636430293\n",
      "[ep169] mean episode reward : 18.72179846316576\n",
      "episode 170 done\n",
      "[ep170] episode_rewards for agent 0 : 97.00199390947819\n",
      "[ep170] episode_rewards for agent 1 : -57.89199662860483\n",
      "[ep170] episode_rewards for agent 2 : 29.88399801403284\n",
      "[ep170] episode_rewards for agent 3 : -14.511999739333987\n",
      "[ep170] episode_rewards for agent 4 : 20.05999817326665\n",
      "[ep170] episode_rewards for agent 5 : 70.91999521292746\n",
      "[ep170] episode_rewards for agent 6 : -39.731998233124614\n",
      "[ep170] episode_rewards for agent 7 : -46.25599769316614\n",
      "[ep170] episode_rewards for agent 8 : -29.411999284289777\n",
      "[ep170] episode_rewards for agent 9 : 64.32399583235383\n",
      "[ep170] mean episode reward : 9.438598956353962\n",
      "episode 171 done\n",
      "[ep171] episode_rewards for agent 0 : -18.873999415896833\n",
      "[ep171] episode_rewards for agent 1 : -58.491996539756656\n",
      "[ep171] episode_rewards for agent 2 : -30.627998799085617\n",
      "[ep171] episode_rewards for agent 3 : -22.7519995784387\n",
      "[ep171] episode_rewards for agent 4 : -9.087999761104584\n",
      "[ep171] episode_rewards for agent 5 : 34.21599720977247\n",
      "[ep171] episode_rewards for agent 6 : -26.71199895069003\n",
      "[ep171] episode_rewards for agent 7 : -3.6960002165287733\n",
      "[ep171] episode_rewards for agent 8 : -27.931999260559678\n",
      "[ep171] episode_rewards for agent 9 : 16.207998561672866\n",
      "[ep171] mean episode reward : -14.774999675061554\n",
      "episode 172 done\n",
      "[ep172] episode_rewards for agent 0 : 195.9379879599437\n",
      "[ep172] episode_rewards for agent 1 : -56.851996692828834\n",
      "[ep172] episode_rewards for agent 2 : -10.491999700665474\n",
      "[ep172] episode_rewards for agent 3 : -30.743999073281884\n",
      "[ep172] episode_rewards for agent 4 : -32.919998433440924\n",
      "[ep172] episode_rewards for agent 5 : 163.5479898089543\n",
      "[ep172] episode_rewards for agent 6 : -39.607998210936785\n",
      "[ep172] episode_rewards for agent 7 : -49.315997331403196\n",
      "[ep172] episode_rewards for agent 8 : -38.243998270481825\n",
      "[ep172] episode_rewards for agent 9 : 62.96799595002085\n",
      "[ep172] mean episode reward : 16.427798600587995\n",
      "episode 173 done\n",
      "[ep173] episode_rewards for agent 0 : 81.9779944755137\n",
      "[ep173] episode_rewards for agent 1 : -58.00399659667164\n",
      "[ep173] episode_rewards for agent 2 : -16.635999327525496\n",
      "[ep173] episode_rewards for agent 3 : -26.68399936053902\n",
      "[ep173] episode_rewards for agent 4 : -18.407999533228576\n",
      "[ep173] episode_rewards for agent 5 : 132.43999166507274\n",
      "[ep173] episode_rewards for agent 6 : -21.211999434046447\n",
      "[ep173] episode_rewards for agent 7 : -4.832000469788909\n",
      "[ep173] episode_rewards for agent 8 : -50.5679972441867\n",
      "[ep173] episode_rewards for agent 9 : 29.951997838914394\n",
      "[ep173] mean episode reward : 4.802599201351404\n",
      "episode 174 done\n",
      "[ep174] episode_rewards for agent 0 : 14.541998540051281\n",
      "[ep174] episode_rewards for agent 1 : -53.71199697069824\n",
      "[ep174] episode_rewards for agent 2 : -16.075999240390956\n",
      "[ep174] episode_rewards for agent 3 : -17.25200020801276\n",
      "[ep174] episode_rewards for agent 4 : 57.931996337138116\n",
      "[ep174] episode_rewards for agent 5 : 149.51999074406922\n",
      "[ep174] episode_rewards for agent 6 : -54.98399679828435\n",
      "[ep174] episode_rewards for agent 7 : -35.86399815604091\n",
      "[ep174] episode_rewards for agent 8 : -58.691996541805565\n",
      "[ep174] episode_rewards for agent 9 : -15.431999596767128\n",
      "[ep174] mean episode reward : -3.001800189074129\n",
      "episode 175 done\n",
      "[ep175] episode_rewards for agent 0 : -47.081997216679156\n",
      "[ep175] episode_rewards for agent 1 : -58.39199654199183\n",
      "[ep175] episode_rewards for agent 2 : -44.8119976753369\n",
      "[ep175] episode_rewards for agent 3 : -26.607999242842197\n",
      "[ep175] episode_rewards for agent 4 : 68.42399554047734\n",
      "[ep175] episode_rewards for agent 5 : 82.31999454740435\n",
      "[ep175] episode_rewards for agent 6 : -32.83199866116047\n",
      "[ep175] episode_rewards for agent 7 : -39.859998253174126\n",
      "[ep175] episode_rewards for agent 8 : -56.83599672559649\n",
      "[ep175] episode_rewards for agent 9 : -29.051998588256538\n",
      "[ep175] mean episode reward : -18.4729992817156\n",
      "episode 176 done\n",
      "[ep176] episode_rewards for agent 0 : 72.07799518294632\n",
      "[ep176] episode_rewards for agent 1 : -56.2159967366606\n",
      "[ep176] episode_rewards for agent 2 : -39.359997782856226\n",
      "[ep176] episode_rewards for agent 3 : -20.99599990155548\n",
      "[ep176] episode_rewards for agent 4 : 23.371998328715563\n",
      "[ep176] episode_rewards for agent 5 : 68.42399522755295\n",
      "[ep176] episode_rewards for agent 6 : -16.739999463781714\n",
      "[ep176] episode_rewards for agent 7 : -19.747999317012727\n",
      "[ep176] episode_rewards for agent 8 : -42.67599779460579\n",
      "[ep176] episode_rewards for agent 9 : 70.43199532944709\n",
      "[ep176] mean episode reward : 3.8569993072189392\n",
      "episode 177 done\n",
      "[ep177] episode_rewards for agent 0 : 97.04199382849038\n",
      "[ep177] episode_rewards for agent 1 : -40.93199812062085\n",
      "[ep177] episode_rewards for agent 2 : 15.839998949319124\n",
      "[ep177] episode_rewards for agent 3 : -36.17599843908101\n",
      "[ep177] episode_rewards for agent 4 : 10.647998983971775\n",
      "[ep177] episode_rewards for agent 5 : 93.16799417696893\n",
      "[ep177] episode_rewards for agent 6 : -38.215998156927526\n",
      "[ep177] episode_rewards for agent 7 : -33.103998775593936\n",
      "[ep177] episode_rewards for agent 8 : -40.523998129181564\n",
      "[ep177] episode_rewards for agent 9 : -2.236000120639801\n",
      "[ep177] mean episode reward : 2.550999419670552\n",
      "episode 178 done\n",
      "[ep178] episode_rewards for agent 0 : 36.1379969548434\n",
      "[ep178] episode_rewards for agent 1 : -50.17999719269574\n",
      "[ep178] episode_rewards for agent 2 : 65.5799957010895\n",
      "[ep178] episode_rewards for agent 3 : -37.7879982329905\n",
      "[ep178] episode_rewards for agent 4 : 91.47199390362948\n",
      "[ep178] episode_rewards for agent 5 : 50.52799641434103\n",
      "[ep178] episode_rewards for agent 6 : 26.91999742295593\n",
      "[ep178] episode_rewards for agent 7 : -58.71199654042721\n",
      "[ep178] episode_rewards for agent 8 : -37.11599849909544\n",
      "[ep178] episode_rewards for agent 9 : 76.38799505587667\n",
      "[ep178] mean episode reward : 16.322998498752714\n",
      "episode 179 done\n",
      "[ep179] episode_rewards for agent 0 : 61.453995859250426\n",
      "[ep179] episode_rewards for agent 1 : -54.651996853761375\n",
      "[ep179] episode_rewards for agent 2 : 21.73199840914458\n",
      "[ep179] episode_rewards for agent 3 : -27.143999403342605\n",
      "[ep179] episode_rewards for agent 4 : 41.57599686272442\n",
      "[ep179] episode_rewards for agent 5 : 44.41199682187289\n",
      "[ep179] episode_rewards for agent 6 : -5.45600027218461\n",
      "[ep179] episode_rewards for agent 7 : -54.3199969092384\n",
      "[ep179] episode_rewards for agent 8 : -54.079996867105365\n",
      "[ep179] episode_rewards for agent 9 : 26.68799800146371\n",
      "[ep179] mean episode reward : 0.02099956488236785\n",
      "episode 180 done\n",
      "[ep180] episode_rewards for agent 0 : 53.61799618136138\n",
      "[ep180] episode_rewards for agent 1 : -56.059996753931046\n",
      "[ep180] episode_rewards for agent 2 : 9.535998987965286\n",
      "[ep180] episode_rewards for agent 3 : -22.563999706879258\n",
      "[ep180] episode_rewards for agent 4 : 30.599997576326132\n",
      "[ep180] episode_rewards for agent 5 : 83.48399441875517\n",
      "[ep180] episode_rewards for agent 6 : -2.004000506363809\n",
      "[ep180] episode_rewards for agent 7 : -34.33199845161289\n",
      "[ep180] episode_rewards for agent 8 : -35.963998625054955\n",
      "[ep180] episode_rewards for agent 9 : 10.675998992286623\n",
      "[ep180] mean episode reward : 3.698999211285263\n",
      "episode 181 done\n",
      "[ep181] episode_rewards for agent 0 : 49.70999632496387\n",
      "[ep181] episode_rewards for agent 1 : -59.34399648755789\n",
      "[ep181] episode_rewards for agent 2 : -19.539999097585678\n",
      "[ep181] episode_rewards for agent 3 : -31.55599899124354\n",
      "[ep181] episode_rewards for agent 4 : 51.13199633266777\n",
      "[ep181] episode_rewards for agent 5 : 107.363993184641\n",
      "[ep181] episode_rewards for agent 6 : -24.491999111138284\n",
      "[ep181] episode_rewards for agent 7 : -47.631997322663665\n",
      "[ep181] episode_rewards for agent 8 : -21.675999290309846\n",
      "[ep181] episode_rewards for agent 9 : 34.65599730797112\n",
      "[ep181] mean episode reward : 3.8621992849744857\n",
      "episode 182 done\n",
      "[ep182] episode_rewards for agent 0 : 119.213992273435\n",
      "[ep182] episode_rewards for agent 1 : -59.26799650210887\n",
      "[ep182] episode_rewards for agent 2 : 8.783999313600361\n",
      "[ep182] episode_rewards for agent 3 : -35.831998637877405\n",
      "[ep182] episode_rewards for agent 4 : 84.22399455029517\n",
      "[ep182] episode_rewards for agent 5 : 125.59199213143438\n",
      "[ep182] episode_rewards for agent 6 : -24.943999145179987\n",
      "[ep182] episode_rewards for agent 7 : -48.82399745937437\n",
      "[ep182] episode_rewards for agent 8 : -42.64399785455316\n",
      "[ep182] episode_rewards for agent 9 : 58.371996058151126\n",
      "[ep182] mean episode reward : 18.467398472782225\n",
      "episode 183 done\n",
      "[ep183] episode_rewards for agent 0 : 42.125997059978545\n",
      "[ep183] episode_rewards for agent 1 : -53.93199692200869\n",
      "[ep183] episode_rewards for agent 2 : 28.179997825995088\n",
      "[ep183] episode_rewards for agent 3 : -5.908000419847667\n",
      "[ep183] episode_rewards for agent 4 : 59.72399590071291\n",
      "[ep183] episode_rewards for agent 5 : 54.13599628582597\n",
      "[ep183] episode_rewards for agent 6 : -28.53599897492677\n",
      "[ep183] episode_rewards for agent 7 : -51.167997162789106\n",
      "[ep183] episode_rewards for agent 8 : -30.05599908903241\n",
      "[ep183] episode_rewards for agent 9 : 93.85199391841888\n",
      "[ep183] mean episode reward : 10.841798842232674\n",
      "episode 184 done\n",
      "[ep184] episode_rewards for agent 0 : 0.5299994433298707\n",
      "[ep184] episode_rewards for agent 1 : -57.679996602237225\n",
      "[ep184] episode_rewards for agent 2 : 9.091999071650207\n",
      "[ep184] episode_rewards for agent 3 : -18.71600018348545\n",
      "[ep184] episode_rewards for agent 4 : 23.999998033046722\n",
      "[ep184] episode_rewards for agent 5 : 51.23199605476111\n",
      "[ep184] episode_rewards for agent 6 : -4.460000578314066\n",
      "[ep184] episode_rewards for agent 7 : -34.38799879606813\n",
      "[ep184] episode_rewards for agent 8 : -51.38799711782485\n",
      "[ep184] episode_rewards for agent 9 : -11.495999534614384\n",
      "[ep184] mean episode reward : -9.32740002097562\n",
      "episode 185 done\n",
      "[ep185] episode_rewards for agent 0 : 68.80999543517828\n",
      "[ep185] episode_rewards for agent 1 : -51.479997128248215\n",
      "[ep185] episode_rewards for agent 2 : -8.467999880202115\n",
      "[ep185] episode_rewards for agent 3 : -34.71599875856191\n",
      "[ep185] episode_rewards for agent 4 : 40.779997068457305\n",
      "[ep185] episode_rewards for agent 5 : 59.75599596835673\n",
      "[ep185] episode_rewards for agent 6 : -27.97199864126742\n",
      "[ep185] episode_rewards for agent 7 : -55.135996885597706\n",
      "[ep185] episode_rewards for agent 8 : -47.299997604452074\n",
      "[ep185] episode_rewards for agent 9 : 37.36399731691927\n",
      "[ep185] mean episode reward : -1.8362003109417855\n",
      "episode 186 done\n",
      "[ep186] episode_rewards for agent 0 : 109.72999314591289\n",
      "[ep186] episode_rewards for agent 1 : -55.56799676641822\n",
      "[ep186] episode_rewards for agent 2 : -13.607999329455197\n",
      "[ep186] episode_rewards for agent 3 : -20.783999398350716\n",
      "[ep186] episode_rewards for agent 4 : -34.427998051047325\n",
      "[ep186] episode_rewards for agent 5 : 88.81199428997934\n",
      "[ep186] episode_rewards for agent 6 : 4.7439991580322385\n",
      "[ep186] episode_rewards for agent 7 : -39.3759983452037\n",
      "[ep186] episode_rewards for agent 8 : -50.759997284039855\n",
      "[ep186] episode_rewards for agent 9 : 51.30399655923247\n",
      "[ep186] mean episode reward : 4.006599397864193\n",
      "episode 187 done\n",
      "[ep187] episode_rewards for agent 0 : 66.19399534910917\n",
      "[ep187] episode_rewards for agent 1 : -55.47599679976702\n",
      "[ep187] episode_rewards for agent 2 : 48.47199669107795\n",
      "[ep187] episode_rewards for agent 3 : -23.06399962771684\n",
      "[ep187] episode_rewards for agent 4 : 37.855997022241354\n",
      "[ep187] episode_rewards for agent 5 : 67.16799523122609\n",
      "[ep187] episode_rewards for agent 6 : -17.055999868549407\n",
      "[ep187] episode_rewards for agent 7 : -45.751997696235776\n",
      "[ep187] episode_rewards for agent 8 : -40.459997991099954\n",
      "[ep187] episode_rewards for agent 9 : 21.35599838756025\n",
      "[ep187] mean episode reward : 5.9237990697845815\n",
      "episode 188 done\n",
      "[ep188] episode_rewards for agent 0 : 31.07399771735072\n",
      "[ep188] episode_rewards for agent 1 : -46.56399759836495\n",
      "[ep188] episode_rewards for agent 2 : -40.78399800043553\n",
      "[ep188] episode_rewards for agent 3 : -10.724000516347587\n",
      "[ep188] episode_rewards for agent 4 : 33.96399737522006\n",
      "[ep188] episode_rewards for agent 5 : 58.63599585276097\n",
      "[ep188] episode_rewards for agent 6 : -24.387998993508518\n",
      "[ep188] episode_rewards for agent 7 : -34.29199855681509\n",
      "[ep188] episode_rewards for agent 8 : -55.16799678746611\n",
      "[ep188] episode_rewards for agent 9 : 53.78399638272822\n",
      "[ep188] mean episode reward : -3.446200312487781\n",
      "episode 189 done\n",
      "[ep189] episode_rewards for agent 0 : 76.36999495700002\n",
      "[ep189] episode_rewards for agent 1 : -56.51199667993933\n",
      "[ep189] episode_rewards for agent 2 : 19.255998014472425\n",
      "[ep189] episode_rewards for agent 3 : -24.127999258227646\n",
      "[ep189] episode_rewards for agent 4 : 43.611996941268444\n",
      "[ep189] episode_rewards for agent 5 : -0.9920005593448877\n",
      "[ep189] episode_rewards for agent 6 : -25.843998992815614\n",
      "[ep189] episode_rewards for agent 7 : -56.49999674130231\n",
      "[ep189] episode_rewards for agent 8 : -39.53599821217358\n",
      "[ep189] episode_rewards for agent 9 : 26.127997904084623\n",
      "[ep189] mean episode reward : -3.814600262697786\n",
      "episode 190 done\n",
      "[ep190] episode_rewards for agent 0 : 113.28599264379591\n",
      "[ep190] episode_rewards for agent 1 : -58.80399651359767\n",
      "[ep190] episode_rewards for agent 2 : 32.05599763896316\n",
      "[ep190] episode_rewards for agent 3 : -34.47599852550775\n",
      "[ep190] episode_rewards for agent 4 : 51.83599629625678\n",
      "[ep190] episode_rewards for agent 5 : 82.2919947206974\n",
      "[ep190] episode_rewards for agent 6 : -26.727998820133507\n",
      "[ep190] episode_rewards for agent 7 : -58.627996551804245\n",
      "[ep190] episode_rewards for agent 8 : -56.823996705934405\n",
      "[ep190] episode_rewards for agent 9 : 82.46799472160637\n",
      "[ep190] mean episode reward : 12.647798890434206\n",
      "episode 191 done\n",
      "[ep191] episode_rewards for agent 0 : 73.62599508464336\n",
      "[ep191] episode_rewards for agent 1 : -45.5079974764958\n",
      "[ep191] episode_rewards for agent 2 : 42.52399705443531\n",
      "[ep191] episode_rewards for agent 3 : -35.49199851974845\n",
      "[ep191] episode_rewards for agent 4 : 76.33999488782138\n",
      "[ep191] episode_rewards for agent 5 : 66.55199543572962\n",
      "[ep191] episode_rewards for agent 6 : -11.292000034824014\n",
      "[ep191] episode_rewards for agent 7 : -52.21199696324766\n",
      "[ep191] episode_rewards for agent 8 : -23.239999775774777\n",
      "[ep191] episode_rewards for agent 9 : 9.96799914445728\n",
      "[ep191] mean episode reward : 10.126598883699625\n",
      "episode 192 done\n",
      "[ep192] episode_rewards for agent 0 : 68.70999515242875\n",
      "[ep192] episode_rewards for agent 1 : -52.33599703852087\n",
      "[ep192] episode_rewards for agent 2 : -38.18399791419506\n",
      "[ep192] episode_rewards for agent 3 : -28.11999915447086\n",
      "[ep192] episode_rewards for agent 4 : 91.60799417831004\n",
      "[ep192] episode_rewards for agent 5 : 63.89999552350491\n",
      "[ep192] episode_rewards for agent 6 : 0.7199992705136538\n",
      "[ep192] episode_rewards for agent 7 : -30.155999158509076\n",
      "[ep192] episode_rewards for agent 8 : -41.579998013563454\n",
      "[ep192] episode_rewards for agent 9 : 14.119998675771058\n",
      "[ep192] mean episode reward : 4.868199152126908\n",
      "episode 193 done\n",
      "[ep193] episode_rewards for agent 0 : 121.85799232963473\n",
      "[ep193] episode_rewards for agent 1 : -56.04799678642303\n",
      "[ep193] episode_rewards for agent 2 : -27.367998487316072\n",
      "[ep193] episode_rewards for agent 3 : -27.435998931527138\n",
      "[ep193] episode_rewards for agent 4 : 74.67999519594014\n",
      "[ep193] episode_rewards for agent 5 : 32.703997211530805\n",
      "[ep193] episode_rewards for agent 6 : -37.97599806915969\n",
      "[ep193] episode_rewards for agent 7 : -46.21999760065228\n",
      "[ep193] episode_rewards for agent 8 : -41.879997932352126\n",
      "[ep193] episode_rewards for agent 9 : 44.87999686598778\n",
      "[ep193] mean episode reward : 3.719399379566312\n",
      "episode 194 done\n",
      "[ep194] episode_rewards for agent 0 : 81.10999468807131\n",
      "[ep194] episode_rewards for agent 1 : -51.82399712316692\n",
      "[ep194] episode_rewards for agent 2 : -43.41999767906964\n",
      "[ep194] episode_rewards for agent 3 : -39.503998247906566\n",
      "[ep194] episode_rewards for agent 4 : 49.791996425017715\n",
      "[ep194] episode_rewards for agent 5 : 21.319998068735003\n",
      "[ep194] episode_rewards for agent 6 : -37.54399808868766\n",
      "[ep194] episode_rewards for agent 7 : -30.2159991171211\n",
      "[ep194] episode_rewards for agent 8 : -51.90399717260152\n",
      "[ep194] episode_rewards for agent 9 : 62.52799587510526\n",
      "[ep194] mean episode reward : -3.966200237162411\n",
      "episode 195 done\n",
      "[ep195] episode_rewards for agent 0 : 73.26999496202916\n",
      "[ep195] episode_rewards for agent 1 : -53.811996817588806\n",
      "[ep195] episode_rewards for agent 2 : -2.9280003290623426\n",
      "[ep195] episode_rewards for agent 3 : -29.22799908462912\n",
      "[ep195] episode_rewards for agent 4 : 26.391997830942273\n",
      "[ep195] episode_rewards for agent 5 : 99.8279935689643\n",
      "[ep195] episode_rewards for agent 6 : -11.131999699398875\n",
      "[ep195] episode_rewards for agent 7 : -55.50399682298303\n",
      "[ep195] episode_rewards for agent 8 : -43.591997540555894\n",
      "[ep195] episode_rewards for agent 9 : 23.89999814145267\n",
      "[ep195] mean episode reward : 2.7193994209170342\n",
      "episode 196 done\n",
      "[ep196] episode_rewards for agent 0 : 76.69799484778196\n",
      "[ep196] episode_rewards for agent 1 : -53.03599701542407\n",
      "[ep196] episode_rewards for agent 2 : 11.911998820491135\n",
      "[ep196] episode_rewards for agent 3 : -44.61199775338173\n",
      "[ep196] episode_rewards for agent 4 : -28.619998638518155\n",
      "[ep196] episode_rewards for agent 5 : 30.83999765664339\n",
      "[ep196] episode_rewards for agent 6 : 10.199998311698437\n",
      "[ep196] episode_rewards for agent 7 : -43.40399797540158\n",
      "[ep196] episode_rewards for agent 8 : -25.80799953173846\n",
      "[ep196] episode_rewards for agent 9 : 51.379996434785426\n",
      "[ep196] mean episode reward : -1.4450004843063653\n",
      "episode 197 done\n",
      "[ep197] episode_rewards for agent 0 : 71.93799514416605\n",
      "[ep197] episode_rewards for agent 1 : -59.179996496997774\n",
      "[ep197] episode_rewards for agent 2 : -32.331998341716826\n",
      "[ep197] episode_rewards for agent 3 : -27.54399901162833\n",
      "[ep197] episode_rewards for agent 4 : 51.65999642666429\n",
      "[ep197] episode_rewards for agent 5 : 83.91199454758316\n",
      "[ep197] episode_rewards for agent 6 : 8.931998934596777\n",
      "[ep197] episode_rewards for agent 7 : -21.799999034963548\n",
      "[ep197] episode_rewards for agent 8 : -37.1999985165894\n",
      "[ep197] episode_rewards for agent 9 : 40.90399708878249\n",
      "[ep197] mean episode reward : 7.928999073989689\n",
      "episode 198 done\n",
      "[ep198] episode_rewards for agent 0 : 52.35799627099186\n",
      "[ep198] episode_rewards for agent 1 : -54.011996906250715\n",
      "[ep198] episode_rewards for agent 2 : 13.931998880580068\n",
      "[ep198] episode_rewards for agent 3 : -29.123998953029513\n",
      "[ep198] episode_rewards for agent 4 : 166.67198934871703\n",
      "[ep198] episode_rewards for agent 5 : 86.30399439763278\n",
      "[ep198] episode_rewards for agent 6 : -21.18799912277609\n",
      "[ep198] episode_rewards for agent 7 : -28.431999195367098\n",
      "[ep198] episode_rewards for agent 8 : -40.199997862800956\n",
      "[ep198] episode_rewards for agent 9 : -11.227999842725694\n",
      "[ep198] mean episode reward : 13.508198701497168\n",
      "episode 199 done\n",
      "[ep199] episode_rewards for agent 0 : 80.01399458106607\n",
      "[ep199] episode_rewards for agent 1 : -55.623996794223785\n",
      "[ep199] episode_rewards for agent 2 : 22.24399834405631\n",
      "[ep199] episode_rewards for agent 3 : -21.819999961182475\n",
      "[ep199] episode_rewards for agent 4 : 30.367997772991657\n",
      "[ep199] episode_rewards for agent 5 : 40.027996918186545\n",
      "[ep199] episode_rewards for agent 6 : -1.6640006247907877\n",
      "[ep199] episode_rewards for agent 7 : -52.44399696402252\n",
      "[ep199] episode_rewards for agent 8 : -58.02799657732248\n",
      "[ep199] episode_rewards for agent 9 : -11.45599970780313\n",
      "[ep199] mean episode reward : -2.8382003013044597\n",
      "episode 200 done\n",
      "[ep200] episode_rewards for agent 0 : 69.14599517174065\n",
      "[ep200] episode_rewards for agent 1 : -57.4919966282323\n",
      "[ep200] episode_rewards for agent 2 : -30.99199837539345\n",
      "[ep200] episode_rewards for agent 3 : -22.675999651663005\n",
      "[ep200] episode_rewards for agent 4 : -2.8280001785606146\n",
      "[ep200] episode_rewards for agent 5 : -5.028000919148326\n",
      "[ep200] episode_rewards for agent 6 : -14.671999494545162\n",
      "[ep200] episode_rewards for agent 7 : -48.835997433401644\n",
      "[ep200] episode_rewards for agent 8 : -42.15999803878367\n",
      "[ep200] episode_rewards for agent 9 : 10.575998906977475\n",
      "[ep200] mean episode reward : -14.496199664101004\n",
      "episode 201 done\n",
      "[ep201] episode_rewards for agent 0 : 107.96599304582924\n",
      "[ep201] episode_rewards for agent 1 : -55.82399678323418\n",
      "[ep201] episode_rewards for agent 2 : -13.987999501638114\n",
      "[ep201] episode_rewards for agent 3 : -18.18400024343282\n",
      "[ep201] episode_rewards for agent 4 : 22.22799811884761\n",
      "[ep201] episode_rewards for agent 5 : 103.39199347235262\n",
      "[ep201] episode_rewards for agent 6 : -28.71999875549227\n",
      "[ep201] episode_rewards for agent 7 : -48.65199748240411\n",
      "[ep201] episode_rewards for agent 8 : -48.76399744767696\n",
      "[ep201] episode_rewards for agent 9 : 16.55199841503054\n",
      "[ep201] mean episode reward : 3.6005992838181555\n",
      "episode 202 done\n",
      "[ep202] episode_rewards for agent 0 : 81.397994549945\n",
      "[ep202] episode_rewards for agent 1 : -57.347996624186635\n",
      "[ep202] episode_rewards for agent 2 : 2.2599996980279684\n",
      "[ep202] episode_rewards for agent 3 : -20.28800009470433\n",
      "[ep202] episode_rewards for agent 4 : 15.471998789347708\n",
      "[ep202] episode_rewards for agent 5 : 122.6919923312962\n",
      "[ep202] episode_rewards for agent 6 : -42.179998049512506\n",
      "[ep202] episode_rewards for agent 7 : -48.63599747605622\n",
      "[ep202] episode_rewards for agent 8 : -31.087998997420073\n",
      "[ep202] episode_rewards for agent 9 : 42.58399704936892\n",
      "[ep202] mean episode reward : 6.486599117610604\n",
      "episode 203 done\n",
      "[ep203] episode_rewards for agent 0 : 63.1579956645146\n",
      "[ep203] episode_rewards for agent 1 : -51.28799717128277\n",
      "[ep203] episode_rewards for agent 2 : 7.851999219506979\n",
      "[ep203] episode_rewards for agent 3 : -15.768000295385718\n",
      "[ep203] episode_rewards for agent 4 : 48.647996447980404\n",
      "[ep203] episode_rewards for agent 5 : -10.288000346161425\n",
      "[ep203] episode_rewards for agent 6 : -18.783999195322394\n",
      "[ep203] episode_rewards for agent 7 : -57.93999661691487\n",
      "[ep203] episode_rewards for agent 8 : -49.52399734314531\n",
      "[ep203] episode_rewards for agent 9 : 8.187999224290252\n",
      "[ep203] mean episode reward : -7.574600041192025\n",
      "episode 204 done\n",
      "[ep204] episode_rewards for agent 0 : 114.99399266205728\n",
      "[ep204] episode_rewards for agent 1 : -53.54799697548151\n",
      "[ep204] episode_rewards for agent 2 : 50.231996710412204\n",
      "[ep204] episode_rewards for agent 3 : -27.883999071083963\n",
      "[ep204] episode_rewards for agent 4 : 40.883997175842524\n",
      "[ep204] episode_rewards for agent 5 : 81.71199437789619\n",
      "[ep204] episode_rewards for agent 6 : -17.455999764613807\n",
      "[ep204] episode_rewards for agent 7 : -42.49199796374887\n",
      "[ep204] episode_rewards for agent 8 : -42.07999801170081\n",
      "[ep204] episode_rewards for agent 9 : 61.691995981149375\n",
      "[ep204] mean episode reward : 16.60539851207286\n",
      "episode 205 done\n",
      "[ep205] episode_rewards for agent 0 : 29.27399766817689\n",
      "[ep205] episode_rewards for agent 1 : -55.619996757246554\n",
      "[ep205] episode_rewards for agent 2 : 40.883997010067105\n",
      "[ep205] episode_rewards for agent 3 : -16.472000336274505\n",
      "[ep205] episode_rewards for agent 4 : 51.35599645599723\n",
      "[ep205] episode_rewards for agent 5 : 140.5199911808595\n",
      "[ep205] episode_rewards for agent 6 : -43.73199770692736\n",
      "[ep205] episode_rewards for agent 7 : -56.42799676395953\n",
      "[ep205] episode_rewards for agent 8 : -50.37999733816832\n",
      "[ep205] episode_rewards for agent 9 : 26.39599802531302\n",
      "[ep205] mean episode reward : 6.579799143783748\n",
      "episode 206 done\n",
      "[ep206] episode_rewards for agent 0 : 68.75799523759633\n",
      "[ep206] episode_rewards for agent 1 : -55.67999679129571\n",
      "[ep206] episode_rewards for agent 2 : -7.419999674893916\n",
      "[ep206] episode_rewards for agent 3 : -18.240000249817967\n",
      "[ep206] episode_rewards for agent 4 : 29.243997677229345\n",
      "[ep206] episode_rewards for agent 5 : 34.547997403889894\n",
      "[ep206] episode_rewards for agent 6 : -32.23999832291156\n",
      "[ep206] episode_rewards for agent 7 : -50.77999728359282\n",
      "[ep206] episode_rewards for agent 8 : -52.959996931254864\n",
      "[ep206] episode_rewards for agent 9 : 13.551998857408762\n",
      "[ep206] mean episode reward : -7.12180000776425\n",
      "episode 207 done\n",
      "[ep207] episode_rewards for agent 0 : 80.53399468958378\n",
      "[ep207] episode_rewards for agent 1 : -57.11599665880203\n",
      "[ep207] episode_rewards for agent 2 : 19.755998597480357\n",
      "[ep207] episode_rewards for agent 3 : -49.595997386612\n",
      "[ep207] episode_rewards for agent 4 : 4.167999223805964\n",
      "[ep207] episode_rewards for agent 5 : -1.2840009909123182\n",
      "[ep207] episode_rewards for agent 6 : -28.91999885160476\n",
      "[ep207] episode_rewards for agent 7 : -42.79999798256904\n",
      "[ep207] episode_rewards for agent 8 : -51.14799724891782\n",
      "[ep207] episode_rewards for agent 9 : -8.020000023767352\n",
      "[ep207] mean episode reward : -13.442599663231523\n",
      "episode 208 done\n",
      "[ep208] episode_rewards for agent 0 : 96.68199375644326\n",
      "[ep208] episode_rewards for agent 1 : -53.39599694125354\n",
      "[ep208] episode_rewards for agent 2 : -41.48399771284312\n",
      "[ep208] episode_rewards for agent 3 : 20.207998023368418\n",
      "[ep208] episode_rewards for agent 4 : -1.8200002331286669\n",
      "[ep208] episode_rewards for agent 5 : 107.11999308038503\n",
      "[ep208] episode_rewards for agent 6 : 75.04399496782571\n",
      "[ep208] episode_rewards for agent 7 : -49.89199723675847\n",
      "[ep208] episode_rewards for agent 8 : -58.0719965742901\n",
      "[ep208] episode_rewards for agent 9 : 49.34399670455605\n",
      "[ep208] mean episode reward : 14.373398783430456\n",
      "episode 209 done\n",
      "[ep209] episode_rewards for agent 0 : 61.129995816387236\n",
      "[ep209] episode_rewards for agent 1 : -57.959996617399156\n",
      "[ep209] episode_rewards for agent 2 : 64.55599579680711\n",
      "[ep209] episode_rewards for agent 3 : -18.295999941416085\n",
      "[ep209] episode_rewards for agent 4 : 39.45199716556817\n",
      "[ep209] episode_rewards for agent 5 : 95.31999379117042\n",
      "[ep209] episode_rewards for agent 6 : -47.51599732693285\n",
      "[ep209] episode_rewards for agent 7 : -55.67199676763266\n",
      "[ep209] episode_rewards for agent 8 : -28.091999345459044\n",
      "[ep209] episode_rewards for agent 9 : 62.43199583981186\n",
      "[ep209] mean episode reward : 11.535398841090501\n",
      "episode 210 done\n",
      "[ep210] episode_rewards for agent 0 : 93.00599402282387\n",
      "[ep210] episode_rewards for agent 1 : -59.843996439129114\n",
      "[ep210] episode_rewards for agent 2 : 105.69999338500202\n",
      "[ep210] episode_rewards for agent 3 : -35.523998411372304\n",
      "[ep210] episode_rewards for agent 4 : 46.383996709249914\n",
      "[ep210] episode_rewards for agent 5 : 77.0559950042516\n",
      "[ep210] episode_rewards for agent 6 : -24.07199944462627\n",
      "[ep210] episode_rewards for agent 7 : -51.72399714309722\n",
      "[ep210] episode_rewards for agent 8 : -33.3399987379089\n",
      "[ep210] episode_rewards for agent 9 : 35.40399741008878\n",
      "[ep210] mean episode reward : 15.304598635528237\n",
      "episode 211 done\n",
      "[ep211] episode_rewards for agent 0 : 36.23799744527787\n",
      "[ep211] episode_rewards for agent 1 : -56.007996717467904\n",
      "[ep211] episode_rewards for agent 2 : 87.46799455955625\n",
      "[ep211] episode_rewards for agent 3 : -30.307999123819172\n",
      "[ep211] episode_rewards for agent 4 : 60.45999592449516\n",
      "[ep211] episode_rewards for agent 5 : 113.00399291608483\n",
      "[ep211] episode_rewards for agent 6 : -18.25199951697141\n",
      "[ep211] episode_rewards for agent 7 : -52.01999716646969\n",
      "[ep211] episode_rewards for agent 8 : -40.6199982073158\n",
      "[ep211] episode_rewards for agent 9 : 32.523997721262276\n",
      "[ep211] mean episode reward : 13.24859878346324\n",
      "episode 212 done\n",
      "[ep212] episode_rewards for agent 0 : 142.69799105171114\n",
      "[ep212] episode_rewards for agent 1 : -56.891996720805764\n",
      "[ep212] episode_rewards for agent 2 : -58.21199659164995\n",
      "[ep212] episode_rewards for agent 3 : -27.795999360270798\n",
      "[ep212] episode_rewards for agent 4 : 70.15999523270875\n",
      "[ep212] episode_rewards for agent 5 : 57.88399623055011\n",
      "[ep212] episode_rewards for agent 6 : -34.37999839056283\n",
      "[ep212] episode_rewards for agent 7 : -49.59999737609178\n",
      "[ep212] episode_rewards for agent 8 : -53.399996996857226\n",
      "[ep212] episode_rewards for agent 9 : 71.9279952980578\n",
      "[ep212] mean episode reward : 6.238999237678945\n",
      "episode 213 done\n",
      "[ep213] episode_rewards for agent 0 : 64.30599551834166\n",
      "[ep213] episode_rewards for agent 1 : -55.799996780231595\n",
      "[ep213] episode_rewards for agent 2 : -58.89999652188271\n",
      "[ep213] episode_rewards for agent 3 : -41.71999809052795\n",
      "[ep213] episode_rewards for agent 4 : 21.759998357854784\n",
      "[ep213] episode_rewards for agent 5 : 99.99199344497174\n",
      "[ep213] episode_rewards for agent 6 : -13.9479994578287\n",
      "[ep213] episode_rewards for agent 7 : -17.815999954007566\n",
      "[ep213] episode_rewards for agent 8 : -29.80399911850691\n",
      "[ep213] episode_rewards for agent 9 : 109.05599303450435\n",
      "[ep213] mean episode reward : 7.71259904326871\n",
      "episode 214 done\n",
      "[ep214] episode_rewards for agent 0 : 38.41799722891301\n",
      "[ep214] episode_rewards for agent 1 : -52.83999699447304\n",
      "[ep214] episode_rewards for agent 2 : 83.29599458258599\n",
      "[ep214] episode_rewards for agent 3 : -26.439999508671463\n",
      "[ep214] episode_rewards for agent 4 : -1.6000005220994353\n",
      "[ep214] episode_rewards for agent 5 : 49.18799639400095\n",
      "[ep214] episode_rewards for agent 6 : -0.5160008259117603\n",
      "[ep214] episode_rewards for agent 7 : -56.435996760614216\n",
      "[ep214] episode_rewards for agent 8 : -52.05599707644433\n",
      "[ep214] episode_rewards for agent 9 : 13.99199853464961\n",
      "[ep214] mean episode reward : -0.4994004948064685\n",
      "episode 215 done\n",
      "[ep215] episode_rewards for agent 0 : 85.24599440675229\n",
      "[ep215] episode_rewards for agent 1 : -59.01999649219215\n",
      "[ep215] episode_rewards for agent 2 : 17.579998669214547\n",
      "[ep215] episode_rewards for agent 3 : -28.807999283075333\n",
      "[ep215] episode_rewards for agent 4 : 69.01999544166028\n",
      "[ep215] episode_rewards for agent 5 : 46.42399660125375\n",
      "[ep215] episode_rewards for agent 6 : -1.8920003725215793\n",
      "[ep215] episode_rewards for agent 7 : -34.71199873927981\n",
      "[ep215] episode_rewards for agent 8 : -51.551997064612806\n",
      "[ep215] episode_rewards for agent 9 : 25.467998013831675\n",
      "[ep215] mean episode reward : 6.775399118103087\n",
      "episode 216 done\n",
      "[ep216] episode_rewards for agent 0 : 61.48599590267986\n",
      "[ep216] episode_rewards for agent 1 : -58.25199659075588\n",
      "[ep216] episode_rewards for agent 2 : 5.7839992279186845\n",
      "[ep216] episode_rewards for agent 3 : -8.452000624500215\n",
      "[ep216] episode_rewards for agent 4 : 42.80399682652205\n",
      "[ep216] episode_rewards for agent 5 : 131.43199170473963\n",
      "[ep216] episode_rewards for agent 6 : -30.203998871147633\n",
      "[ep216] episode_rewards for agent 7 : -25.70799900405109\n",
      "[ep216] episode_rewards for agent 8 : -48.40799737628549\n",
      "[ep216] episode_rewards for agent 9 : 59.79999597556889\n",
      "[ep216] mean episode reward : 13.02819871706888\n",
      "episode 217 done\n",
      "[ep217] episode_rewards for agent 0 : 82.77399468235672\n",
      "[ep217] episode_rewards for agent 1 : -53.70399692840874\n",
      "[ep217] episode_rewards for agent 2 : 2.039999695494771\n",
      "[ep217] episode_rewards for agent 3 : -2.46400083322078\n",
      "[ep217] episode_rewards for agent 4 : 40.807997084222734\n",
      "[ep217] episode_rewards for agent 5 : 27.175997717306018\n",
      "[ep217] episode_rewards for agent 6 : 5.251999210566282\n",
      "[ep217] episode_rewards for agent 7 : -56.48399677313864\n",
      "[ep217] episode_rewards for agent 8 : -54.31199687998742\n",
      "[ep217] episode_rewards for agent 9 : 61.031995992176235\n",
      "[ep217] mean episode reward : 5.211799296736717\n",
      "episode 218 done\n",
      "[ep218] episode_rewards for agent 0 : 63.06199571304023\n",
      "[ep218] episode_rewards for agent 1 : -57.271996651776135\n",
      "[ep218] episode_rewards for agent 2 : 41.42799720261246\n",
      "[ep218] episode_rewards for agent 3 : -44.44399785064161\n",
      "[ep218] episode_rewards for agent 4 : 82.02399450633675\n",
      "[ep218] episode_rewards for agent 5 : 30.971997688524425\n",
      "[ep218] episode_rewards for agent 6 : -17.395999799482524\n",
      "[ep218] episode_rewards for agent 7 : -39.731997908093035\n",
      "[ep218] episode_rewards for agent 8 : -35.38799845986068\n",
      "[ep218] episode_rewards for agent 9 : -14.211999383755028\n",
      "[ep218] mean episode reward : 0.9041995056904852\n",
      "episode 219 done\n",
      "[ep219] episode_rewards for agent 0 : 84.55399444699287\n",
      "[ep219] episode_rewards for agent 1 : -54.30399682931602\n",
      "[ep219] episode_rewards for agent 2 : 94.63199411146343\n",
      "[ep219] episode_rewards for agent 3 : -14.94799979776144\n",
      "[ep219] episode_rewards for agent 4 : 52.219996395520866\n",
      "[ep219] episode_rewards for agent 5 : 102.81199347693473\n",
      "[ep219] episode_rewards for agent 6 : -17.367999880574644\n",
      "[ep219] episode_rewards for agent 7 : -29.515999285504222\n",
      "[ep219] episode_rewards for agent 8 : -23.655999393202364\n",
      "[ep219] episode_rewards for agent 9 : 41.16799707245082\n",
      "[ep219] mean episode reward : 23.559398031700404\n",
      "episode 220 done\n",
      "[ep220] episode_rewards for agent 0 : 26.80199788324535\n",
      "[ep220] episode_rewards for agent 1 : -54.15599690377712\n",
      "[ep220] episode_rewards for agent 2 : -53.24799704924226\n",
      "[ep220] episode_rewards for agent 3 : -22.123999872244895\n",
      "[ep220] episode_rewards for agent 4 : 40.58399677835405\n",
      "[ep220] episode_rewards for agent 5 : 126.05599192995578\n",
      "[ep220] episode_rewards for agent 6 : -43.771997682750225\n",
      "[ep220] episode_rewards for agent 7 : -33.787998522631824\n",
      "[ep220] episode_rewards for agent 8 : -44.983997819945216\n",
      "[ep220] episode_rewards for agent 9 : 94.47999376431108\n",
      "[ep220] mean episode reward : 3.5849992505274715\n",
      "episode 221 done\n",
      "[ep221] episode_rewards for agent 0 : 40.06199712213129\n",
      "[ep221] episode_rewards for agent 1 : -52.439997006207705\n",
      "[ep221] episode_rewards for agent 2 : 15.955998848192394\n",
      "[ep221] episode_rewards for agent 3 : -13.676000136882067\n",
      "[ep221] episode_rewards for agent 4 : -30.823998630978167\n",
      "[ep221] episode_rewards for agent 5 : 37.00399711821228\n",
      "[ep221] episode_rewards for agent 6 : -4.860000782646239\n",
      "[ep221] episode_rewards for agent 7 : -48.351997435092926\n",
      "[ep221] episode_rewards for agent 8 : -36.66799858212471\n",
      "[ep221] episode_rewards for agent 9 : 2.5759995160624385\n",
      "[ep221] mean episode reward : -9.122199996933341\n",
      "episode 222 done\n",
      "[ep222] episode_rewards for agent 0 : 47.677996513433754\n",
      "[ep222] episode_rewards for agent 1 : -57.82799663487822\n",
      "[ep222] episode_rewards for agent 2 : 13.971998762339354\n",
      "[ep222] episode_rewards for agent 3 : -22.387999051250517\n",
      "[ep222] episode_rewards for agent 4 : 71.35599529277533\n",
      "[ep222] episode_rewards for agent 5 : -3.5000009052455425\n",
      "[ep222] episode_rewards for agent 6 : -10.204000100493431\n",
      "[ep222] episode_rewards for agent 7 : -33.83999883662909\n",
      "[ep222] episode_rewards for agent 8 : -49.27599735930562\n",
      "[ep222] episode_rewards for agent 9 : 58.011996067129076\n",
      "[ep222] mean episode reward : 1.3981993747875094\n",
      "episode 223 done\n",
      "[ep223] episode_rewards for agent 0 : -13.357999659143388\n",
      "[ep223] episode_rewards for agent 1 : -51.003997140564024\n",
      "[ep223] episode_rewards for agent 2 : -29.191998437047005\n",
      "[ep223] episode_rewards for agent 3 : -34.03599869366735\n",
      "[ep223] episode_rewards for agent 4 : 68.05199534725398\n",
      "[ep223] episode_rewards for agent 5 : 124.59199208766222\n",
      "[ep223] episode_rewards for agent 6 : -8.884000204503536\n",
      "[ep223] episode_rewards for agent 7 : -58.131996602751315\n",
      "[ep223] episode_rewards for agent 8 : -48.37599750049412\n",
      "[ep223] episode_rewards for agent 9 : 53.135996382683516\n",
      "[ep223] mean episode reward : 0.27979955794289707\n",
      "episode 224 done\n",
      "[ep224] episode_rewards for agent 0 : 37.03399720415473\n",
      "[ep224] episode_rewards for agent 1 : -59.20399649720639\n",
      "[ep224] episode_rewards for agent 2 : 65.71999569609761\n",
      "[ep224] episode_rewards for agent 3 : -20.495999248698354\n",
      "[ep224] episode_rewards for agent 4 : 65.78799546230584\n",
      "[ep224] episode_rewards for agent 5 : 93.5119937164709\n",
      "[ep224] episode_rewards for agent 6 : -24.067999207414687\n",
      "[ep224] episode_rewards for agent 7 : -55.74799674935639\n",
      "[ep224] episode_rewards for agent 8 : -30.1079987809062\n",
      "[ep224] episode_rewards for agent 9 : -1.0400003707036376\n",
      "[ep224] mean episode reward : 7.138999122474343\n",
      "episode 225 done\n",
      "[ep225] episode_rewards for agent 0 : 15.465998521074653\n",
      "[ep225] episode_rewards for agent 1 : -55.387996807694435\n",
      "[ep225] episode_rewards for agent 2 : -44.59199783578515\n",
      "[ep225] episode_rewards for agent 3 : -34.07999877631664\n",
      "[ep225] episode_rewards for agent 4 : 4.931999213062227\n",
      "[ep225] episode_rewards for agent 5 : 140.61999105941504\n",
      "[ep225] episode_rewards for agent 6 : -26.123998844064772\n",
      "[ep225] episode_rewards for agent 7 : -35.267998720519245\n",
      "[ep225] episode_rewards for agent 8 : -42.163997870869935\n",
      "[ep225] episode_rewards for agent 9 : 7.943999046459794\n",
      "[ep225] mean episode reward : -6.865400101523846\n",
      "episode 226 done\n",
      "[ep226] episode_rewards for agent 0 : 19.73799811862409\n",
      "[ep226] episode_rewards for agent 1 : -55.75599678885192\n",
      "[ep226] episode_rewards for agent 2 : -0.252000343054533\n",
      "[ep226] episode_rewards for agent 3 : -16.524000390432775\n",
      "[ep226] episode_rewards for agent 4 : 12.51999872829765\n",
      "[ep226] episode_rewards for agent 5 : 33.94799742195755\n",
      "[ep226] episode_rewards for agent 6 : -18.223999908193946\n",
      "[ep226] episode_rewards for agent 7 : -34.243998737074435\n",
      "[ep226] episode_rewards for agent 8 : -48.95199735276401\n",
      "[ep226] episode_rewards for agent 9 : 8.835999017581344\n",
      "[ep226] mean episode reward : -9.891000023391097\n",
      "episode 227 done\n",
      "[ep227] episode_rewards for agent 0 : 74.40199503488839\n",
      "[ep227] episode_rewards for agent 1 : -56.223996710032225\n",
      "[ep227] episode_rewards for agent 2 : -30.931998318061233\n",
      "[ep227] episode_rewards for agent 3 : -36.875998582690954\n",
      "[ep227] episode_rewards for agent 4 : 7.82399882003665\n",
      "[ep227] episode_rewards for agent 5 : 50.527996418997645\n",
      "[ep227] episode_rewards for agent 6 : -55.94799680169672\n",
      "[ep227] episode_rewards for agent 7 : -27.199999425560236\n",
      "[ep227] episode_rewards for agent 8 : -48.56799734290689\n",
      "[ep227] episode_rewards for agent 9 : -20.003999314270914\n",
      "[ep227] mean episode reward : -14.29979962212965\n",
      "episode 228 done\n",
      "[ep228] episode_rewards for agent 0 : -27.521998582407832\n",
      "[ep228] episode_rewards for agent 1 : -48.73999742884189\n",
      "[ep228] episode_rewards for agent 2 : 29.567997816950083\n",
      "[ep228] episode_rewards for agent 3 : -42.299997847527266\n",
      "[ep228] episode_rewards for agent 4 : -2.1560002053156495\n",
      "[ep228] episode_rewards for agent 5 : 110.21599290985614\n",
      "[ep228] episode_rewards for agent 6 : -16.915999651886523\n",
      "[ep228] episode_rewards for agent 7 : -35.467998585663736\n",
      "[ep228] episode_rewards for agent 8 : -53.771996966563165\n",
      "[ep228] episode_rewards for agent 9 : 32.00399754848331\n",
      "[ep228] mean episode reward : -5.508600099291653\n",
      "episode 229 done\n",
      "[ep229] episode_rewards for agent 0 : 40.63799698650837\n",
      "[ep229] episode_rewards for agent 1 : -54.0999968405813\n",
      "[ep229] episode_rewards for agent 2 : -2.252000174485147\n",
      "[ep229] episode_rewards for agent 3 : -33.87999879010022\n",
      "[ep229] episode_rewards for agent 4 : 43.15199713502079\n",
      "[ep229] episode_rewards for agent 5 : 56.555995965376496\n",
      "[ep229] episode_rewards for agent 6 : -13.488000078126788\n",
      "[ep229] episode_rewards for agent 7 : -55.931996788829565\n",
      "[ep229] episode_rewards for agent 8 : -34.23599863611162\n",
      "[ep229] episode_rewards for agent 9 : 47.74399662204087\n",
      "[ep229] mean episode reward : -0.5798004599288106\n",
      "episode 230 done\n",
      "[ep230] episode_rewards for agent 0 : 19.325998130254447\n",
      "[ep230] episode_rewards for agent 1 : -49.935997164808214\n",
      "[ep230] episode_rewards for agent 2 : -11.839999527670443\n",
      "[ep230] episode_rewards for agent 3 : -19.999999438412488\n",
      "[ep230] episode_rewards for agent 4 : 8.9039994077757\n",
      "[ep230] episode_rewards for agent 5 : 78.13199490122497\n",
      "[ep230] episode_rewards for agent 6 : -7.604000243358314\n",
      "[ep230] episode_rewards for agent 7 : -27.07999941520393\n",
      "[ep230] episode_rewards for agent 8 : -51.9079971909523\n",
      "[ep230] episode_rewards for agent 9 : 117.83199256006628\n",
      "[ep230] mean episode reward : 5.582599201891571\n",
      "episode 231 done\n",
      "[ep231] episode_rewards for agent 0 : 79.96999458223581\n",
      "[ep231] episode_rewards for agent 1 : -56.27199675887823\n",
      "[ep231] episode_rewards for agent 2 : -9.575999500229955\n",
      "[ep231] episode_rewards for agent 3 : -26.10799941048026\n",
      "[ep231] episode_rewards for agent 4 : 79.70799474231899\n",
      "[ep231] episode_rewards for agent 5 : 55.3799961861223\n",
      "[ep231] episode_rewards for agent 6 : 19.647997841238976\n",
      "[ep231] episode_rewards for agent 7 : -49.7559973699972\n",
      "[ep231] episode_rewards for agent 8 : -49.9079973725602\n",
      "[ep231] episode_rewards for agent 9 : 14.51999884750694\n",
      "[ep231] mean episode reward : 5.760599178727716\n",
      "episode 232 done\n",
      "[ep232] episode_rewards for agent 0 : 82.88199465535581\n",
      "[ep232] episode_rewards for agent 1 : -55.479996803216636\n",
      "[ep232] episode_rewards for agent 2 : -46.303997312672436\n",
      "[ep232] episode_rewards for agent 3 : -21.120000023394823\n",
      "[ep232] episode_rewards for agent 4 : 90.63199420738965\n",
      "[ep232] episode_rewards for agent 5 : 102.46799346245825\n",
      "[ep232] episode_rewards for agent 6 : -13.155999808572233\n",
      "[ep232] episode_rewards for agent 7 : -50.84799701254815\n",
      "[ep232] episode_rewards for agent 8 : -22.76799970585853\n",
      "[ep232] episode_rewards for agent 9 : 40.547996923327446\n",
      "[ep232] mean episode reward : 10.685398858226836\n",
      "episode 233 done\n",
      "[ep233] episode_rewards for agent 0 : 59.485995745286345\n",
      "[ep233] episode_rewards for agent 1 : -55.515996797941625\n",
      "[ep233] episode_rewards for agent 2 : 52.91999642085284\n",
      "[ep233] episode_rewards for agent 3 : -22.35599928162992\n",
      "[ep233] episode_rewards for agent 4 : 44.12399684265256\n",
      "[ep233] episode_rewards for agent 5 : 26.74799770116806\n",
      "[ep233] episode_rewards for agent 6 : -12.211999891325831\n",
      "[ep233] episode_rewards for agent 7 : -46.027997649274766\n",
      "[ep233] episode_rewards for agent 8 : -46.979997554793954\n",
      "[ep233] episode_rewards for agent 9 : 48.19199662283063\n",
      "[ep233] mean episode reward : 4.837799215782434\n",
      "episode 234 done\n",
      "[ep234] episode_rewards for agent 0 : 75.01799498591572\n",
      "[ep234] episode_rewards for agent 1 : -50.52399708237499\n",
      "[ep234] episode_rewards for agent 2 : -10.83199973218143\n",
      "[ep234] episode_rewards for agent 3 : -28.603999053128064\n",
      "[ep234] episode_rewards for agent 4 : 82.5559946782887\n",
      "[ep234] episode_rewards for agent 5 : 110.49599286261946\n",
      "[ep234] episode_rewards for agent 6 : -22.06399923749268\n",
      "[ep234] episode_rewards for agent 7 : -37.4199981726706\n",
      "[ep234] episode_rewards for agent 8 : -31.467998730018735\n",
      "[ep234] episode_rewards for agent 9 : 47.32799678109586\n",
      "[ep234] mean episode reward : 13.448598730005324\n",
      "episode 235 done\n",
      "[ep235] episode_rewards for agent 0 : 58.937995865009725\n",
      "[ep235] episode_rewards for agent 1 : -58.19199656136334\n",
      "[ep235] episode_rewards for agent 2 : 16.383998854085803\n",
      "[ep235] episode_rewards for agent 3 : -8.32800033967942\n",
      "[ep235] episode_rewards for agent 4 : 40.367996994405985\n",
      "[ep235] episode_rewards for agent 5 : 38.171997014433146\n",
      "[ep235] episode_rewards for agent 6 : -20.68799937237054\n",
      "[ep235] episode_rewards for agent 7 : -50.90799720771611\n",
      "[ep235] episode_rewards for agent 8 : -42.69199784845114\n",
      "[ep235] episode_rewards for agent 9 : 47.315996868535876\n",
      "[ep235] mean episode reward : 2.036999426688999\n",
      "episode 236 done\n",
      "[ep236] episode_rewards for agent 0 : 33.06999753694981\n",
      "[ep236] episode_rewards for agent 1 : -51.62399715464562\n",
      "[ep236] episode_rewards for agent 2 : 88.22799439355731\n",
      "[ep236] episode_rewards for agent 3 : -15.196000127121806\n",
      "[ep236] episode_rewards for agent 4 : -18.27599946130067\n",
      "[ep236] episode_rewards for agent 5 : 46.25599670782685\n",
      "[ep236] episode_rewards for agent 6 : 3.627999051474035\n",
      "[ep236] episode_rewards for agent 7 : -22.919998997822404\n",
      "[ep236] episode_rewards for agent 8 : -39.67199824284762\n",
      "[ep236] episode_rewards for agent 9 : -21.41199914366007\n",
      "[ep236] mean episode reward : 0.20819945624098182\n",
      "episode 237 done\n",
      "[ep237] episode_rewards for agent 0 : 64.35799556970596\n",
      "[ep237] episode_rewards for agent 1 : -58.55599653720856\n",
      "[ep237] episode_rewards for agent 2 : 17.43999827746302\n",
      "[ep237] episode_rewards for agent 3 : -23.467999398708344\n",
      "[ep237] episode_rewards for agent 4 : 48.931996514089406\n",
      "[ep237] episode_rewards for agent 5 : 43.73599669057876\n",
      "[ep237] episode_rewards for agent 6 : -10.216000044718385\n",
      "[ep237] episode_rewards for agent 7 : -43.89999789651483\n",
      "[ep237] episode_rewards for agent 8 : -36.91599845793098\n",
      "[ep237] episode_rewards for agent 9 : 93.14399384427816\n",
      "[ep237] mean episode reward : 9.45539885610342\n",
      "episode 238 done\n",
      "[ep238] episode_rewards for agent 0 : 47.86999666783959\n",
      "[ep238] episode_rewards for agent 1 : -52.09199694637209\n",
      "[ep238] episode_rewards for agent 2 : -33.26799823809415\n",
      "[ep238] episode_rewards for agent 3 : -39.04799835011363\n",
      "[ep238] episode_rewards for agent 4 : 66.72399574425071\n",
      "[ep238] episode_rewards for agent 5 : 80.39599458221346\n",
      "[ep238] episode_rewards for agent 6 : -23.683999166823924\n",
      "[ep238] episode_rewards for agent 7 : -27.339999003335834\n",
      "[ep238] episode_rewards for agent 8 : -40.17199824843556\n",
      "[ep238] episode_rewards for agent 9 : -6.059999933466315\n",
      "[ep238] mean episode reward : -2.667400289233774\n",
      "episode 239 done\n",
      "[ep239] episode_rewards for agent 0 : 62.52999596763402\n",
      "[ep239] episode_rewards for agent 1 : -57.76799659244716\n",
      "[ep239] episode_rewards for agent 2 : -5.147999929264188\n",
      "[ep239] episode_rewards for agent 3 : -19.13600022532046\n",
      "[ep239] episode_rewards for agent 4 : 65.56799550447613\n",
      "[ep239] episode_rewards for agent 5 : 69.94399508833885\n",
      "[ep239] episode_rewards for agent 6 : -27.075998773798347\n",
      "[ep239] episode_rewards for agent 7 : -24.24399974104017\n",
      "[ep239] episode_rewards for agent 8 : -51.67999719735235\n",
      "[ep239] episode_rewards for agent 9 : 36.58399723935872\n",
      "[ep239] mean episode reward : 4.957399134058505\n",
      "episode 240 done\n",
      "[ep240] episode_rewards for agent 0 : 16.529998469166458\n",
      "[ep240] episode_rewards for agent 1 : -56.515996747650206\n",
      "[ep240] episode_rewards for agent 2 : -50.10399708058685\n",
      "[ep240] episode_rewards for agent 3 : -30.407998777925968\n",
      "[ep240] episode_rewards for agent 4 : 27.459997659549117\n",
      "[ep240] episode_rewards for agent 5 : 52.32399622537196\n",
      "[ep240] episode_rewards for agent 6 : -28.79199903085828\n",
      "[ep240] episode_rewards for agent 7 : -48.12399753462523\n",
      "[ep240] episode_rewards for agent 8 : -36.983998517505825\n",
      "[ep240] episode_rewards for agent 9 : 65.0399956246838\n",
      "[ep240] mean episode reward : -8.957399971038104\n",
      "episode 241 done\n",
      "[ep241] episode_rewards for agent 0 : 40.76199702452868\n",
      "[ep241] episode_rewards for agent 1 : -48.347997264936566\n",
      "[ep241] episode_rewards for agent 2 : -43.71199769247323\n",
      "[ep241] episode_rewards for agent 3 : -28.02399903163314\n",
      "[ep241] episode_rewards for agent 4 : 8.29599904641509\n",
      "[ep241] episode_rewards for agent 5 : 93.83599366154522\n",
      "[ep241] episode_rewards for agent 6 : -28.823998810723424\n",
      "[ep241] episode_rewards for agent 7 : -44.20799786131829\n",
      "[ep241] episode_rewards for agent 8 : -45.18399776984006\n",
      "[ep241] episode_rewards for agent 9 : 20.04799823369831\n",
      "[ep241] mean episode reward : -7.535800046473741\n",
      "episode 242 done\n",
      "[ep242] episode_rewards for agent 0 : 54.32199616264552\n",
      "[ep242] episode_rewards for agent 1 : -58.44399656821042\n",
      "[ep242] episode_rewards for agent 2 : 79.49199478607625\n",
      "[ep242] episode_rewards for agent 3 : -52.62399712949991\n",
      "[ep242] episode_rewards for agent 4 : 42.4839971261099\n",
      "[ep242] episode_rewards for agent 5 : 96.73599372152239\n",
      "[ep242] episode_rewards for agent 6 : -26.55199930537492\n",
      "[ep242] episode_rewards for agent 7 : -45.29599777329713\n",
      "[ep242] episode_rewards for agent 8 : -34.027998828329146\n",
      "[ep242] episode_rewards for agent 9 : 66.33999549224973\n",
      "[ep242] mean episode reward : 12.242998768389224\n",
      "episode 243 done\n",
      "[ep243] episode_rewards for agent 0 : 23.597997983917594\n",
      "[ep243] episode_rewards for agent 1 : -56.339996746741235\n",
      "[ep243] episode_rewards for agent 2 : 71.8839951986447\n",
      "[ep243] episode_rewards for agent 3 : -34.803998636081815\n",
      "[ep243] episode_rewards for agent 4 : 56.54799625650048\n",
      "[ep243] episode_rewards for agent 5 : 101.75199347175658\n",
      "[ep243] episode_rewards for agent 6 : -31.711998669430614\n",
      "[ep243] episode_rewards for agent 7 : -39.50799815636128\n",
      "[ep243] episode_rewards for agent 8 : -49.86399730015546\n",
      "[ep243] episode_rewards for agent 9 : 34.95199746545404\n",
      "[ep243] mean episode reward : 7.650599086750299\n",
      "episode 244 done\n",
      "[ep244] episode_rewards for agent 0 : 93.47799402847886\n",
      "[ep244] episode_rewards for agent 1 : -57.739996646530926\n",
      "[ep244] episode_rewards for agent 2 : 22.287998378276825\n",
      "[ep244] episode_rewards for agent 3 : -31.019999117590487\n",
      "[ep244] episode_rewards for agent 4 : 10.923999240621924\n",
      "[ep244] episode_rewards for agent 5 : 86.33199435845017\n",
      "[ep244] episode_rewards for agent 6 : -24.95999898482114\n",
      "[ep244] episode_rewards for agent 7 : -54.57199688907713\n",
      "[ep244] episode_rewards for agent 8 : -42.287998034618795\n",
      "[ep244] episode_rewards for agent 9 : 8.983999377116561\n",
      "[ep244] mean episode reward : 1.142599571030587\n",
      "episode 245 done\n",
      "[ep245] episode_rewards for agent 0 : 41.37399704940617\n",
      "[ep245] episode_rewards for agent 1 : -51.1599971242249\n",
      "[ep245] episode_rewards for agent 2 : 9.339999006129801\n",
      "[ep245] episode_rewards for agent 3 : -18.651999536901712\n",
      "[ep245] episode_rewards for agent 4 : -53.027996975928545\n",
      "[ep245] episode_rewards for agent 5 : 8.155998973175883\n",
      "[ep245] episode_rewards for agent 6 : -22.7279995046556\n",
      "[ep245] episode_rewards for agent 7 : -30.883999111130834\n",
      "[ep245] episode_rewards for agent 8 : -38.75199835281819\n",
      "[ep245] episode_rewards for agent 9 : 20.64799818303436\n",
      "[ep245] mean episode reward : -13.568599739391356\n",
      "episode 246 done\n",
      "[ep246] episode_rewards for agent 0 : 117.02599248662591\n",
      "[ep246] episode_rewards for agent 1 : -56.67999673075974\n",
      "[ep246] episode_rewards for agent 2 : -29.899998605251312\n",
      "[ep246] episode_rewards for agent 3 : -45.87599750235677\n",
      "[ep246] episode_rewards for agent 4 : 85.58399434480816\n",
      "[ep246] episode_rewards for agent 5 : 49.02799633331597\n",
      "[ep246] episode_rewards for agent 6 : -30.843998877331614\n",
      "[ep246] episode_rewards for agent 7 : -34.423998691141605\n",
      "[ep246] episode_rewards for agent 8 : -23.859999735839665\n",
      "[ep246] episode_rewards for agent 9 : 51.507996536791325\n",
      "[ep246] mean episode reward : 8.156198955886065\n",
      "episode 247 done\n",
      "[ep247] episode_rewards for agent 0 : 52.033996472135186\n",
      "[ep247] episode_rewards for agent 1 : -52.707996980287135\n",
      "[ep247] episode_rewards for agent 2 : 45.91599703673273\n",
      "[ep247] episode_rewards for agent 3 : -40.563997835852206\n",
      "[ep247] episode_rewards for agent 4 : 74.16399516630918\n",
      "[ep247] episode_rewards for agent 5 : 73.16799507848918\n",
      "[ep247] episode_rewards for agent 6 : 11.50399861484766\n",
      "[ep247] episode_rewards for agent 7 : -28.095998871140182\n",
      "[ep247] episode_rewards for agent 8 : -28.675999131053686\n",
      "[ep247] episode_rewards for agent 9 : 47.82799677923322\n",
      "[ep247] mean episode reward : 15.456998632941396\n",
      "episode 248 done\n",
      "[ep248] episode_rewards for agent 0 : 79.38999483827502\n",
      "[ep248] episode_rewards for agent 1 : -55.71999682392925\n",
      "[ep248] episode_rewards for agent 2 : -22.391998814418912\n",
      "[ep248] episode_rewards for agent 3 : -22.499999698251486\n",
      "[ep248] episode_rewards for agent 4 : 61.71599562745541\n",
      "[ep248] episode_rewards for agent 5 : 66.34399570524693\n",
      "[ep248] episode_rewards for agent 6 : -4.644000295549631\n",
      "[ep248] episode_rewards for agent 7 : -47.259997610002756\n",
      "[ep248] episode_rewards for agent 8 : -32.50799894798547\n",
      "[ep248] episode_rewards for agent 9 : 84.3959946911782\n",
      "[ep248] mean episode reward : 10.682198867201805\n",
      "episode 249 done\n",
      "[ep249] episode_rewards for agent 0 : 15.321998602710664\n",
      "[ep249] episode_rewards for agent 1 : -57.87599657010287\n",
      "[ep249] episode_rewards for agent 2 : -39.235997893847525\n",
      "[ep249] episode_rewards for agent 3 : -22.755999885499477\n",
      "[ep249] episode_rewards for agent 4 : 14.891998733393848\n",
      "[ep249] episode_rewards for agent 5 : 86.7279942324385\n",
      "[ep249] episode_rewards for agent 6 : -4.00800025369972\n",
      "[ep249] episode_rewards for agent 7 : -22.555999948643148\n",
      "[ep249] episode_rewards for agent 8 : -31.779998920857906\n",
      "[ep249] episode_rewards for agent 9 : 29.979997707530856\n",
      "[ep249] mean episode reward : -3.1290004196576775\n",
      "episode 250 done\n",
      "[ep250] episode_rewards for agent 0 : 55.4859962342307\n",
      "[ep250] episode_rewards for agent 1 : -55.31999681144953\n",
      "[ep250] episode_rewards for agent 2 : -54.88399692252278\n",
      "[ep250] episode_rewards for agent 3 : -30.251999179832637\n",
      "[ep250] episode_rewards for agent 4 : 55.73199608549476\n",
      "[ep250] episode_rewards for agent 5 : 44.40799653995782\n",
      "[ep250] episode_rewards for agent 6 : -34.947998451069\n",
      "[ep250] episode_rewards for agent 7 : -52.02399715408683\n",
      "[ep250] episode_rewards for agent 8 : -36.519998415373266\n",
      "[ep250] episode_rewards for agent 9 : 90.06399423722178\n",
      "[ep250] mean episode reward : -1.8258003837428987\n",
      "episode 251 done\n",
      "[ep251] episode_rewards for agent 0 : 17.11399854812771\n",
      "[ep251] episode_rewards for agent 1 : -56.86399665568024\n",
      "[ep251] episode_rewards for agent 2 : -52.363997160457075\n",
      "[ep251] episode_rewards for agent 3 : -44.5999977812171\n",
      "[ep251] episode_rewards for agent 4 : 38.76799731422216\n",
      "[ep251] episode_rewards for agent 5 : 74.75999502185732\n",
      "[ep251] episode_rewards for agent 6 : -8.004000436514616\n",
      "[ep251] episode_rewards for agent 7 : -32.33199894614518\n",
      "[ep251] episode_rewards for agent 8 : -36.115998207591474\n",
      "[ep251] episode_rewards for agent 9 : 15.991998441517353\n",
      "[ep251] mean episode reward : -8.364599986188114\n",
      "episode 252 done\n",
      "[ep252] episode_rewards for agent 0 : 13.577998655848205\n",
      "[ep252] episode_rewards for agent 1 : -54.91999682132155\n",
      "[ep252] episode_rewards for agent 2 : -34.4159983061254\n",
      "[ep252] episode_rewards for agent 3 : -25.147999549284577\n",
      "[ep252] episode_rewards for agent 4 : 41.135996755212545\n",
      "[ep252] episode_rewards for agent 5 : 53.739996205084026\n",
      "[ep252] episode_rewards for agent 6 : -30.511998910456896\n",
      "[ep252] episode_rewards for agent 7 : -38.2159984158352\n",
      "[ep252] episode_rewards for agent 8 : -57.20799669530243\n",
      "[ep252] episode_rewards for agent 9 : 16.88399845547974\n",
      "[ep252] mean episode reward : -11.508199862670153\n",
      "episode 253 done\n",
      "[ep253] episode_rewards for agent 0 : 120.38999240007252\n",
      "[ep253] episode_rewards for agent 1 : -58.095996553078294\n",
      "[ep253] episode_rewards for agent 2 : -38.583997862413526\n",
      "[ep253] episode_rewards for agent 3 : -23.25999949965626\n",
      "[ep253] episode_rewards for agent 4 : 19.823998336680233\n",
      "[ep253] episode_rewards for agent 5 : 54.35599619988352\n",
      "[ep253] episode_rewards for agent 6 : -28.25199877936393\n",
      "[ep253] episode_rewards for agent 7 : -37.91199836321175\n",
      "[ep253] episode_rewards for agent 8 : -39.69199831597507\n",
      "[ep253] episode_rewards for agent 9 : 22.93599823117256\n",
      "[ep253] mean episode reward : -0.829000420589\n",
      "episode 254 done\n",
      "[ep254] episode_rewards for agent 0 : 130.65399179141968\n",
      "[ep254] episode_rewards for agent 1 : -45.15199770312756\n",
      "[ep254] episode_rewards for agent 2 : -45.9719973243773\n",
      "[ep254] episode_rewards for agent 3 : -22.45599934179336\n",
      "[ep254] episode_rewards for agent 4 : 15.395998617634177\n",
      "[ep254] episode_rewards for agent 5 : 92.9039938794449\n",
      "[ep254] episode_rewards for agent 6 : 23.11199767049402\n",
      "[ep254] episode_rewards for agent 7 : -36.40399808809161\n",
      "[ep254] episode_rewards for agent 8 : -42.95999791100621\n",
      "[ep254] episode_rewards for agent 9 : 90.59199418779463\n",
      "[ep254] mean episode reward : 15.971398577839135\n",
      "episode 255 done\n",
      "[ep255] episode_rewards for agent 0 : 52.9659962374717\n",
      "[ep255] episode_rewards for agent 1 : -57.14399663824588\n",
      "[ep255] episode_rewards for agent 2 : -0.2880003824830055\n",
      "[ep255] episode_rewards for agent 3 : -40.87599821668118\n",
      "[ep255] episode_rewards for agent 4 : 49.61199668329209\n",
      "[ep255] episode_rewards for agent 5 : 78.41199478507042\n",
      "[ep255] episode_rewards for agent 6 : -2.6400007335469127\n",
      "[ep255] episode_rewards for agent 7 : -45.89999766647816\n",
      "[ep255] episode_rewards for agent 8 : -24.435999325476587\n",
      "[ep255] episode_rewards for agent 9 : 9.207999124191701\n",
      "[ep255] mean episode reward : 1.8913993867114187\n",
      "episode 256 done\n",
      "[ep256] episode_rewards for agent 0 : 81.89799470454454\n",
      "[ep256] episode_rewards for agent 1 : -54.11999687179923\n",
      "[ep256] episode_rewards for agent 2 : 25.243997876532376\n",
      "[ep256] episode_rewards for agent 3 : -5.896000818349421\n",
      "[ep256] episode_rewards for agent 4 : 112.93599270284176\n",
      "[ep256] episode_rewards for agent 5 : 23.923997847363353\n",
      "[ep256] episode_rewards for agent 6 : -20.455999555066228\n",
      "[ep256] episode_rewards for agent 7 : -53.29599691927433\n",
      "[ep256] episode_rewards for agent 8 : -40.98799809347838\n",
      "[ep256] episode_rewards for agent 9 : 23.98799809254706\n",
      "[ep256] mean episode reward : 9.32339889658615\n",
      "episode 257 done\n",
      "[ep257] episode_rewards for agent 0 : 5.50199915561825\n",
      "[ep257] episode_rewards for agent 1 : -57.23999667633325\n",
      "[ep257] episode_rewards for agent 2 : 56.29199608694762\n",
      "[ep257] episode_rewards for agent 3 : -33.779998583719134\n",
      "[ep257] episode_rewards for agent 4 : 39.50799705926329\n",
      "[ep257] episode_rewards for agent 5 : 96.6399938184768\n",
      "[ep257] episode_rewards for agent 6 : -39.2159982630983\n",
      "[ep257] episode_rewards for agent 7 : -56.75999671127647\n",
      "[ep257] episode_rewards for agent 8 : -31.259999062865973\n",
      "[ep257] episode_rewards for agent 9 : 7.779999224469066\n",
      "[ep257] mean episode reward : -1.2534003952518105\n",
      "episode 258 done\n",
      "[ep258] episode_rewards for agent 0 : 67.17799554485828\n",
      "[ep258] episode_rewards for agent 1 : -59.80399645585567\n",
      "[ep258] episode_rewards for agent 2 : -55.87599674984813\n",
      "[ep258] episode_rewards for agent 3 : -21.035999728366733\n",
      "[ep258] episode_rewards for agent 4 : 64.43599556945264\n",
      "[ep258] episode_rewards for agent 5 : 139.1119913654402\n",
      "[ep258] episode_rewards for agent 6 : 36.01199699752033\n",
      "[ep258] episode_rewards for agent 7 : -36.3599985698238\n",
      "[ep258] episode_rewards for agent 8 : -47.691997449845076\n",
      "[ep258] episode_rewards for agent 9 : 56.34399589896202\n",
      "[ep258] mean episode reward : 14.231398642249406\n",
      "episode 259 done\n",
      "[ep259] episode_rewards for agent 0 : 163.79798977728933\n",
      "[ep259] episode_rewards for agent 1 : -55.191996805369854\n",
      "[ep259] episode_rewards for agent 2 : -49.643997240811586\n",
      "[ep259] episode_rewards for agent 3 : -25.427999555133283\n",
      "[ep259] episode_rewards for agent 4 : 88.18799430504441\n",
      "[ep259] episode_rewards for agent 5 : 35.875997295603156\n",
      "[ep259] episode_rewards for agent 6 : -14.579999772831798\n",
      "[ep259] episode_rewards for agent 7 : -50.39199728984386\n",
      "[ep259] episode_rewards for agent 8 : -44.07199787069112\n",
      "[ep259] episode_rewards for agent 9 : 30.50399768911302\n",
      "[ep259] mean episode reward : 7.9057990532368425\n",
      "episode 260 done\n",
      "[ep260] episode_rewards for agent 0 : 25.277997931465507\n",
      "[ep260] episode_rewards for agent 1 : -56.30799678247422\n",
      "[ep260] episode_rewards for agent 2 : -43.03999784775078\n",
      "[ep260] episode_rewards for agent 3 : -49.17599740345031\n",
      "[ep260] episode_rewards for agent 4 : -45.07599765434861\n",
      "[ep260] episode_rewards for agent 5 : 33.14799681119621\n",
      "[ep260] episode_rewards for agent 6 : -38.97999837063253\n",
      "[ep260] episode_rewards for agent 7 : -30.067999077029526\n",
      "[ep260] episode_rewards for agent 8 : -43.29199787788093\n",
      "[ep260] episode_rewards for agent 9 : 40.5039971685037\n",
      "[ep260] mean episode reward : -20.70099931024015\n",
      "episode 261 done\n",
      "[ep261] episode_rewards for agent 0 : 127.04599200654775\n",
      "[ep261] episode_rewards for agent 1 : -56.2319967020303\n",
      "[ep261] episode_rewards for agent 2 : -24.55999881774187\n",
      "[ep261] episode_rewards for agent 3 : -8.15600036457181\n",
      "[ep261] episode_rewards for agent 4 : 42.31599695235491\n",
      "[ep261] episode_rewards for agent 5 : 111.48399279359728\n",
      "[ep261] episode_rewards for agent 6 : 4.591999097727239\n",
      "[ep261] episode_rewards for agent 7 : -29.799999051727355\n",
      "[ep261] episode_rewards for agent 8 : -45.87999765295535\n",
      "[ep261] episode_rewards for agent 9 : 62.63599581364542\n",
      "[ep261] mean episode reward : 18.34459840748459\n",
      "episode 262 done\n",
      "[ep262] episode_rewards for agent 0 : 39.061997132375836\n",
      "[ep262] episode_rewards for agent 1 : -53.811996896751225\n",
      "[ep262] episode_rewards for agent 2 : -55.57599682547152\n",
      "[ep262] episode_rewards for agent 3 : -21.207999672740698\n",
      "[ep262] episode_rewards for agent 4 : 15.131998987868428\n",
      "[ep262] episode_rewards for agent 5 : -11.391999930143356\n",
      "[ep262] episode_rewards for agent 6 : -21.567999554798007\n",
      "[ep262] episode_rewards for agent 7 : -39.923998015001416\n",
      "[ep262] episode_rewards for agent 8 : -33.83599880896509\n",
      "[ep262] episode_rewards for agent 9 : 31.743997545912862\n",
      "[ep262] mean episode reward : -15.137799603771418\n",
      "episode 263 done\n",
      "[ep263] episode_rewards for agent 0 : 15.537998501211405\n",
      "[ep263] episode_rewards for agent 1 : -56.4599967719987\n",
      "[ep263] episode_rewards for agent 2 : -37.12399790622294\n",
      "[ep263] episode_rewards for agent 3 : -27.583999360911548\n",
      "[ep263] episode_rewards for agent 4 : 166.97198970708996\n",
      "[ep263] episode_rewards for agent 5 : 61.207995630800724\n",
      "[ep263] episode_rewards for agent 6 : -13.759999866597354\n",
      "[ep263] episode_rewards for agent 7 : -47.387997614219785\n",
      "[ep263] episode_rewards for agent 8 : -29.235999274998903\n",
      "[ep263] episode_rewards for agent 9 : 0.33999931812286377\n",
      "[ep263] mean episode reward : 3.250599236227572\n",
      "episode 264 done\n",
      "[ep264] episode_rewards for agent 0 : -21.113999160006642\n",
      "[ep264] episode_rewards for agent 1 : -56.27199670486152\n",
      "[ep264] episode_rewards for agent 2 : 74.74399513937533\n",
      "[ep264] episode_rewards for agent 3 : -26.52799933683127\n",
      "[ep264] episode_rewards for agent 4 : 9.29999882914126\n",
      "[ep264] episode_rewards for agent 5 : 39.01599697209895\n",
      "[ep264] episode_rewards for agent 6 : -16.148000145331025\n",
      "[ep264] episode_rewards for agent 7 : -34.639998683705926\n",
      "[ep264] episode_rewards for agent 8 : -42.115998041816056\n",
      "[ep264] episode_rewards for agent 9 : 53.431996297091246\n",
      "[ep264] mean episode reward : -2.032600483484566\n",
      "episode 265 done\n",
      "[ep265] episode_rewards for agent 0 : 61.50199577957392\n",
      "[ep265] episode_rewards for agent 1 : -49.723997136577964\n",
      "[ep265] episode_rewards for agent 2 : -28.09999854490161\n",
      "[ep265] episode_rewards for agent 3 : -35.93999834544957\n",
      "[ep265] episode_rewards for agent 4 : 123.21199237089604\n",
      "[ep265] episode_rewards for agent 5 : 106.54799306765199\n",
      "[ep265] episode_rewards for agent 6 : -15.943999688141048\n",
      "[ep265] episode_rewards for agent 7 : -21.20799995586276\n",
      "[ep265] episode_rewards for agent 8 : -42.1519980924204\n",
      "[ep265] episode_rewards for agent 9 : 59.491995982825756\n",
      "[ep265] mean episode reward : 15.768598543759435\n",
      "episode 266 done\n",
      "[ep266] episode_rewards for agent 0 : -33.12999811116606\n",
      "[ep266] episode_rewards for agent 1 : -57.68799663055688\n",
      "[ep266] episode_rewards for agent 2 : -46.791997611522675\n",
      "[ep266] episode_rewards for agent 3 : -31.811998923309147\n",
      "[ep266] episode_rewards for agent 4 : 44.35199672356248\n",
      "[ep266] episode_rewards for agent 5 : 106.18799312133342\n",
      "[ep266] episode_rewards for agent 6 : -22.03199932258576\n",
      "[ep266] episode_rewards for agent 7 : -45.97999773360789\n",
      "[ep266] episode_rewards for agent 8 : -39.86799828149378\n",
      "[ep266] episode_rewards for agent 9 : 1.4399993289262056\n",
      "[ep266] mean episode reward : -12.532199744042009\n",
      "episode 267 done\n",
      "[ep267] episode_rewards for agent 0 : 34.941997300833464\n",
      "[ep267] episode_rewards for agent 1 : -54.215996850281954\n",
      "[ep267] episode_rewards for agent 2 : -57.91999658662826\n",
      "[ep267] episode_rewards for agent 3 : -23.875999500975013\n",
      "[ep267] episode_rewards for agent 4 : 49.63999641034752\n",
      "[ep267] episode_rewards for agent 5 : 43.49999679625034\n",
      "[ep267] episode_rewards for agent 6 : 10.907998602837324\n",
      "[ep267] episode_rewards for agent 7 : -43.883997939527035\n",
      "[ep267] episode_rewards for agent 8 : -32.91599883697927\n",
      "[ep267] episode_rewards for agent 9 : 62.81199568230659\n",
      "[ep267] mean episode reward : -1.101000492181629\n",
      "episode 268 done\n",
      "[ep268] episode_rewards for agent 0 : -35.44199851062149\n",
      "[ep268] episode_rewards for agent 1 : -57.78399660345167\n",
      "[ep268] episode_rewards for agent 2 : -46.20799745153636\n",
      "[ep268] episode_rewards for agent 3 : -11.848000187426805\n",
      "[ep268] episode_rewards for agent 4 : -15.355999610386789\n",
      "[ep268] episode_rewards for agent 5 : 74.97599506098777\n",
      "[ep268] episode_rewards for agent 6 : -12.60000012256205\n",
      "[ep268] episode_rewards for agent 7 : -46.03599767293781\n",
      "[ep268] episode_rewards for agent 8 : -33.43199864961207\n",
      "[ep268] episode_rewards for agent 9 : 94.70799383055419\n",
      "[ep268] mean episode reward : -8.902199991699309\n",
      "episode 269 done\n",
      "[ep269] episode_rewards for agent 0 : 124.04999198298901\n",
      "[ep269] episode_rewards for agent 1 : -55.683996739797294\n",
      "[ep269] episode_rewards for agent 2 : -40.76399789284915\n",
      "[ep269] episode_rewards for agent 3 : -21.799999416805804\n",
      "[ep269] episode_rewards for agent 4 : 68.06399577017874\n",
      "[ep269] episode_rewards for agent 5 : 94.24399386439472\n",
      "[ep269] episode_rewards for agent 6 : -9.159999984316528\n",
      "[ep269] episode_rewards for agent 7 : -40.83599817939103\n",
      "[ep269] episode_rewards for agent 8 : -54.923996828496456\n",
      "[ep269] episode_rewards for agent 9 : 59.879996014758945\n",
      "[ep269] mean episode reward : 12.306998859066516\n",
      "episode 270 done\n",
      "[ep270] episode_rewards for agent 0 : 93.7219940815121\n",
      "[ep270] episode_rewards for agent 1 : -58.811996531672776\n",
      "[ep270] episode_rewards for agent 2 : -50.29999727755785\n",
      "[ep270] episode_rewards for agent 3 : -16.25599986128509\n",
      "[ep270] episode_rewards for agent 4 : -3.720000167377293\n",
      "[ep270] episode_rewards for agent 5 : 75.45599498972297\n",
      "[ep270] episode_rewards for agent 6 : -18.739999884739518\n",
      "[ep270] episode_rewards for agent 7 : -54.13599697407335\n",
      "[ep270] episode_rewards for agent 8 : -37.99999824445695\n",
      "[ep270] episode_rewards for agent 9 : 2.9679995086044073\n",
      "[ep270] mean episode reward : -6.781800036132336\n",
      "episode 271 done\n",
      "[ep271] episode_rewards for agent 0 : 89.6099942959845\n",
      "[ep271] episode_rewards for agent 1 : -50.791997206397355\n",
      "[ep271] episode_rewards for agent 2 : -57.811996635980904\n",
      "[ep271] episode_rewards for agent 3 : -32.551998873241246\n",
      "[ep271] episode_rewards for agent 4 : 173.9319893475622\n",
      "[ep271] episode_rewards for agent 5 : 12.547998423688114\n",
      "[ep271] episode_rewards for agent 6 : -16.615999720990658\n",
      "[ep271] episode_rewards for agent 7 : -28.343999265693128\n",
      "[ep271] episode_rewards for agent 8 : -27.06799939274788\n",
      "[ep271] episode_rewards for agent 9 : 85.47599447797984\n",
      "[ep271] mean episode reward : 14.838198545016349\n",
      "episode 272 done\n",
      "[ep272] episode_rewards for agent 0 : 40.48599696904421\n",
      "[ep272] episode_rewards for agent 1 : -57.819996603764594\n",
      "[ep272] episode_rewards for agent 2 : -54.05199687927961\n",
      "[ep272] episode_rewards for agent 3 : -28.42399914842099\n",
      "[ep272] episode_rewards for agent 4 : 128.37999208830297\n",
      "[ep272] episode_rewards for agent 5 : 117.19599253125489\n",
      "[ep272] episode_rewards for agent 6 : -1.2880007000640035\n",
      "[ep272] episode_rewards for agent 7 : -18.212000048719347\n",
      "[ep272] episode_rewards for agent 8 : -56.883996684104204\n",
      "[ep272] episode_rewards for agent 9 : 5.515999181196094\n",
      "[ep272] mean episode reward : 7.4897990705445405\n",
      "episode 273 done\n",
      "[ep273] episode_rewards for agent 0 : 46.52599675767124\n",
      "[ep273] episode_rewards for agent 1 : -46.895997473970056\n",
      "[ep273] episode_rewards for agent 2 : -54.72799680754542\n",
      "[ep273] episode_rewards for agent 3 : -19.319999595172703\n",
      "[ep273] episode_rewards for agent 4 : 33.18799763079733\n",
      "[ep273] episode_rewards for agent 5 : 135.5279914373532\n",
      "[ep273] episode_rewards for agent 6 : -39.87599794007838\n",
      "[ep273] episode_rewards for agent 7 : -47.05599762964994\n",
      "[ep273] episode_rewards for agent 8 : -52.97199706360698\n",
      "[ep273] episode_rewards for agent 9 : 27.611997864209116\n",
      "[ep273] mean episode reward : -1.7994002819992603\n",
      "episode 274 done\n",
      "[ep274] episode_rewards for agent 0 : 71.25799531303346\n",
      "[ep274] episode_rewards for agent 1 : -58.53199656866491\n",
      "[ep274] episode_rewards for agent 2 : -51.20799712277949\n",
      "[ep274] episode_rewards for agent 3 : -7.388000641018152\n",
      "[ep274] episode_rewards for agent 4 : 55.33999630436301\n",
      "[ep274] episode_rewards for agent 5 : 71.95599510334432\n",
      "[ep274] episode_rewards for agent 6 : -35.29999860189855\n",
      "[ep274] episode_rewards for agent 7 : -52.48399709351361\n",
      "[ep274] episode_rewards for agent 8 : -55.74399673379958\n",
      "[ep274] episode_rewards for agent 9 : 64.44399558473378\n",
      "[ep274] mean episode reward : 0.23419955438002943\n",
      "episode 275 done\n",
      "[ep275] episode_rewards for agent 0 : 108.06999317090958\n",
      "[ep275] episode_rewards for agent 1 : -54.79199684690684\n",
      "[ep275] episode_rewards for agent 2 : -40.03599797189236\n",
      "[ep275] episode_rewards for agent 3 : -32.319998976774514\n",
      "[ep275] episode_rewards for agent 4 : 44.74799696635455\n",
      "[ep275] episode_rewards for agent 5 : 7.943998514674604\n",
      "[ep275] episode_rewards for agent 6 : -53.9799969131127\n",
      "[ep275] episode_rewards for agent 7 : -54.1959969336167\n",
      "[ep275] episode_rewards for agent 8 : -30.535999161191285\n",
      "[ep275] episode_rewards for agent 9 : 3.243999314494431\n",
      "[ep275] mean episode reward : -10.185399883706122\n",
      "episode 276 done\n",
      "[ep276] episode_rewards for agent 0 : 32.001997616142035\n",
      "[ep276] episode_rewards for agent 1 : -54.70399682968855\n",
      "[ep276] episode_rewards for agent 2 : -52.8279969478026\n",
      "[ep276] episode_rewards for agent 3 : -19.61999993864447\n",
      "[ep276] episode_rewards for agent 4 : 61.51999578438699\n",
      "[ep276] episode_rewards for agent 5 : 141.93999115377665\n",
      "[ep276] episode_rewards for agent 6 : -32.64399844780564\n",
      "[ep276] episode_rewards for agent 7 : -52.89599699340761\n",
      "[ep276] episode_rewards for agent 8 : -44.44799780845642\n",
      "[ep276] episode_rewards for agent 9 : 41.14799701143056\n",
      "[ep276] mean episode reward : 1.9469994599930942\n",
      "episode 277 done\n",
      "[ep277] episode_rewards for agent 0 : 29.597997752949595\n",
      "[ep277] episode_rewards for agent 1 : -51.31999710574746\n",
      "[ep277] episode_rewards for agent 2 : -52.58799705654383\n",
      "[ep277] episode_rewards for agent 3 : -12.303999992087483\n",
      "[ep277] episode_rewards for agent 4 : -7.631999846547842\n",
      "[ep277] episode_rewards for agent 5 : 107.60799316130579\n",
      "[ep277] episode_rewards for agent 6 : -0.12800073716789484\n",
      "[ep277] episode_rewards for agent 7 : -18.904000063426793\n",
      "[ep277] episode_rewards for agent 8 : -40.21999818086624\n",
      "[ep277] episode_rewards for agent 9 : 19.667998482473195\n",
      "[ep277] mean episode reward : -2.622200358565897\n",
      "episode 278 done\n",
      "[ep278] episode_rewards for agent 0 : 39.12999705411494\n",
      "[ep278] episode_rewards for agent 1 : -57.85999663639814\n",
      "[ep278] episode_rewards for agent 2 : -58.03199658356607\n",
      "[ep278] episode_rewards for agent 3 : -29.8319991864264\n",
      "[ep278] episode_rewards for agent 4 : 30.267997932620347\n",
      "[ep278] episode_rewards for agent 5 : 58.33999619074166\n",
      "[ep278] episode_rewards for agent 6 : -24.94799883197993\n",
      "[ep278] episode_rewards for agent 7 : -26.903999185189605\n",
      "[ep278] episode_rewards for agent 8 : -37.83999837748706\n",
      "[ep278] episode_rewards for agent 9 : 47.739996617659926\n",
      "[ep278] mean episode reward : -5.9938001005910335\n",
      "episode 279 done\n",
      "[ep279] episode_rewards for agent 0 : 48.17799653392285\n",
      "[ep279] episode_rewards for agent 1 : -58.45999660342932\n",
      "[ep279] episode_rewards for agent 2 : -59.19599650520831\n",
      "[ep279] episode_rewards for agent 3 : -19.81199953146279\n",
      "[ep279] episode_rewards for agent 4 : 7.331999259069562\n",
      "[ep279] episode_rewards for agent 5 : 33.187997134402394\n",
      "[ep279] episode_rewards for agent 6 : -8.960000034421682\n",
      "[ep279] episode_rewards for agent 7 : -52.603997140191495\n",
      "[ep279] episode_rewards for agent 8 : -36.65599850844592\n",
      "[ep279] episode_rewards for agent 9 : 42.051996850408614\n",
      "[ep279] mean episode reward : -10.49379985453561\n",
      "episode 280 done\n",
      "[ep280] episode_rewards for agent 0 : 28.093997745774686\n",
      "[ep280] episode_rewards for agent 1 : -49.507997375912964\n",
      "[ep280] episode_rewards for agent 2 : -59.52399647049606\n",
      "[ep280] episode_rewards for agent 3 : 0.6319990819320083\n",
      "[ep280] episode_rewards for agent 4 : 131.41999184526503\n",
      "[ep280] episode_rewards for agent 5 : 97.39199382346123\n",
      "[ep280] episode_rewards for agent 6 : -7.47600020468235\n",
      "[ep280] episode_rewards for agent 7 : -51.13199725188315\n",
      "[ep280] episode_rewards for agent 8 : -42.76799796335399\n",
      "[ep280] episode_rewards for agent 9 : 95.29199380427599\n",
      "[ep280] mean episode reward : 14.242198703438044\n",
      "episode 281 done\n",
      "[ep281] episode_rewards for agent 0 : 47.08599675446749\n",
      "[ep281] episode_rewards for agent 1 : -55.55999671667814\n",
      "[ep281] episode_rewards for agent 2 : -29.159998774528503\n",
      "[ep281] episode_rewards for agent 3 : -17.11200018040836\n",
      "[ep281] episode_rewards for agent 4 : 106.23199329525232\n",
      "[ep281] episode_rewards for agent 5 : 116.55199258308858\n",
      "[ep281] episode_rewards for agent 6 : -18.943999534472823\n",
      "[ep281] episode_rewards for agent 7 : -29.51199897006154\n",
      "[ep281] episode_rewards for agent 8 : -44.26399768795818\n",
      "[ep281] episode_rewards for agent 9 : 17.631998545490205\n",
      "[ep281] mean episode reward : 9.294998931419105\n",
      "episode 282 done\n",
      "[ep282] episode_rewards for agent 0 : 138.7339913221076\n",
      "[ep282] episode_rewards for agent 1 : -58.759996513836086\n",
      "[ep282] episode_rewards for agent 2 : -49.31199727859348\n",
      "[ep282] episode_rewards for agent 3 : -44.14799766801298\n",
      "[ep282] episode_rewards for agent 4 : 31.507997632026672\n",
      "[ep282] episode_rewards for agent 5 : -21.015999888069928\n",
      "[ep282] episode_rewards for agent 6 : 26.16799753624946\n",
      "[ep282] episode_rewards for agent 7 : -32.84399897698313\n",
      "[ep282] episode_rewards for agent 8 : -51.43199721258134\n",
      "[ep282] episode_rewards for agent 9 : 21.655998162925243\n",
      "[ep282] mean episode reward : -3.944600288476795\n",
      "episode 283 done\n",
      "[ep283] episode_rewards for agent 0 : 87.98199434671551\n",
      "[ep283] episode_rewards for agent 1 : -58.80399652477354\n",
      "[ep283] episode_rewards for agent 2 : -50.491997158154845\n",
      "[ep283] episode_rewards for agent 3 : -31.815998894162476\n",
      "[ep283] episode_rewards for agent 4 : 119.36399268358946\n",
      "[ep283] episode_rewards for agent 5 : 188.81198844593018\n",
      "[ep283] episode_rewards for agent 6 : -34.70399864856154\n",
      "[ep283] episode_rewards for agent 7 : -53.779997003264725\n",
      "[ep283] episode_rewards for agent 8 : -47.655997541733086\n",
      "[ep283] episode_rewards for agent 9 : 13.451998616568744\n",
      "[ep283] mean episode reward : 13.23579883221537\n",
      "episode 284 done\n",
      "[ep284] episode_rewards for agent 0 : 21.95399832073599\n",
      "[ep284] episode_rewards for agent 1 : -48.211997292004526\n",
      "[ep284] episode_rewards for agent 2 : -50.57999713905156\n",
      "[ep284] episode_rewards for agent 3 : -23.543999277986586\n",
      "[ep284] episode_rewards for agent 4 : 153.6039905641228\n",
      "[ep284] episode_rewards for agent 5 : 127.72799183335155\n",
      "[ep284] episode_rewards for agent 6 : 7.483998893760145\n",
      "[ep284] episode_rewards for agent 7 : -44.54399781674147\n",
      "[ep284] episode_rewards for agent 8 : -23.551999636925757\n",
      "[ep284] episode_rewards for agent 9 : -22.19999911915511\n",
      "[ep284] mean episode reward : 9.813798933010549\n",
      "episode 285 done\n",
      "[ep285] episode_rewards for agent 0 : 20.349998159334064\n",
      "[ep285] episode_rewards for agent 1 : -57.25199664756656\n",
      "[ep285] episode_rewards for agent 2 : -58.18799660447985\n",
      "[ep285] episode_rewards for agent 3 : -32.25199899356812\n",
      "[ep285] episode_rewards for agent 4 : -21.947999807074666\n",
      "[ep285] episode_rewards for agent 5 : 24.875997328199446\n",
      "[ep285] episode_rewards for agent 6 : 24.431997815147042\n",
      "[ep285] episode_rewards for agent 7 : -45.93599761836231\n",
      "[ep285] episode_rewards for agent 8 : -49.159997314214706\n",
      "[ep285] episode_rewards for agent 9 : -0.336000450886786\n",
      "[ep285] mean episode reward : -19.541399413347243\n",
      "episode 286 done\n",
      "[ep286] episode_rewards for agent 0 : 25.729997843503952\n",
      "[ep286] episode_rewards for agent 1 : -47.20799739751965\n",
      "[ep286] episode_rewards for agent 2 : -50.0039972551167\n",
      "[ep286] episode_rewards for agent 3 : -29.08399904705584\n",
      "[ep286] episode_rewards for agent 4 : 83.09599445201457\n",
      "[ep286] episode_rewards for agent 5 : 86.9919943716377\n",
      "[ep286] episode_rewards for agent 6 : -27.39999909605831\n",
      "[ep286] episode_rewards for agent 7 : -52.79599698539823\n",
      "[ep286] episode_rewards for agent 8 : -40.37199819087982\n",
      "[ep286] episode_rewards for agent 9 : 67.21999558713287\n",
      "[ep286] mean episode reward : 1.6173994282260538\n",
      "episode 287 done\n",
      "[ep287] episode_rewards for agent 0 : 22.697998364455998\n",
      "[ep287] episode_rewards for agent 1 : -54.43599677272141\n",
      "[ep287] episode_rewards for agent 2 : -44.99999773222953\n",
      "[ep287] episode_rewards for agent 3 : -24.399999234825373\n",
      "[ep287] episode_rewards for agent 4 : -33.95999801065773\n",
      "[ep287] episode_rewards for agent 5 : 105.3839933425188\n",
      "[ep287] episode_rewards for agent 6 : -12.987999713979661\n",
      "[ep287] episode_rewards for agent 7 : -19.576000064611435\n",
      "[ep287] episode_rewards for agent 8 : -28.73599927034229\n",
      "[ep287] episode_rewards for agent 9 : 55.719996359199286\n",
      "[ep287] mean episode reward : -3.5294002733193337\n",
      "episode 288 done\n",
      "[ep288] episode_rewards for agent 0 : 10.121998882852495\n",
      "[ep288] episode_rewards for agent 1 : -58.05999657791108\n",
      "[ep288] episode_rewards for agent 2 : -56.41199670732021\n",
      "[ep288] episode_rewards for agent 3 : -8.820000092498958\n",
      "[ep288] episode_rewards for agent 4 : -54.4239968508482\n",
      "[ep288] episode_rewards for agent 5 : 73.84799500741065\n",
      "[ep288] episode_rewards for agent 6 : 30.41599751263857\n",
      "[ep288] episode_rewards for agent 7 : -54.33999696467072\n",
      "[ep288] episode_rewards for agent 8 : -48.59199746046215\n",
      "[ep288] episode_rewards for agent 9 : 98.87199364043772\n",
      "[ep288] mean episode reward : -6.738999961037189\n",
      "episode 289 done\n",
      "[ep289] episode_rewards for agent 0 : 71.81399525795132\n",
      "[ep289] episode_rewards for agent 1 : -57.071996736340225\n",
      "[ep289] episode_rewards for agent 2 : -56.14799672272056\n",
      "[ep289] episode_rewards for agent 3 : -22.383999635465443\n",
      "[ep289] episode_rewards for agent 4 : 33.095997353084385\n",
      "[ep289] episode_rewards for agent 5 : 75.03599492553622\n",
      "[ep289] episode_rewards for agent 6 : -12.491999948397279\n",
      "[ep289] episode_rewards for agent 7 : -50.51199728902429\n",
      "[ep289] episode_rewards for agent 8 : -39.93999821972102\n",
      "[ep289] episode_rewards for agent 9 : 38.13599734194577\n",
      "[ep289] mean episode reward : -2.0466003673151136\n",
      "episode 290 done\n",
      "[ep290] episode_rewards for agent 0 : 98.3899935754016\n",
      "[ep290] episode_rewards for agent 1 : -51.003997191786766\n",
      "[ep290] episode_rewards for agent 2 : -49.25199735350907\n",
      "[ep290] episode_rewards for agent 3 : -19.227999626658857\n",
      "[ep290] episode_rewards for agent 4 : 21.09599849395454\n",
      "[ep290] episode_rewards for agent 5 : 71.15199521742761\n",
      "[ep290] episode_rewards for agent 6 : 11.359998597763479\n",
      "[ep290] episode_rewards for agent 7 : -29.039999240078032\n",
      "[ep290] episode_rewards for agent 8 : -45.83599755819887\n",
      "[ep290] episode_rewards for agent 9 : 18.76799855567515\n",
      "[ep290] mean episode reward : 2.640599346999079\n",
      "episode 291 done\n",
      "[ep291] episode_rewards for agent 0 : 84.69399461243302\n",
      "[ep291] episode_rewards for agent 1 : -57.5799966417253\n",
      "[ep291] episode_rewards for agent 2 : -41.12799788732082\n",
      "[ep291] episode_rewards for agent 3 : -18.94799952581525\n",
      "[ep291] episode_rewards for agent 4 : 110.24799296725541\n",
      "[ep291] episode_rewards for agent 5 : 86.48799426760525\n",
      "[ep291] episode_rewards for agent 6 : -7.972000006586313\n",
      "[ep291] episode_rewards for agent 7 : -38.31199804227799\n",
      "[ep291] episode_rewards for agent 8 : -37.79599815513939\n",
      "[ep291] episode_rewards for agent 9 : 45.41999696753919\n",
      "[ep291] mean episode reward : 12.51139885559678\n",
      "episode 292 done\n",
      "[ep292] episode_rewards for agent 0 : 56.84199613425881\n",
      "[ep292] episode_rewards for agent 1 : -54.12799686007202\n",
      "[ep292] episode_rewards for agent 2 : -51.21199715510011\n",
      "[ep292] episode_rewards for agent 3 : -16.92799990531057\n",
      "[ep292] episode_rewards for agent 4 : 178.17198920622468\n",
      "[ep292] episode_rewards for agent 5 : 56.015996226109564\n",
      "[ep292] episode_rewards for agent 6 : -4.720000476576388\n",
      "[ep292] episode_rewards for agent 7 : -50.33599731512368\n",
      "[ep292] episode_rewards for agent 8 : -31.703998723998666\n",
      "[ep292] episode_rewards for agent 9 : 10.867998767644167\n",
      "[ep292] mean episode reward : 9.286998989805578\n",
      "episode 293 done\n",
      "[ep293] episode_rewards for agent 0 : 74.07799506559968\n",
      "[ep293] episode_rewards for agent 1 : -58.723996507935226\n",
      "[ep293] episode_rewards for agent 2 : -48.03599754627794\n",
      "[ep293] episode_rewards for agent 3 : -13.688000418245792\n",
      "[ep293] episode_rewards for agent 4 : -20.795998856425285\n",
      "[ep293] episode_rewards for agent 5 : 29.807997716590762\n",
      "[ep293] episode_rewards for agent 6 : -14.423999632708728\n",
      "[ep293] episode_rewards for agent 7 : -40.57199810817838\n",
      "[ep293] episode_rewards for agent 8 : -44.66399780474603\n",
      "[ep293] episode_rewards for agent 9 : 33.923997663892806\n",
      "[ep293] mean episode reward : -10.309399842843414\n",
      "episode 294 done\n",
      "[ep294] episode_rewards for agent 0 : 28.19799790997058\n",
      "[ep294] episode_rewards for agent 1 : -57.94399661105126\n",
      "[ep294] episode_rewards for agent 2 : -52.191997112706304\n",
      "[ep294] episode_rewards for agent 3 : -16.34399985615164\n",
      "[ep294] episode_rewards for agent 4 : 108.32399304769933\n",
      "[ep294] episode_rewards for agent 5 : 12.167998841032386\n",
      "[ep294] episode_rewards for agent 6 : -11.34800014924258\n",
      "[ep294] episode_rewards for agent 7 : -29.191999099217355\n",
      "[ep294] episode_rewards for agent 8 : -49.23599745053798\n",
      "[ep294] episode_rewards for agent 9 : 58.1279962323606\n",
      "[ep294] mean episode reward : -0.9438004247844219\n",
      "episode 295 done\n",
      "[ep295] episode_rewards for agent 0 : 20.341998427174985\n",
      "[ep295] episode_rewards for agent 1 : -58.60399656184018\n",
      "[ep295] episode_rewards for agent 2 : -42.95999779179692\n",
      "[ep295] episode_rewards for agent 3 : -24.531999395228922\n",
      "[ep295] episode_rewards for agent 4 : 39.195997225120664\n",
      "[ep295] episode_rewards for agent 5 : 50.883996048010886\n",
      "[ep295] episode_rewards for agent 6 : 6.29599872417748\n",
      "[ep295] episode_rewards for agent 7 : -53.29199707508087\n",
      "[ep295] episode_rewards for agent 8 : -48.599997346289456\n",
      "[ep295] episode_rewards for agent 9 : 14.019998605363071\n",
      "[ep295] mean episode reward : -9.724999914038927\n",
      "episode 296 done\n",
      "[ep296] episode_rewards for agent 0 : 73.1379952467978\n",
      "[ep296] episode_rewards for agent 1 : -53.819996843114495\n",
      "[ep296] episode_rewards for agent 2 : -42.49199795629829\n",
      "[ep296] episode_rewards for agent 3 : -7.920000419951975\n",
      "[ep296] episode_rewards for agent 4 : 29.503997826948762\n",
      "[ep296] episode_rewards for agent 5 : 93.0119938487187\n",
      "[ep296] episode_rewards for agent 6 : -13.739999769255519\n",
      "[ep296] episode_rewards for agent 7 : -45.61199773941189\n",
      "[ep296] episode_rewards for agent 8 : -44.463997828774154\n",
      "[ep296] episode_rewards for agent 9 : -2.00400026794523\n",
      "[ep296] mean episode reward : -1.4398003902286292\n",
      "episode 297 done\n",
      "[ep297] episode_rewards for agent 0 : 84.89799446705729\n",
      "[ep297] episode_rewards for agent 1 : -52.2719971453771\n",
      "[ep297] episode_rewards for agent 2 : -53.83599697705358\n",
      "[ep297] episode_rewards for agent 3 : -24.79599936120212\n",
      "[ep297] episode_rewards for agent 4 : 83.92799468804151\n",
      "[ep297] episode_rewards for agent 5 : 50.515996461734176\n",
      "[ep297] episode_rewards for agent 6 : -18.991999574936926\n",
      "[ep297] episode_rewards for agent 7 : -50.90399725083262\n",
      "[ep297] episode_rewards for agent 8 : -46.76799747347832\n",
      "[ep297] episode_rewards for agent 9 : 3.015999458730221\n",
      "[ep297] mean episode reward : -2.521000270731747\n",
      "episode 298 done\n",
      "[ep298] episode_rewards for agent 0 : 25.473998153582215\n",
      "[ep298] episode_rewards for agent 1 : -55.323996821418405\n",
      "[ep298] episode_rewards for agent 2 : -53.72799700591713\n",
      "[ep298] episode_rewards for agent 3 : -11.300000291317701\n",
      "[ep298] episode_rewards for agent 4 : 37.75199746899307\n",
      "[ep298] episode_rewards for agent 5 : 38.275997267104685\n",
      "[ep298] episode_rewards for agent 6 : -3.5720005678012967\n",
      "[ep298] episode_rewards for agent 7 : -29.52799922041595\n",
      "[ep298] episode_rewards for agent 8 : -51.69999710004777\n",
      "[ep298] episode_rewards for agent 9 : 84.55199449136853\n",
      "[ep298] mean episode reward : -1.909800362586975\n",
      "episode 299 done\n",
      "[ep299] episode_rewards for agent 0 : 2.2779995603486896\n",
      "[ep299] episode_rewards for agent 1 : -55.16799682658166\n",
      "[ep299] episode_rewards for agent 2 : -53.15999699383974\n",
      "[ep299] episode_rewards for agent 3 : -15.864000031724572\n",
      "[ep299] episode_rewards for agent 4 : -15.271999416872859\n",
      "[ep299] episode_rewards for agent 5 : 67.6039953418076\n",
      "[ep299] episode_rewards for agent 6 : -37.33999787736684\n",
      "[ep299] episode_rewards for agent 7 : -38.4159983554855\n",
      "[ep299] episode_rewards for agent 8 : -35.82799859996885\n",
      "[ep299] episode_rewards for agent 9 : 74.02399507723749\n",
      "[ep299] mean episode reward : -10.714199812244624\n",
      "episode 300 done\n",
      "[ep300] episode_rewards for agent 0 : 30.31399796437472\n",
      "[ep300] episode_rewards for agent 1 : -59.17199650127441\n",
      "[ep300] episode_rewards for agent 2 : -52.05199709441513\n",
      "[ep300] episode_rewards for agent 3 : -26.87599914520979\n",
      "[ep300] episode_rewards for agent 4 : 89.09599433001131\n",
      "[ep300] episode_rewards for agent 5 : 57.719996348023415\n",
      "[ep300] episode_rewards for agent 6 : -51.099997146986425\n",
      "[ep300] episode_rewards for agent 7 : -35.38799871876836\n",
      "[ep300] episode_rewards for agent 8 : -45.18799777049571\n",
      "[ep300] episode_rewards for agent 9 : 12.667998747900128\n",
      "[ep300] mean episode reward : -7.997799898684025\n",
      "episode 301 done\n",
      "[ep301] episode_rewards for agent 0 : 41.153997180983424\n",
      "[ep301] episode_rewards for agent 1 : -53.43599695339799\n",
      "[ep301] episode_rewards for agent 2 : -53.37599691003561\n",
      "[ep301] episode_rewards for agent 3 : -36.555998442694545\n",
      "[ep301] episode_rewards for agent 4 : -7.819999917410314\n",
      "[ep301] episode_rewards for agent 5 : 121.27199224662036\n",
      "[ep301] episode_rewards for agent 6 : -11.923999519087374\n",
      "[ep301] episode_rewards for agent 7 : -44.29199788160622\n",
      "[ep301] episode_rewards for agent 8 : -45.439997614361346\n",
      "[ep301] episode_rewards for agent 9 : 34.85599743202329\n",
      "[ep301] mean episode reward : -5.556200037896633\n",
      "episode 302 done\n",
      "[ep302] episode_rewards for agent 0 : 80.93399465177208\n",
      "[ep302] episode_rewards for agent 1 : -48.963997275568545\n",
      "[ep302] episode_rewards for agent 2 : -46.79999740887433\n",
      "[ep302] episode_rewards for agent 3 : -32.83199887070805\n",
      "[ep302] episode_rewards for agent 4 : 94.22399413678795\n",
      "[ep302] episode_rewards for agent 5 : 97.73199352342635\n",
      "[ep302] episode_rewards for agent 6 : -50.98799722827971\n",
      "[ep302] episode_rewards for agent 7 : -47.40399754606187\n",
      "[ep302] episode_rewards for agent 8 : -36.55599850509316\n",
      "[ep302] episode_rewards for agent 9 : 5.179999299347401\n",
      "[ep302] mean episode reward : 1.4525994776748121\n",
      "episode 303 done\n",
      "[ep303] episode_rewards for agent 0 : -9.397999755106866\n",
      "[ep303] episode_rewards for agent 1 : -54.631996924988925\n",
      "[ep303] episode_rewards for agent 2 : -59.97999642603099\n",
      "[ep303] episode_rewards for agent 3 : -19.98399968445301\n",
      "[ep303] episode_rewards for agent 4 : 79.90399462822825\n",
      "[ep303] episode_rewards for agent 5 : 23.315997913479805\n",
      "[ep303] episode_rewards for agent 6 : -10.496000160463154\n",
      "[ep303] episode_rewards for agent 7 : -38.907998368144035\n",
      "[ep303] episode_rewards for agent 8 : -47.56799755152315\n",
      "[ep303] episode_rewards for agent 9 : 72.935995221138\n",
      "[ep303] mean episode reward : -6.481000110786408\n",
      "episode 304 done\n",
      "[ep304] episode_rewards for agent 0 : 0.029999420046806335\n",
      "[ep304] episode_rewards for agent 1 : -55.31599685084075\n",
      "[ep304] episode_rewards for agent 2 : -47.771997508592904\n",
      "[ep304] episode_rewards for agent 3 : -23.643999711610377\n",
      "[ep304] episode_rewards for agent 4 : 37.79599721636623\n",
      "[ep304] episode_rewards for agent 5 : 53.759996278211474\n",
      "[ep304] episode_rewards for agent 6 : -23.17199904564768\n",
      "[ep304] episode_rewards for agent 7 : -19.688000151887536\n",
      "[ep304] episode_rewards for agent 8 : -43.695997815579176\n",
      "[ep304] episode_rewards for agent 9 : 26.57199795730412\n",
      "[ep304] mean episode reward : -9.513000021222979\n",
      "episode 305 done\n",
      "[ep305] episode_rewards for agent 0 : -29.049998357892036\n",
      "[ep305] episode_rewards for agent 1 : -58.34399652481079\n",
      "[ep305] episode_rewards for agent 2 : -55.003996894694865\n",
      "[ep305] episode_rewards for agent 3 : -20.37199986539781\n",
      "[ep305] episode_rewards for agent 4 : 112.1999928271398\n",
      "[ep305] episode_rewards for agent 5 : 132.89599169883877\n",
      "[ep305] episode_rewards for agent 6 : -23.291999191977084\n",
      "[ep305] episode_rewards for agent 7 : -41.24799810908735\n",
      "[ep305] episode_rewards for agent 8 : -55.32399685680866\n",
      "[ep305] episode_rewards for agent 9 : 76.6319950511679\n",
      "[ep305] mean episode reward : 3.9093993776477873\n",
      "episode 306 done\n",
      "[ep306] episode_rewards for agent 0 : 45.801997006870806\n",
      "[ep306] episode_rewards for agent 1 : -57.49599662423134\n",
      "[ep306] episode_rewards for agent 2 : -56.53199676051736\n",
      "[ep306] episode_rewards for agent 3 : -31.275999004021287\n",
      "[ep306] episode_rewards for agent 4 : 71.23599516786635\n",
      "[ep306] episode_rewards for agent 5 : 135.84399140253663\n",
      "[ep306] episode_rewards for agent 6 : -3.424000445753336\n",
      "[ep306] episode_rewards for agent 7 : -54.41999691165984\n",
      "[ep306] episode_rewards for agent 8 : -46.97599753458053\n",
      "[ep306] episode_rewards for agent 9 : 40.01599712576717\n",
      "[ep306] mean episode reward : 4.277399342227727\n",
      "episode 307 done\n",
      "[ep307] episode_rewards for agent 0 : 48.75799673143774\n",
      "[ep307] episode_rewards for agent 1 : -53.963996910490096\n",
      "[ep307] episode_rewards for agent 2 : -50.81199728138745\n",
      "[ep307] episode_rewards for agent 3 : -10.212000416591763\n",
      "[ep307] episode_rewards for agent 4 : 35.623997170478106\n",
      "[ep307] episode_rewards for agent 5 : 53.89999601524323\n",
      "[ep307] episode_rewards for agent 6 : -31.511998672038317\n",
      "[ep307] episode_rewards for agent 7 : -35.195998733863235\n",
      "[ep307] episode_rewards for agent 8 : -29.999999043531716\n",
      "[ep307] episode_rewards for agent 9 : 53.591996296308935\n",
      "[ep307] mean episode reward : -1.982200484443456\n",
      "episode 308 done\n",
      "[ep308] episode_rewards for agent 0 : -1.702000267803669\n",
      "[ep308] episode_rewards for agent 1 : -53.531997005455196\n",
      "[ep308] episode_rewards for agent 2 : -43.03199779242277\n",
      "[ep308] episode_rewards for agent 3 : -16.92799976747483\n",
      "[ep308] episode_rewards for agent 4 : 32.383997964672744\n",
      "[ep308] episode_rewards for agent 5 : 90.17199434433132\n",
      "[ep308] episode_rewards for agent 6 : -48.9199973391369\n",
      "[ep308] episode_rewards for agent 7 : -42.69199800118804\n",
      "[ep308] episode_rewards for agent 8 : -40.04399826750159\n",
      "[ep308] episode_rewards for agent 9 : 105.49199334066361\n",
      "[ep308] mean episode reward : -1.8802002791315318\n",
      "episode 309 done\n",
      "[ep309] episode_rewards for agent 0 : -44.305997588671744\n",
      "[ep309] episode_rewards for agent 1 : -54.93599684908986\n",
      "[ep309] episode_rewards for agent 2 : -52.40799707826227\n",
      "[ep309] episode_rewards for agent 3 : 4.323999005369842\n",
      "[ep309] episode_rewards for agent 4 : 87.54799454659224\n",
      "[ep309] episode_rewards for agent 5 : 32.4839973738417\n",
      "[ep309] episode_rewards for agent 6 : -26.7239988213405\n",
      "[ep309] episode_rewards for agent 7 : -38.05599828623235\n",
      "[ep309] episode_rewards for agent 8 : -27.867999327369034\n",
      "[ep309] episode_rewards for agent 9 : 1.6039995793253183\n",
      "[ep309] mean episode reward : -11.833799744583667\n",
      "episode 310 done\n",
      "[ep310] episode_rewards for agent 0 : 60.04199605342001\n",
      "[ep310] episode_rewards for agent 1 : -51.7439970979467\n",
      "[ep310] episode_rewards for agent 2 : -58.39199656806886\n",
      "[ep310] episode_rewards for agent 3 : 26.627997627481818\n",
      "[ep310] episode_rewards for agent 4 : 31.879997956566513\n",
      "[ep310] episode_rewards for agent 5 : 97.17599365394562\n",
      "[ep310] episode_rewards for agent 6 : -3.828000597655773\n",
      "[ep310] episode_rewards for agent 7 : -32.79599862918258\n",
      "[ep310] episode_rewards for agent 8 : -46.43599768448621\n",
      "[ep310] episode_rewards for agent 9 : 90.09999415371567\n",
      "[ep310] mean episode reward : 11.26299888677895\n",
      "episode 311 done\n",
      "[ep311] episode_rewards for agent 0 : 76.78199483640492\n",
      "[ep311] episode_rewards for agent 1 : -59.93999643065035\n",
      "[ep311] episode_rewards for agent 2 : -54.4559969175607\n",
      "[ep311] episode_rewards for agent 3 : -5.372000568546355\n",
      "[ep311] episode_rewards for agent 4 : 76.63199499994516\n",
      "[ep311] episode_rewards for agent 5 : 49.30799646675587\n",
      "[ep311] episode_rewards for agent 6 : -18.07999944780022\n",
      "[ep311] episode_rewards for agent 7 : -42.719998029991984\n",
      "[ep311] episode_rewards for agent 8 : -49.29199737962335\n",
      "[ep311] episode_rewards for agent 9 : -29.403998703695834\n",
      "[ep311] mean episode reward : -5.654200117476284\n",
      "episode 312 done\n",
      "[ep312] episode_rewards for agent 0 : 92.33399395085871\n",
      "[ep312] episode_rewards for agent 1 : -54.77199678495526\n",
      "[ep312] episode_rewards for agent 2 : -41.99199816677719\n",
      "[ep312] episode_rewards for agent 3 : -6.360000629909337\n",
      "[ep312] episode_rewards for agent 4 : 76.3399950247258\n",
      "[ep312] episode_rewards for agent 5 : 15.50799844879657\n",
      "[ep312] episode_rewards for agent 6 : -28.13999853283167\n",
      "[ep312] episode_rewards for agent 7 : -49.091997446492314\n",
      "[ep312] episode_rewards for agent 8 : -42.72799795959145\n",
      "[ep312] episode_rewards for agent 9 : 65.01599553134292\n",
      "[ep312] mean episode reward : 2.611399343516678\n",
      "episode 313 done\n",
      "[ep313] episode_rewards for agent 0 : 14.893998816609383\n",
      "[ep313] episode_rewards for agent 1 : -48.2159973224625\n",
      "[ep313] episode_rewards for agent 2 : -59.75599644612521\n",
      "[ep313] episode_rewards for agent 3 : -25.735999195836484\n",
      "[ep313] episode_rewards for agent 4 : -2.268000611104071\n",
      "[ep313] episode_rewards for agent 5 : 56.36799576878548\n",
      "[ep313] episode_rewards for agent 6 : -24.859999337233603\n",
      "[ep313] episode_rewards for agent 7 : -39.167998334392905\n",
      "[ep313] episode_rewards for agent 8 : -39.45199796464294\n",
      "[ep313] episode_rewards for agent 9 : 72.72399527579546\n",
      "[ep313] mean episode reward : -9.54699993506074\n",
      "episode 314 done\n",
      "[ep314] episode_rewards for agent 0 : 63.4539955817163\n",
      "[ep314] episode_rewards for agent 1 : -58.03999657463282\n",
      "[ep314] episode_rewards for agent 2 : -46.803997662849724\n",
      "[ep314] episode_rewards for agent 3 : -14.655999990180135\n",
      "[ep314] episode_rewards for agent 4 : 55.95999641995877\n",
      "[ep314] episode_rewards for agent 5 : 56.62799592129886\n",
      "[ep314] episode_rewards for agent 6 : 31.86399742309004\n",
      "[ep314] episode_rewards for agent 7 : -37.98399830516428\n",
      "[ep314] episode_rewards for agent 8 : -38.05599837191403\n",
      "[ep314] episode_rewards for agent 9 : 70.1239953180775\n",
      "[ep314] mean episode reward : 8.248998975940049\n",
      "episode 315 done\n",
      "[ep315] episode_rewards for agent 0 : 117.68999259080738\n",
      "[ep315] episode_rewards for agent 1 : -59.45199648104608\n",
      "[ep315] episode_rewards for agent 2 : -47.54399739392102\n",
      "[ep315] episode_rewards for agent 3 : 10.183998447842896\n",
      "[ep315] episode_rewards for agent 4 : 92.53999401256442\n",
      "[ep315] episode_rewards for agent 5 : 13.759998925961554\n",
      "[ep315] episode_rewards for agent 6 : 2.9479993479326367\n",
      "[ep315] episode_rewards for agent 7 : -53.94399696588516\n",
      "[ep315] episode_rewards for agent 8 : -33.723998851142824\n",
      "[ep315] episode_rewards for agent 9 : 95.58799398038536\n",
      "[ep315] mean episode reward : 13.804598761349917\n",
      "episode 316 done\n",
      "[ep316] episode_rewards for agent 0 : 34.765997525304556\n",
      "[ep316] episode_rewards for agent 1 : -52.86799697764218\n",
      "[ep316] episode_rewards for agent 2 : -50.33199716452509\n",
      "[ep316] episode_rewards for agent 3 : -20.87999973911792\n",
      "[ep316] episode_rewards for agent 4 : -17.611999795772135\n",
      "[ep316] episode_rewards for agent 5 : 68.65199551265687\n",
      "[ep316] episode_rewards for agent 6 : -26.431998788379133\n",
      "[ep316] episode_rewards for agent 7 : -25.955999086610973\n",
      "[ep316] episode_rewards for agent 8 : -50.7919971877709\n",
      "[ep316] episode_rewards for agent 9 : 9.01999891269952\n",
      "[ep316] mean episode reward : -13.24339967891574\n",
      "episode 317 done\n",
      "[ep317] episode_rewards for agent 0 : 84.1779944775626\n",
      "[ep317] episode_rewards for agent 1 : -59.3359964909032\n",
      "[ep317] episode_rewards for agent 2 : -45.80399773642421\n",
      "[ep317] episode_rewards for agent 3 : -19.235999574884772\n",
      "[ep317] episode_rewards for agent 4 : 142.6839912617579\n",
      "[ep317] episode_rewards for agent 5 : 110.9399928143248\n",
      "[ep317] episode_rewards for agent 6 : -33.87199835758656\n",
      "[ep317] episode_rewards for agent 7 : -49.967997305095196\n",
      "[ep317] episode_rewards for agent 8 : -45.43599737994373\n",
      "[ep317] episode_rewards for agent 9 : 87.33199430257082\n",
      "[ep317] mean episode reward : 17.148198601137846\n",
      "episode 318 done\n",
      "[ep318] episode_rewards for agent 0 : -13.273999601602554\n",
      "[ep318] episode_rewards for agent 1 : -57.391996670514345\n",
      "[ep318] episode_rewards for agent 2 : -39.303998154588044\n",
      "[ep318] episode_rewards for agent 3 : -31.055998926982284\n",
      "[ep318] episode_rewards for agent 4 : 171.41198942437768\n",
      "[ep318] episode_rewards for agent 5 : 109.38799281325191\n",
      "[ep318] episode_rewards for agent 6 : -27.139999309554696\n",
      "[ep318] episode_rewards for agent 7 : -22.979999667964876\n",
      "[ep318] episode_rewards for agent 8 : -55.35199682414532\n",
      "[ep318] episode_rewards for agent 9 : 39.47599720861763\n",
      "[ep318] mean episode reward : 7.377799029089511\n",
      "episode 319 done\n",
      "[ep319] episode_rewards for agent 0 : 77.38599503040314\n",
      "[ep319] episode_rewards for agent 1 : -59.11199650913477\n",
      "[ep319] episode_rewards for agent 2 : -44.29199751652777\n",
      "[ep319] episode_rewards for agent 3 : -13.980000159703195\n",
      "[ep319] episode_rewards for agent 4 : -21.83599998243153\n",
      "[ep319] episode_rewards for agent 5 : 26.167997219599783\n",
      "[ep319] episode_rewards for agent 6 : 59.759995565749705\n",
      "[ep319] episode_rewards for agent 7 : -49.075997420586646\n",
      "[ep319] episode_rewards for agent 8 : -54.347996950149536\n",
      "[ep319] episode_rewards for agent 9 : 12.23599874228239\n",
      "[ep319] mean episode reward : -6.709400198049844\n",
      "episode 320 done\n",
      "[ep320] episode_rewards for agent 0 : -17.865999238565564\n",
      "[ep320] episode_rewards for agent 1 : -56.50799673516303\n",
      "[ep320] episode_rewards for agent 2 : -37.45999842695892\n",
      "[ep320] episode_rewards for agent 3 : -14.675999937579036\n",
      "[ep320] episode_rewards for agent 4 : 107.9519935073331\n",
      "[ep320] episode_rewards for agent 5 : 7.003999251872301\n",
      "[ep320] episode_rewards for agent 6 : -20.60799964517355\n",
      "[ep320] episode_rewards for agent 7 : -54.09199696779251\n",
      "[ep320] episode_rewards for agent 8 : -34.93999871890992\n",
      "[ep320] episode_rewards for agent 9 : 58.34399603493512\n",
      "[ep320] mean episode reward : -6.285000087600201\n",
      "episode 321 done\n",
      "[ep321] episode_rewards for agent 0 : 49.437996657565236\n",
      "[ep321] episode_rewards for agent 1 : -58.7959965467453\n",
      "[ep321] episode_rewards for agent 2 : -58.29199659265578\n",
      "[ep321] episode_rewards for agent 3 : -23.671999210491776\n",
      "[ep321] episode_rewards for agent 4 : 133.11599177215248\n",
      "[ep321] episode_rewards for agent 5 : 102.60399326495826\n",
      "[ep321] episode_rewards for agent 6 : -6.484000368975103\n",
      "[ep321] episode_rewards for agent 7 : -24.455999644473195\n",
      "[ep321] episode_rewards for agent 8 : -55.51599682774395\n",
      "[ep321] episode_rewards for agent 9 : -15.295999412424862\n",
      "[ep321] mean episode reward : 4.264599309116602\n",
      "episode 322 done\n",
      "[ep322] episode_rewards for agent 0 : -26.845998815260828\n",
      "[ep322] episode_rewards for agent 1 : -58.043996590189636\n",
      "[ep322] episode_rewards for agent 2 : -54.08799694664776\n",
      "[ep322] episode_rewards for agent 3 : -4.732000165618956\n",
      "[ep322] episode_rewards for agent 4 : -6.61599987000227\n",
      "[ep322] episode_rewards for agent 5 : 74.17599501553923\n",
      "[ep322] episode_rewards for agent 6 : -6.5240002339705825\n",
      "[ep322] episode_rewards for agent 7 : -47.91199748869985\n",
      "[ep322] episode_rewards for agent 8 : -32.81999886780977\n",
      "[ep322] episode_rewards for agent 9 : 78.20399487111717\n",
      "[ep322] mean episode reward : -8.520199909154325\n",
      "episode 323 done\n",
      "[ep323] episode_rewards for agent 0 : 1.1139997141435742\n",
      "[ep323] episode_rewards for agent 1 : -55.83999677095562\n",
      "[ep323] episode_rewards for agent 2 : -49.567997328937054\n",
      "[ep323] episode_rewards for agent 3 : -31.179998827166855\n",
      "[ep323] episode_rewards for agent 4 : 3.3879993613809347\n",
      "[ep323] episode_rewards for agent 5 : 36.09599706623703\n",
      "[ep323] episode_rewards for agent 6 : -28.27599921822548\n",
      "[ep323] episode_rewards for agent 7 : -25.62399951927364\n",
      "[ep323] episode_rewards for agent 8 : -48.97199747059494\n",
      "[ep323] episode_rewards for agent 9 : 96.46399390231818\n",
      "[ep323] mean episode reward : -10.239799909107386\n",
      "episode 324 done\n",
      "[ep324] episode_rewards for agent 0 : -23.2379989605397\n",
      "[ep324] episode_rewards for agent 1 : -55.67999671958387\n",
      "[ep324] episode_rewards for agent 2 : -54.5839968752116\n",
      "[ep324] episode_rewards for agent 3 : -7.000000626780093\n",
      "[ep324] episode_rewards for agent 4 : 42.29999735299498\n",
      "[ep324] episode_rewards for agent 5 : 182.24798889830709\n",
      "[ep324] episode_rewards for agent 6 : 9.671998458914459\n",
      "[ep324] episode_rewards for agent 7 : -50.25199730694294\n",
      "[ep324] episode_rewards for agent 8 : -50.5559973185882\n",
      "[ep324] episode_rewards for agent 9 : 102.74799336306751\n",
      "[ep324] mean episode reward : 9.565799026563763\n",
      "episode 325 done\n",
      "[ep325] episode_rewards for agent 0 : 62.8539960430935\n",
      "[ep325] episode_rewards for agent 1 : -58.21199655532837\n",
      "[ep325] episode_rewards for agent 2 : -48.64799745101482\n",
      "[ep325] episode_rewards for agent 3 : -22.26799936965108\n",
      "[ep325] episode_rewards for agent 4 : 231.0719860708341\n",
      "[ep325] episode_rewards for agent 5 : 91.07999424170703\n",
      "[ep325] episode_rewards for agent 6 : -24.635999157093465\n",
      "[ep325] episode_rewards for agent 7 : -33.33199889305979\n",
      "[ep325] episode_rewards for agent 8 : -29.90399920195341\n",
      "[ep325] episode_rewards for agent 9 : 64.0359958698973\n",
      "[ep325] mean episode reward : 23.2041981597431\n",
      "episode 326 done\n",
      "[ep326] episode_rewards for agent 0 : 6.113999154418707\n",
      "[ep326] episode_rewards for agent 1 : -52.29999709315598\n",
      "[ep326] episode_rewards for agent 2 : -57.80799659900367\n",
      "[ep326] episode_rewards for agent 3 : -5.888000420294702\n",
      "[ep326] episode_rewards for agent 4 : 83.38799472432584\n",
      "[ep326] episode_rewards for agent 5 : 137.8759913109243\n",
      "[ep326] episode_rewards for agent 6 : 12.175998433493078\n",
      "[ep326] episode_rewards for agent 7 : -37.495998442173004\n",
      "[ep326] episode_rewards for agent 8 : -22.807999794371426\n",
      "[ep326] episode_rewards for agent 9 : 41.43199695367366\n",
      "[ep326] mean episode reward : 10.46859882278368\n",
      "episode 327 done\n",
      "[ep327] episode_rewards for agent 0 : 13.10199858713895\n",
      "[ep327] episode_rewards for agent 1 : -56.63999674003571\n",
      "[ep327] episode_rewards for agent 2 : -52.01599710714072\n",
      "[ep327] episode_rewards for agent 3 : -6.30800062417984\n",
      "[ep327] episode_rewards for agent 4 : 67.72799547947943\n",
      "[ep327] episode_rewards for agent 5 : -23.83599976450205\n",
      "[ep327] episode_rewards for agent 6 : 1.691999288275838\n",
      "[ep327] episode_rewards for agent 7 : -30.31999916397035\n",
      "[ep327] episode_rewards for agent 8 : -51.83199716452509\n",
      "[ep327] episode_rewards for agent 9 : 75.68399498611689\n",
      "[ep327] mean episode reward : -6.274600222334266\n",
      "episode 328 done\n",
      "[ep328] episode_rewards for agent 0 : 11.245998780243099\n",
      "[ep328] episode_rewards for agent 1 : -50.815997229889035\n",
      "[ep328] episode_rewards for agent 2 : -58.98799652419984\n",
      "[ep328] episode_rewards for agent 3 : -18.31599991954863\n",
      "[ep328] episode_rewards for agent 4 : 205.7599875247106\n",
      "[ep328] episode_rewards for agent 5 : 83.30799463577569\n",
      "[ep328] episode_rewards for agent 6 : -7.340000283904374\n",
      "[ep328] episode_rewards for agent 7 : -46.291997647844255\n",
      "[ep328] episode_rewards for agent 8 : -48.05599741637707\n",
      "[ep328] episode_rewards for agent 9 : 175.92398912645876\n",
      "[ep328] mean episode reward : 24.642998104542492\n",
      "episode 329 done\n",
      "[ep329] episode_rewards for agent 0 : -34.24199809320271\n",
      "[ep329] episode_rewards for agent 1 : -59.531996469944715\n",
      "[ep329] episode_rewards for agent 2 : -51.011997336521745\n",
      "[ep329] episode_rewards for agent 3 : -38.75199804734439\n",
      "[ep329] episode_rewards for agent 4 : -58.4879965223372\n",
      "[ep329] episode_rewards for agent 5 : 94.13599386997521\n",
      "[ep329] episode_rewards for agent 6 : -11.444000201299787\n",
      "[ep329] episode_rewards for agent 7 : -39.33599823247641\n",
      "[ep329] episode_rewards for agent 8 : -33.10799877066165\n",
      "[ep329] episode_rewards for agent 9 : 83.05599462706596\n",
      "[ep329] mean episode reward : -14.872199517674744\n",
      "episode 330 done\n",
      "[ep330] episode_rewards for agent 0 : -27.657998808659613\n",
      "[ep330] episode_rewards for agent 1 : -54.7879969086498\n",
      "[ep330] episode_rewards for agent 2 : -54.9359968919307\n",
      "[ep330] episode_rewards for agent 3 : -30.275998982600868\n",
      "[ep330] episode_rewards for agent 4 : 29.06399734504521\n",
      "[ep330] episode_rewards for agent 5 : 51.21599634364247\n",
      "[ep330] episode_rewards for agent 6 : -41.943997878581285\n",
      "[ep330] episode_rewards for agent 7 : -47.59599752910435\n",
      "[ep330] episode_rewards for agent 8 : -24.21999971754849\n",
      "[ep330] episode_rewards for agent 9 : 70.73999531101435\n",
      "[ep330] mean episode reward : -13.039799771737307\n",
      "episode 331 done\n",
      "[ep331] episode_rewards for agent 0 : 53.7419962529093\n",
      "[ep331] episode_rewards for agent 1 : -54.107996822334826\n",
      "[ep331] episode_rewards for agent 2 : -55.03599680773914\n",
      "[ep331] episode_rewards for agent 3 : 0.6959991008043289\n",
      "[ep331] episode_rewards for agent 4 : 146.3839909909293\n",
      "[ep331] episode_rewards for agent 5 : 22.315997731871903\n",
      "[ep331] episode_rewards for agent 6 : 2.9159990334883332\n",
      "[ep331] episode_rewards for agent 7 : -32.979998922906816\n",
      "[ep331] episode_rewards for agent 8 : -51.51999716088176\n",
      "[ep331] episode_rewards for agent 9 : -9.511999791488051\n",
      "[ep331] mean episode reward : 2.2897993604652584\n",
      "episode 332 done\n",
      "[ep332] episode_rewards for agent 0 : 96.62199388071895\n",
      "[ep332] episode_rewards for agent 1 : -54.18399692233652\n",
      "[ep332] episode_rewards for agent 2 : -46.683997618965805\n",
      "[ep332] episode_rewards for agent 3 : -12.991999972611666\n",
      "[ep332] episode_rewards for agent 4 : 20.15199844352901\n",
      "[ep332] episode_rewards for agent 5 : 54.783995910547674\n",
      "[ep332] episode_rewards for agent 6 : -31.855998841114342\n",
      "[ep332] episode_rewards for agent 7 : -42.19199799094349\n",
      "[ep332] episode_rewards for agent 8 : -48.29599747713655\n",
      "[ep332] episode_rewards for agent 9 : 76.14799504354596\n",
      "[ep332] mean episode reward : 1.1501994455233215\n",
      "episode 333 done\n",
      "[ep333] episode_rewards for agent 0 : 21.113998373039067\n",
      "[ep333] episode_rewards for agent 1 : -58.603996557183564\n",
      "[ep333] episode_rewards for agent 2 : -45.775997624732554\n",
      "[ep333] episode_rewards for agent 3 : -31.95599893387407\n",
      "[ep333] episode_rewards for agent 4 : 29.49999796692282\n",
      "[ep333] episode_rewards for agent 5 : 55.499995943158865\n",
      "[ep333] episode_rewards for agent 6 : -20.08000003360212\n",
      "[ep333] episode_rewards for agent 7 : -44.95999774988741\n",
      "[ep333] episode_rewards for agent 8 : -31.619998758658767\n",
      "[ep333] episode_rewards for agent 9 : 70.97199531830847\n",
      "[ep333] mean episode reward : -5.591000205650926\n",
      "episode 334 done\n",
      "[ep334] episode_rewards for agent 0 : 65.38999566342682\n",
      "[ep334] episode_rewards for agent 1 : -55.73599672410637\n",
      "[ep334] episode_rewards for agent 2 : -57.15999661758542\n",
      "[ep334] episode_rewards for agent 3 : -22.619999405927956\n",
      "[ep334] episode_rewards for agent 4 : 148.3919906951487\n",
      "[ep334] episode_rewards for agent 5 : 117.29599255882204\n",
      "[ep334] episode_rewards for agent 6 : 10.687998928129673\n",
      "[ep334] episode_rewards for agent 7 : -50.359997311607\n",
      "[ep334] episode_rewards for agent 8 : -53.43999698385596\n",
      "[ep334] episode_rewards for agent 9 : 66.61199570354074\n",
      "[ep334] mean episode reward : 16.906198650598526\n",
      "episode 335 done\n",
      "[ep335] episode_rewards for agent 0 : -4.029999991878867\n",
      "[ep335] episode_rewards for agent 1 : -47.21599743980914\n",
      "[ep335] episode_rewards for agent 2 : -46.019997701980174\n",
      "[ep335] episode_rewards for agent 3 : -0.6840005535632372\n",
      "[ep335] episode_rewards for agent 4 : 102.66799361165613\n",
      "[ep335] episode_rewards for agent 5 : 33.0959973949939\n",
      "[ep335] episode_rewards for agent 6 : -16.9799996772781\n",
      "[ep335] episode_rewards for agent 7 : -30.435999090783298\n",
      "[ep335] episode_rewards for agent 8 : -52.291997040621936\n",
      "[ep335] episode_rewards for agent 9 : 15.043998818844557\n",
      "[ep335] mean episode reward : -4.685000167042017\n",
      "episode 336 done\n",
      "[ep336] episode_rewards for agent 0 : 175.4259892757982\n",
      "[ep336] episode_rewards for agent 1 : -58.70399651210755\n",
      "[ep336] episode_rewards for agent 2 : -53.12799706775695\n",
      "[ep336] episode_rewards for agent 3 : -8.100000211037695\n",
      "[ep336] episode_rewards for agent 4 : 71.5639950344339\n",
      "[ep336] episode_rewards for agent 5 : 53.01199628226459\n",
      "[ep336] episode_rewards for agent 6 : -37.07199837267399\n",
      "[ep336] episode_rewards for agent 7 : -37.75199826899916\n",
      "[ep336] episode_rewards for agent 8 : -31.235999048687518\n",
      "[ep336] episode_rewards for agent 9 : 113.5359927257523\n",
      "[ep336] mean episode reward : 18.754598383698614\n",
      "episode 337 done\n",
      "[ep337] episode_rewards for agent 0 : 71.48599534109235\n",
      "[ep337] episode_rewards for agent 1 : -58.355996581725776\n",
      "[ep337] episode_rewards for agent 2 : -59.867996437475085\n",
      "[ep337] episode_rewards for agent 3 : -37.179998389445245\n",
      "[ep337] episode_rewards for agent 4 : 73.78799524903297\n",
      "[ep337] episode_rewards for agent 5 : 74.23599490895867\n",
      "[ep337] episode_rewards for agent 6 : -20.69199938699603\n",
      "[ep337] episode_rewards for agent 7 : -33.64799863751978\n",
      "[ep337] episode_rewards for agent 8 : -43.059997871518135\n",
      "[ep337] episode_rewards for agent 9 : 15.9439985640347\n",
      "[ep337] mean episode reward : -1.7350003241561354\n",
      "episode 338 done\n",
      "[ep338] episode_rewards for agent 0 : 47.593996627256274\n",
      "[ep338] episode_rewards for agent 1 : -56.60399667173624\n",
      "[ep338] episode_rewards for agent 2 : -53.20799705944955\n",
      "[ep338] episode_rewards for agent 3 : -24.28799928445369\n",
      "[ep338] episode_rewards for agent 4 : -10.63999987859279\n",
      "[ep338] episode_rewards for agent 5 : 119.41999241523445\n",
      "[ep338] episode_rewards for agent 6 : 50.19999625813216\n",
      "[ep338] episode_rewards for agent 7 : -45.81599771324545\n",
      "[ep338] episode_rewards for agent 8 : -45.255997764877975\n",
      "[ep338] episode_rewards for agent 9 : 88.76399433240294\n",
      "[ep338] mean episode reward : 7.016599126067012\n",
      "episode 339 done\n",
      "[ep339] episode_rewards for agent 0 : 88.20599421393126\n",
      "[ep339] episode_rewards for agent 1 : -53.335996905341744\n",
      "[ep339] episode_rewards for agent 2 : -51.139997142367065\n",
      "[ep339] episode_rewards for agent 3 : -12.235999776981771\n",
      "[ep339] episode_rewards for agent 4 : 83.89599456824362\n",
      "[ep339] episode_rewards for agent 5 : 43.611996714025736\n",
      "[ep339] episode_rewards for agent 6 : -18.783999813720584\n",
      "[ep339] episode_rewards for agent 7 : -26.88799914624542\n",
      "[ep339] episode_rewards for agent 8 : -35.13599850796163\n",
      "[ep339] episode_rewards for agent 9 : 105.17199328448623\n",
      "[ep339] mean episode reward : 12.336598748806864\n",
      "episode 340 done\n",
      "[ep340] episode_rewards for agent 0 : 54.701996291056275\n",
      "[ep340] episode_rewards for agent 1 : -50.575997123494744\n",
      "[ep340] episode_rewards for agent 2 : -54.13199690915644\n",
      "[ep340] episode_rewards for agent 3 : -4.464000363834202\n",
      "[ep340] episode_rewards for agent 4 : 45.79599707853049\n",
      "[ep340] episode_rewards for agent 5 : 94.93599367700517\n",
      "[ep340] episode_rewards for agent 6 : 14.303998441435397\n",
      "[ep340] episode_rewards for agent 7 : -39.3799981912598\n",
      "[ep340] episode_rewards for agent 8 : -43.23999763280153\n",
      "[ep340] episode_rewards for agent 9 : 130.0439918478951\n",
      "[ep340] mean episode reward : 14.79899871153757\n",
      "episode 341 done\n",
      "[ep341] episode_rewards for agent 0 : 110.06999283842742\n",
      "[ep341] episode_rewards for agent 1 : -58.699996531009674\n",
      "[ep341] episode_rewards for agent 2 : -52.12399713974446\n",
      "[ep341] episode_rewards for agent 3 : -30.955998621881008\n",
      "[ep341] episode_rewards for agent 4 : 140.37599125225097\n",
      "[ep341] episode_rewards for agent 5 : 105.49999298807234\n",
      "[ep341] episode_rewards for agent 6 : -23.811999469064176\n",
      "[ep341] episode_rewards for agent 7 : -39.771998316049576\n",
      "[ep341] episode_rewards for agent 8 : -48.647997356019914\n",
      "[ep341] episode_rewards for agent 9 : 33.79199749883264\n",
      "[ep341] mean episode reward : 13.572598714381456\n",
      "episode 342 done\n",
      "[ep342] episode_rewards for agent 0 : 90.04199389088899\n",
      "[ep342] episode_rewards for agent 1 : -54.20399691350758\n",
      "[ep342] episode_rewards for agent 2 : -57.851996646262705\n",
      "[ep342] episode_rewards for agent 3 : 23.643998007290065\n",
      "[ep342] episode_rewards for agent 4 : 97.37599378079176\n",
      "[ep342] episode_rewards for agent 5 : 116.05999247729778\n",
      "[ep342] episode_rewards for agent 6 : -4.052000478841364\n",
      "[ep342] episode_rewards for agent 7 : -50.211997140198946\n",
      "[ep342] episode_rewards for agent 8 : -23.383999714627862\n",
      "[ep342] episode_rewards for agent 9 : 100.07999348361045\n",
      "[ep342] mean episode reward : 23.74979807464406\n",
      "episode 343 done\n",
      "[ep343] episode_rewards for agent 0 : 40.0059971883893\n",
      "[ep343] episode_rewards for agent 1 : -52.87999693676829\n",
      "[ep343] episode_rewards for agent 2 : -58.85599652770907\n",
      "[ep343] episode_rewards for agent 3 : 7.847999040968716\n",
      "[ep343] episode_rewards for agent 4 : 33.667997284792364\n",
      "[ep343] episode_rewards for agent 5 : 134.9159914208576\n",
      "[ep343] episode_rewards for agent 6 : -1.6320006800815463\n",
      "[ep343] episode_rewards for agent 7 : -48.54799750633538\n",
      "[ep343] episode_rewards for agent 8 : -55.991996818222106\n",
      "[ep343] episode_rewards for agent 9 : 102.45599347166717\n",
      "[ep343] mean episode reward : 10.098598993755877\n",
      "episode 344 done\n",
      "[ep344] episode_rewards for agent 0 : 53.90999632142484\n",
      "[ep344] episode_rewards for agent 1 : -52.39999708533287\n",
      "[ep344] episode_rewards for agent 2 : -59.71599644422531\n",
      "[ep344] episode_rewards for agent 3 : -11.164000275544822\n",
      "[ep344] episode_rewards for agent 4 : 45.091996939852834\n",
      "[ep344] episode_rewards for agent 5 : 55.16399593278766\n",
      "[ep344] episode_rewards for agent 6 : -12.38399971742183\n",
      "[ep344] episode_rewards for agent 7 : -27.167999069206417\n",
      "[ep344] episode_rewards for agent 8 : -48.30399725865573\n",
      "[ep344] episode_rewards for agent 9 : 52.73199644032866\n",
      "[ep344] mean episode reward : -0.4238004215992987\n",
      "episode 345 done\n",
      "[ep345] episode_rewards for agent 0 : 37.2059974251315\n",
      "[ep345] episode_rewards for agent 1 : -56.439996710047126\n",
      "[ep345] episode_rewards for agent 2 : -57.54399661999196\n",
      "[ep345] episode_rewards for agent 3 : 9.155998724512756\n",
      "[ep345] episode_rewards for agent 4 : 138.83599141798913\n",
      "[ep345] episode_rewards for agent 5 : 88.36799406073987\n",
      "[ep345] episode_rewards for agent 6 : 12.539998249150813\n",
      "[ep345] episode_rewards for agent 7 : -52.45199710596353\n",
      "[ep345] episode_rewards for agent 8 : -52.167997100390494\n",
      "[ep345] episode_rewards for agent 9 : 65.06399541627616\n",
      "[ep345] mean episode reward : 13.256598775740713\n",
      "episode 346 done\n",
      "[ep346] episode_rewards for agent 0 : 11.657998715527356\n",
      "[ep346] episode_rewards for agent 1 : -56.271996688097715\n",
      "[ep346] episode_rewards for agent 2 : -32.35199900530279\n",
      "[ep346] episode_rewards for agent 3 : -15.583999626338482\n",
      "[ep346] episode_rewards for agent 4 : 75.00799500849098\n",
      "[ep346] episode_rewards for agent 5 : 69.54799524322152\n",
      "[ep346] episode_rewards for agent 6 : 7.6199988862499595\n",
      "[ep346] episode_rewards for agent 7 : -43.371997960843146\n",
      "[ep346] episode_rewards for agent 8 : -46.89999745413661\n",
      "[ep346] episode_rewards for agent 9 : 83.33999468386173\n",
      "[ep346] mean episode reward : 5.269399180263281\n",
      "episode 347 done\n",
      "[ep347] episode_rewards for agent 0 : 54.97399632912129\n",
      "[ep347] episode_rewards for agent 1 : -55.76799676474184\n",
      "[ep347] episode_rewards for agent 2 : -35.66799861937761\n",
      "[ep347] episode_rewards for agent 3 : -19.66399942431599\n",
      "[ep347] episode_rewards for agent 4 : 42.64399717282504\n",
      "[ep347] episode_rewards for agent 5 : 27.72799750044942\n",
      "[ep347] episode_rewards for agent 6 : -1.728000801987946\n",
      "[ep347] episode_rewards for agent 7 : -53.84799693804234\n",
      "[ep347] episode_rewards for agent 8 : -35.991998594254255\n",
      "[ep347] episode_rewards for agent 9 : 32.88799746707082\n",
      "[ep347] mean episode reward : -4.443400267325342\n",
      "episode 348 done\n",
      "[ep348] episode_rewards for agent 0 : 80.13399482611567\n",
      "[ep348] episode_rewards for agent 1 : -48.6719972724095\n",
      "[ep348] episode_rewards for agent 2 : -47.7199973994866\n",
      "[ep348] episode_rewards for agent 3 : -14.335999691858888\n",
      "[ep348] episode_rewards for agent 4 : 88.0599944172427\n",
      "[ep348] episode_rewards for agent 5 : 115.92399253696203\n",
      "[ep348] episode_rewards for agent 6 : 14.451998459175229\n",
      "[ep348] episode_rewards for agent 7 : -51.78399713523686\n",
      "[ep348] episode_rewards for agent 8 : -29.79599923081696\n",
      "[ep348] episode_rewards for agent 9 : 13.459998803213239\n",
      "[ep348] mean episode reward : 11.972198831290006\n",
      "episode 349 done\n",
      "[ep349] episode_rewards for agent 0 : 72.50999506097287\n",
      "[ep349] episode_rewards for agent 1 : -56.283996735699475\n",
      "[ep349] episode_rewards for agent 2 : -46.727997611276805\n",
      "[ep349] episode_rewards for agent 3 : -19.623999375849962\n",
      "[ep349] episode_rewards for agent 4 : 42.731997082941234\n",
      "[ep349] episode_rewards for agent 5 : 54.091996188275516\n",
      "[ep349] episode_rewards for agent 6 : 7.575998823158443\n",
      "[ep349] episode_rewards for agent 7 : -51.35599724017084\n",
      "[ep349] episode_rewards for agent 8 : -34.0999985197559\n",
      "[ep349] episode_rewards for agent 9 : 105.47199328243732\n",
      "[ep349] mean episode reward : 7.428999095503241\n",
      "episode 350 done\n",
      "[ep350] episode_rewards for agent 0 : 8.697999150492251\n",
      "[ep350] episode_rewards for agent 1 : -59.93199643213302\n",
      "[ep350] episode_rewards for agent 2 : -54.16399689856917\n",
      "[ep350] episode_rewards for agent 3 : -28.619999228976667\n",
      "[ep350] episode_rewards for agent 4 : 20.379998308606446\n",
      "[ep350] episode_rewards for agent 5 : 118.09199243970215\n",
      "[ep350] episode_rewards for agent 6 : 11.04399861767888\n",
      "[ep350] episode_rewards for agent 7 : -53.523997047916055\n",
      "[ep350] episode_rewards for agent 8 : -54.95599685702473\n",
      "[ep350] episode_rewards for agent 9 : 120.1399925192818\n",
      "[ep350] mean episode reward : 2.7157994571141897\n",
      "episode 351 done\n",
      "[ep351] episode_rewards for agent 0 : 66.76599567104131\n",
      "[ep351] episode_rewards for agent 1 : -53.57599700149149\n",
      "[ep351] episode_rewards for agent 2 : -48.019997427240014\n",
      "[ep351] episode_rewards for agent 3 : -22.655999287962914\n",
      "[ep351] episode_rewards for agent 4 : 50.91999657638371\n",
      "[ep351] episode_rewards for agent 5 : 24.647997610270977\n",
      "[ep351] episode_rewards for agent 6 : -4.800000447779894\n",
      "[ep351] episode_rewards for agent 7 : -40.491998206824064\n",
      "[ep351] episode_rewards for agent 8 : -56.879996640607715\n",
      "[ep351] episode_rewards for agent 9 : 94.97199403401464\n",
      "[ep351] mean episode reward : 1.088199487980455\n",
      "episode 352 done\n",
      "[ep352] episode_rewards for agent 0 : 97.2339937677607\n",
      "[ep352] episode_rewards for agent 1 : -49.171997275203466\n",
      "[ep352] episode_rewards for agent 2 : -43.471997941844165\n",
      "[ep352] episode_rewards for agent 3 : -14.59599981084466\n",
      "[ep352] episode_rewards for agent 4 : -25.035998657345772\n",
      "[ep352] episode_rewards for agent 5 : 93.17599381692708\n",
      "[ep352] episode_rewards for agent 6 : -0.3160008583217859\n",
      "[ep352] episode_rewards for agent 7 : -39.38799825310707\n",
      "[ep352] episode_rewards for agent 8 : -24.767999263480306\n",
      "[ep352] episode_rewards for agent 9 : 28.595997764728963\n",
      "[ep352] mean episode reward : 2.225799328926951\n",
      "episode 353 done\n",
      "[ep353] episode_rewards for agent 0 : 61.58599591162056\n",
      "[ep353] episode_rewards for agent 1 : -58.407996566966176\n",
      "[ep353] episode_rewards for agent 2 : -59.17999650165439\n",
      "[ep353] episode_rewards for agent 3 : -14.963999663479626\n",
      "[ep353] episode_rewards for agent 4 : 34.68799747340381\n",
      "[ep353] episode_rewards for agent 5 : 47.00799637567252\n",
      "[ep353] episode_rewards for agent 6 : -10.20800036098808\n",
      "[ep353] episode_rewards for agent 7 : -31.359998944215477\n",
      "[ep353] episode_rewards for agent 8 : -32.379998898133636\n",
      "[ep353] episode_rewards for agent 9 : 61.80799575243145\n",
      "[ep353] mean episode reward : -0.1410005422309041\n",
      "episode 354 done\n",
      "[ep354] episode_rewards for agent 0 : 61.64999577496201\n",
      "[ep354] episode_rewards for agent 1 : -57.08799665980041\n",
      "[ep354] episode_rewards for agent 2 : -47.291997427120805\n",
      "[ep354] episode_rewards for agent 3 : 17.179998503997922\n",
      "[ep354] episode_rewards for agent 4 : 40.96399711817503\n",
      "[ep354] episode_rewards for agent 5 : 78.58399468660355\n",
      "[ep354] episode_rewards for agent 6 : 25.999997718259692\n",
      "[ep354] episode_rewards for agent 7 : -19.615999691188335\n",
      "[ep354] episode_rewards for agent 8 : -33.74399879388511\n",
      "[ep354] episode_rewards for agent 9 : 39.99199714604765\n",
      "[ep354] mean episode reward : 10.66299883760512\n",
      "episode 355 done\n",
      "[ep355] episode_rewards for agent 0 : 39.50199730601162\n",
      "[ep355] episode_rewards for agent 1 : -50.819997229613364\n",
      "[ep355] episode_rewards for agent 2 : -51.095997153781354\n",
      "[ep355] episode_rewards for agent 3 : -22.54399931617081\n",
      "[ep355] episode_rewards for agent 4 : 11.283998961560428\n",
      "[ep355] episode_rewards for agent 5 : 135.65599136799574\n",
      "[ep355] episode_rewards for agent 6 : -21.95199988503009\n",
      "[ep355] episode_rewards for agent 7 : -33.42399860173464\n",
      "[ep355] episode_rewards for agent 8 : -44.835997542366385\n",
      "[ep355] episode_rewards for agent 9 : -6.524000217206776\n",
      "[ep355] mean episode reward : -4.475400231033563\n",
      "episode 356 done\n",
      "[ep356] episode_rewards for agent 0 : 53.4139963472262\n",
      "[ep356] episode_rewards for agent 1 : -52.935997039079666\n",
      "[ep356] episode_rewards for agent 2 : -54.559996887110174\n",
      "[ep356] episode_rewards for agent 3 : -33.21999816317111\n",
      "[ep356] episode_rewards for agent 4 : 40.21599717903882\n",
      "[ep356] episode_rewards for agent 5 : 127.51999201718718\n",
      "[ep356] episode_rewards for agent 6 : -4.604000587947667\n",
      "[ep356] episode_rewards for agent 7 : -49.131997304968536\n",
      "[ep356] episode_rewards for agent 8 : -58.45599656458944\n",
      "[ep356] episode_rewards for agent 9 : 70.11999548226595\n",
      "[ep356] mean episode reward : 3.8361994478851558\n",
      "episode 357 done\n",
      "[ep357] episode_rewards for agent 0 : -9.181999796070158\n",
      "[ep357] episode_rewards for agent 1 : -56.30399676039815\n",
      "[ep357] episode_rewards for agent 2 : -48.81999736279249\n",
      "[ep357] episode_rewards for agent 3 : 7.6119988560676575\n",
      "[ep357] episode_rewards for agent 4 : 61.99599579721689\n",
      "[ep357] episode_rewards for agent 5 : 116.83999256882817\n",
      "[ep357] episode_rewards for agent 6 : 2.1879992047324777\n",
      "[ep357] episode_rewards for agent 7 : -42.65599792636931\n",
      "[ep357] episode_rewards for agent 8 : -30.395999162457883\n",
      "[ep357] episode_rewards for agent 9 : 82.2799947373569\n",
      "[ep357] mean episode reward : 8.35579901561141\n",
      "episode 358 done\n",
      "[ep358] episode_rewards for agent 0 : 155.04599030595273\n",
      "[ep358] episode_rewards for agent 1 : -52.73199690878391\n",
      "[ep358] episode_rewards for agent 2 : -53.14399706199765\n",
      "[ep358] episode_rewards for agent 3 : -14.615999574773014\n",
      "[ep358] episode_rewards for agent 4 : 47.37999673746526\n",
      "[ep358] episode_rewards for agent 5 : 38.01599698513746\n",
      "[ep358] episode_rewards for agent 6 : -21.671999217942357\n",
      "[ep358] episode_rewards for agent 7 : -45.771997667849064\n",
      "[ep358] episode_rewards for agent 8 : -36.875998102128506\n",
      "[ep358] episode_rewards for agent 9 : 89.31999431643635\n",
      "[ep358] mean episode reward : 10.49499898115173\n",
      "episode 359 done\n",
      "[ep359] episode_rewards for agent 0 : 85.65799440816045\n",
      "[ep359] episode_rewards for agent 1 : -52.887997013516724\n",
      "[ep359] episode_rewards for agent 2 : -46.171997502446175\n",
      "[ep359] episode_rewards for agent 3 : -38.1599979409948\n",
      "[ep359] episode_rewards for agent 4 : 86.89999446645379\n",
      "[ep359] episode_rewards for agent 5 : 54.90799619909376\n",
      "[ep359] episode_rewards for agent 6 : 3.1519991094246507\n",
      "[ep359] episode_rewards for agent 7 : -43.37999792583287\n",
      "[ep359] episode_rewards for agent 8 : -42.94799791555852\n",
      "[ep359] episode_rewards for agent 9 : 39.4919973872602\n",
      "[ep359] mean episode reward : 4.6561993272043765\n",
      "episode 360 done\n",
      "[ep360] episode_rewards for agent 0 : 88.16999430861324\n",
      "[ep360] episode_rewards for agent 1 : -54.831996850669384\n",
      "[ep360] episode_rewards for agent 2 : -56.6759967347607\n",
      "[ep360] episode_rewards for agent 3 : 4.939998990856111\n",
      "[ep360] episode_rewards for agent 4 : 28.607997748069465\n",
      "[ep360] episode_rewards for agent 5 : 126.85999204032123\n",
      "[ep360] episode_rewards for agent 6 : -41.5319978389889\n",
      "[ep360] episode_rewards for agent 7 : -54.30399692431092\n",
      "[ep360] episode_rewards for agent 8 : -40.851997908204794\n",
      "[ep360] episode_rewards for agent 9 : 169.85198949091136\n",
      "[ep360] mean episode reward : 17.02339863218367\n",
      "episode 361 done\n",
      "[ep361] episode_rewards for agent 0 : 28.637997827492654\n",
      "[ep361] episode_rewards for agent 1 : -53.095996959134936\n",
      "[ep361] episode_rewards for agent 2 : -48.97599715273827\n",
      "[ep361] episode_rewards for agent 3 : -22.355999338440597\n",
      "[ep361] episode_rewards for agent 4 : 49.38399657700211\n",
      "[ep361] episode_rewards for agent 5 : 40.81199671514332\n",
      "[ep361] episode_rewards for agent 6 : 0.5399993974715471\n",
      "[ep361] episode_rewards for agent 7 : -21.88399914186448\n",
      "[ep361] episode_rewards for agent 8 : -46.667997520416975\n",
      "[ep361] episode_rewards for agent 9 : 34.767997559159994\n",
      "[ep361] mean episode reward : -3.883800203632563\n",
      "episode 362 done\n",
      "[ep362] episode_rewards for agent 0 : 62.877995749004185\n",
      "[ep362] episode_rewards for agent 1 : -54.675996898673475\n",
      "[ep362] episode_rewards for agent 2 : -51.19599718414247\n",
      "[ep362] episode_rewards for agent 3 : -8.15200003515929\n",
      "[ep362] episode_rewards for agent 4 : 1.279999516904354\n",
      "[ep362] episode_rewards for agent 5 : 126.77599207032472\n",
      "[ep362] episode_rewards for agent 6 : -50.28799727372825\n",
      "[ep362] episode_rewards for agent 7 : -22.959999145939946\n",
      "[ep362] episode_rewards for agent 8 : -41.511997991241515\n",
      "[ep362] episode_rewards for agent 9 : 46.06799681298435\n",
      "[ep362] mean episode reward : 0.8217995620332659\n",
      "episode 363 done\n",
      "[ep363] episode_rewards for agent 0 : 74.99399514775723\n",
      "[ep363] episode_rewards for agent 1 : -56.091996680013835\n",
      "[ep363] episode_rewards for agent 2 : -53.71199702937156\n",
      "[ep363] episode_rewards for agent 3 : -26.995998980477452\n",
      "[ep363] episode_rewards for agent 4 : 66.66399564407766\n",
      "[ep363] episode_rewards for agent 5 : 76.1399950273335\n",
      "[ep363] episode_rewards for agent 6 : -32.03199829440564\n",
      "[ep363] episode_rewards for agent 7 : -39.291998313739896\n",
      "[ep363] episode_rewards for agent 8 : -51.259997201152146\n",
      "[ep363] episode_rewards for agent 9 : 14.743998727761209\n",
      "[ep363] mean episode reward : -2.684200195223093\n",
      "episode 364 done\n",
      "[ep364] episode_rewards for agent 0 : 77.4459951063618\n",
      "[ep364] episode_rewards for agent 1 : -55.383996781893075\n",
      "[ep364] episode_rewards for agent 2 : -44.915997884236276\n",
      "[ep364] episode_rewards for agent 3 : -10.944000040180981\n",
      "[ep364] episode_rewards for agent 4 : 13.419998686760664\n",
      "[ep364] episode_rewards for agent 5 : 20.19999870378524\n",
      "[ep364] episode_rewards for agent 6 : -5.319999980740249\n",
      "[ep364] episode_rewards for agent 7 : -44.523997873067856\n",
      "[ep364] episode_rewards for agent 8 : -55.13199682533741\n",
      "[ep364] episode_rewards for agent 9 : 39.459997163154185\n",
      "[ep364] mean episode reward : -6.5693999725393954\n",
      "episode 365 done\n",
      "[ep365] episode_rewards for agent 0 : 45.22599708940834\n",
      "[ep365] episode_rewards for agent 1 : -56.15199671778828\n",
      "[ep365] episode_rewards for agent 2 : -53.879996817559004\n",
      "[ep365] episode_rewards for agent 3 : -11.227999740280211\n",
      "[ep365] episode_rewards for agent 4 : 36.39999744575471\n",
      "[ep365] episode_rewards for agent 5 : 126.89599194098264\n",
      "[ep365] episode_rewards for agent 6 : -27.79599896725267\n",
      "[ep365] episode_rewards for agent 7 : -27.435999269597232\n",
      "[ep365] episode_rewards for agent 8 : -25.759999502450228\n",
      "[ep365] episode_rewards for agent 9 : 86.83599436562508\n",
      "[ep365] mean episode reward : 9.310598982684315\n",
      "episode 366 done\n",
      "[ep366] episode_rewards for agent 0 : 75.26999485958368\n",
      "[ep366] episode_rewards for agent 1 : -41.60799810383469\n",
      "[ep366] episode_rewards for agent 2 : -55.48799677379429\n",
      "[ep366] episode_rewards for agent 3 : -7.724000122398138\n",
      "[ep366] episode_rewards for agent 4 : 27.567997778765857\n",
      "[ep366] episode_rewards for agent 5 : 68.69199525751173\n",
      "[ep366] episode_rewards for agent 6 : -19.031999645754695\n",
      "[ep366] episode_rewards for agent 7 : -28.77999867592007\n",
      "[ep366] episode_rewards for agent 8 : -46.52799760643393\n",
      "[ep366] episode_rewards for agent 9 : 42.783996815793216\n",
      "[ep366] mean episode reward : 1.515399378351867\n",
      "episode 367 done\n",
      "[ep367] episode_rewards for agent 0 : 67.98999551124871\n",
      "[ep367] episode_rewards for agent 1 : -57.0079966718331\n",
      "[ep367] episode_rewards for agent 2 : -57.34399666637182\n",
      "[ep367] episode_rewards for agent 3 : -23.151999256573617\n",
      "[ep367] episode_rewards for agent 4 : 22.151998086832464\n",
      "[ep367] episode_rewards for agent 5 : 109.82799303717911\n",
      "[ep367] episode_rewards for agent 6 : -23.319999712519348\n",
      "[ep367] episode_rewards for agent 7 : -44.95599773991853\n",
      "[ep367] episode_rewards for agent 8 : -49.183997315354645\n",
      "[ep367] episode_rewards for agent 9 : 53.85999632906169\n",
      "[ep367] mean episode reward : -0.11340043982490897\n",
      "episode 368 done\n",
      "[ep368] episode_rewards for agent 0 : 51.56599650066346\n",
      "[ep368] episode_rewards for agent 1 : -56.06399670056999\n",
      "[ep368] episode_rewards for agent 2 : -56.71599672921002\n",
      "[ep368] episode_rewards for agent 3 : -5.132000335492194\n",
      "[ep368] episode_rewards for agent 4 : 73.04399526398629\n",
      "[ep368] episode_rewards for agent 5 : 142.38799118995667\n",
      "[ep368] episode_rewards for agent 6 : 6.099998753517866\n",
      "[ep368] episode_rewards for agent 7 : -52.995997100137174\n",
      "[ep368] episode_rewards for agent 8 : -40.163998211734\n",
      "[ep368] episode_rewards for agent 9 : 49.05599652323872\n",
      "[ep368] mean episode reward : 11.108198915421962\n",
      "episode 369 done\n",
      "[ep369] episode_rewards for agent 0 : 64.67799566499889\n",
      "[ep369] episode_rewards for agent 1 : -48.49999725352973\n",
      "[ep369] episode_rewards for agent 2 : -57.98399658408016\n",
      "[ep369] episode_rewards for agent 3 : -28.143999286927283\n",
      "[ep369] episode_rewards for agent 4 : 93.29599401913583\n",
      "[ep369] episode_rewards for agent 5 : 124.44799190480262\n",
      "[ep369] episode_rewards for agent 6 : 76.33599455840886\n",
      "[ep369] episode_rewards for agent 7 : -50.85999724268913\n",
      "[ep369] episode_rewards for agent 8 : -52.94399703480303\n",
      "[ep369] episode_rewards for agent 9 : 43.47599698416889\n",
      "[ep369] mean episode reward : 16.380198572948576\n",
      "episode 370 done\n",
      "[ep370] episode_rewards for agent 0 : 36.809997339732945\n",
      "[ep370] episode_rewards for agent 1 : -56.3039967129007\n",
      "[ep370] episode_rewards for agent 2 : -53.77599694393575\n",
      "[ep370] episode_rewards for agent 3 : -19.15999942831695\n",
      "[ep370] episode_rewards for agent 4 : 52.90399631019682\n",
      "[ep370] episode_rewards for agent 5 : 31.111997421830893\n",
      "[ep370] episode_rewards for agent 6 : -21.56399956345558\n",
      "[ep370] episode_rewards for agent 7 : -45.67199773713946\n",
      "[ep370] episode_rewards for agent 8 : -51.915997128002346\n",
      "[ep370] episode_rewards for agent 9 : 88.26799433026463\n",
      "[ep370] mean episode reward : -3.9298002111725507\n",
      "episode 371 done\n",
      "[ep371] episode_rewards for agent 0 : 140.58999133389443\n",
      "[ep371] episode_rewards for agent 1 : -53.61199702229351\n",
      "[ep371] episode_rewards for agent 2 : -48.70399743039161\n",
      "[ep371] episode_rewards for agent 3 : -23.57599919103086\n",
      "[ep371] episode_rewards for agent 4 : 90.11199398525059\n",
      "[ep371] episode_rewards for agent 5 : 95.10399375483394\n",
      "[ep371] episode_rewards for agent 6 : -4.072000470943749\n",
      "[ep371] episode_rewards for agent 7 : -55.799996816553175\n",
      "[ep371] episode_rewards for agent 8 : -46.92799751739949\n",
      "[ep371] episode_rewards for agent 9 : 61.723995914682746\n",
      "[ep371] mean episode reward : 15.483798654004932\n",
      "episode 372 done\n",
      "[ep372] episode_rewards for agent 0 : -6.2180000096559525\n",
      "[ep372] episode_rewards for agent 1 : -58.17199658229947\n",
      "[ep372] episode_rewards for agent 2 : -38.06799824722111\n",
      "[ep372] episode_rewards for agent 3 : -11.40799989271909\n",
      "[ep372] episode_rewards for agent 4 : 45.315996867604554\n",
      "[ep372] episode_rewards for agent 5 : 91.83999394252896\n",
      "[ep372] episode_rewards for agent 6 : -2.056000581011176\n",
      "[ep372] episode_rewards for agent 7 : -37.539998488500714\n",
      "[ep372] episode_rewards for agent 8 : -48.547997321002185\n",
      "[ep372] episode_rewards for agent 9 : 70.2079953160137\n",
      "[ep372] mean episode reward : 0.535399500373751\n",
      "episode 373 done\n",
      "[ep373] episode_rewards for agent 0 : 88.12199426162988\n",
      "[ep373] episode_rewards for agent 1 : -55.791996757499874\n",
      "[ep373] episode_rewards for agent 2 : -55.41599681880325\n",
      "[ep373] episode_rewards for agent 3 : -19.87599973101169\n",
      "[ep373] episode_rewards for agent 4 : 33.987997552379966\n",
      "[ep373] episode_rewards for agent 5 : 72.11999506689608\n",
      "[ep373] episode_rewards for agent 6 : -45.63199769239873\n",
      "[ep373] episode_rewards for agent 7 : -48.77999740932137\n",
      "[ep373] episode_rewards for agent 8 : -37.895998447202146\n",
      "[ep373] episode_rewards for agent 9 : 20.651998196728528\n",
      "[ep373] mean episode reward : -4.85100017786026\n",
      "episode 374 done\n",
      "[ep374] episode_rewards for agent 0 : 132.38999183289707\n",
      "[ep374] episode_rewards for agent 1 : -40.26399805676192\n",
      "[ep374] episode_rewards for agent 2 : -58.21199659910053\n",
      "[ep374] episode_rewards for agent 3 : -14.372000144794583\n",
      "[ep374] episode_rewards for agent 4 : 36.12799725681543\n",
      "[ep374] episode_rewards for agent 5 : 48.51999671384692\n",
      "[ep374] episode_rewards for agent 6 : 44.72799668367952\n",
      "[ep374] episode_rewards for agent 7 : -52.02799714822322\n",
      "[ep374] episode_rewards for agent 8 : -32.891998920589685\n",
      "[ep374] episode_rewards for agent 9 : 63.57199583016336\n",
      "[ep374] mean episode reward : 12.756998744793236\n",
      "episode 375 done\n",
      "[ep375] episode_rewards for agent 0 : 23.16999823320657\n",
      "[ep375] episode_rewards for agent 1 : -55.987996698357165\n",
      "[ep375] episode_rewards for agent 2 : -51.61599720828235\n",
      "[ep375] episode_rewards for agent 3 : 11.86799899302423\n",
      "[ep375] episode_rewards for agent 4 : 12.16799886804074\n",
      "[ep375] episode_rewards for agent 5 : 32.48399742692709\n",
      "[ep375] episode_rewards for agent 6 : 48.527996396645904\n",
      "[ep375] episode_rewards for agent 7 : -21.451999860815704\n",
      "[ep375] episode_rewards for agent 8 : -55.01199686340988\n",
      "[ep375] episode_rewards for agent 9 : 15.4479986326769\n",
      "[ep375] mean episode reward : -4.040200208034366\n",
      "episode 376 done\n",
      "[ep376] episode_rewards for agent 0 : 27.245998072437942\n",
      "[ep376] episode_rewards for agent 1 : -46.175997332669795\n",
      "[ep376] episode_rewards for agent 2 : -56.723996721208096\n",
      "[ep376] episode_rewards for agent 3 : -27.46799905784428\n",
      "[ep376] episode_rewards for agent 4 : -11.035999551415443\n",
      "[ep376] episode_rewards for agent 5 : 59.84399585146457\n",
      "[ep376] episode_rewards for agent 6 : -5.252000344917178\n",
      "[ep376] episode_rewards for agent 7 : -35.447998407296836\n",
      "[ep376] episode_rewards for agent 8 : -47.959997481666505\n",
      "[ep376] episode_rewards for agent 9 : 24.13599804788828\n",
      "[ep376] mean episode reward : -11.883799692522734\n",
      "episode 377 done\n",
      "[ep377] episode_rewards for agent 0 : 45.99399676732719\n",
      "[ep377] episode_rewards for agent 1 : -55.0599969048053\n",
      "[ep377] episode_rewards for agent 2 : -54.823996882885695\n",
      "[ep377] episode_rewards for agent 3 : -9.832000403665006\n",
      "[ep377] episode_rewards for agent 4 : 40.91999715194106\n",
      "[ep377] episode_rewards for agent 5 : 50.38399633113295\n",
      "[ep377] episode_rewards for agent 6 : -21.91599929239601\n",
      "[ep377] episode_rewards for agent 7 : -55.36399688664824\n",
      "[ep377] episode_rewards for agent 8 : -53.86399698071182\n",
      "[ep377] episode_rewards for agent 9 : -15.503999385982752\n",
      "[ep377] mean episode reward : -12.906599648669362\n",
      "episode 378 done\n",
      "[ep378] episode_rewards for agent 0 : 80.3499950086698\n",
      "[ep378] episode_rewards for agent 1 : -57.4319966211915\n",
      "[ep378] episode_rewards for agent 2 : -51.355997226201\n",
      "[ep378] episode_rewards for agent 3 : -17.375999364070594\n",
      "[ep378] episode_rewards for agent 4 : 45.923996759578586\n",
      "[ep378] episode_rewards for agent 5 : 71.10799497645348\n",
      "[ep378] episode_rewards for agent 6 : -0.4720007348805666\n",
      "[ep378] episode_rewards for agent 7 : -21.17199967894703\n",
      "[ep378] episode_rewards for agent 8 : -52.75199703499675\n",
      "[ep378] episode_rewards for agent 9 : -22.527999110519886\n",
      "[ep378] mean episode reward : -2.570600302610546\n",
      "episode 379 done\n",
      "[ep379] episode_rewards for agent 0 : 50.1899965563789\n",
      "[ep379] episode_rewards for agent 1 : -52.947997068054974\n",
      "[ep379] episode_rewards for agent 2 : -58.043996611610055\n",
      "[ep379] episode_rewards for agent 3 : 14.263998596929014\n",
      "[ep379] episode_rewards for agent 4 : 31.77599753346294\n",
      "[ep379] episode_rewards for agent 5 : 131.47599170170724\n",
      "[ep379] episode_rewards for agent 6 : -19.275999173521996\n",
      "[ep379] episode_rewards for agent 7 : -22.05199993401766\n",
      "[ep379] episode_rewards for agent 8 : -29.4599992306903\n",
      "[ep379] episode_rewards for agent 9 : 30.65199777390808\n",
      "[ep379] mean episode reward : 7.65779901444912\n",
      "episode 380 done\n",
      "[ep380] episode_rewards for agent 0 : 73.77799509465694\n",
      "[ep380] episode_rewards for agent 1 : -49.247997250407934\n",
      "[ep380] episode_rewards for agent 2 : -58.69199654832482\n",
      "[ep380] episode_rewards for agent 3 : -36.167998338118196\n",
      "[ep380] episode_rewards for agent 4 : 35.531997247599065\n",
      "[ep380] episode_rewards for agent 5 : 93.01199386268854\n",
      "[ep380] episode_rewards for agent 6 : 2.8359988098964095\n",
      "[ep380] episode_rewards for agent 7 : -51.84799716062844\n",
      "[ep380] episode_rewards for agent 8 : -48.93199723958969\n",
      "[ep380] episode_rewards for agent 9 : -2.6800001934170723\n",
      "[ep380] mean episode reward : -4.24100017156452\n",
      "episode 381 done\n",
      "[ep381] episode_rewards for agent 0 : 46.30599683523178\n",
      "[ep381] episode_rewards for agent 1 : -56.07999678142369\n",
      "[ep381] episode_rewards for agent 2 : -58.95599653292447\n",
      "[ep381] episode_rewards for agent 3 : -32.67999845277518\n",
      "[ep381] episode_rewards for agent 4 : -2.7880001701414585\n",
      "[ep381] episode_rewards for agent 5 : 61.02399594057351\n",
      "[ep381] episode_rewards for agent 6 : -0.06000110786408186\n",
      "[ep381] episode_rewards for agent 7 : -29.471999031491578\n",
      "[ep381] episode_rewards for agent 8 : -42.22799793165177\n",
      "[ep381] episode_rewards for agent 9 : 58.299996081739664\n",
      "[ep381] mean episode reward : -5.663400115072728\n",
      "episode 382 done\n",
      "[ep382] episode_rewards for agent 0 : 67.49799557030201\n",
      "[ep382] episode_rewards for agent 1 : -56.99999667238444\n",
      "[ep382] episode_rewards for agent 2 : -38.411998379044235\n",
      "[ep382] episode_rewards for agent 3 : -23.799999331124127\n",
      "[ep382] episode_rewards for agent 4 : 61.07199580222368\n",
      "[ep382] episode_rewards for agent 5 : 41.25999666098505\n",
      "[ep382] episode_rewards for agent 6 : -14.42400017566979\n",
      "[ep382] episode_rewards for agent 7 : -43.89999771397561\n",
      "[ep382] episode_rewards for agent 8 : -52.515997065231204\n",
      "[ep382] episode_rewards for agent 9 : 62.41599570866674\n",
      "[ep382] mean episode reward : 0.21939944047480822\n",
      "episode 383 done\n",
      "[ep383] episode_rewards for agent 0 : 64.10199578292668\n",
      "[ep383] episode_rewards for agent 1 : -54.97199685871601\n",
      "[ep383] episode_rewards for agent 2 : -57.75999660976231\n",
      "[ep383] episode_rewards for agent 3 : -24.60799931921065\n",
      "[ep383] episode_rewards for agent 4 : -5.812000057660043\n",
      "[ep383] episode_rewards for agent 5 : 83.02799463737756\n",
      "[ep383] episode_rewards for agent 6 : -8.188000182621181\n",
      "[ep383] episode_rewards for agent 7 : -32.78799854684621\n",
      "[ep383] episode_rewards for agent 8 : -36.471998484805226\n",
      "[ep383] episode_rewards for agent 9 : 19.827998384833336\n",
      "[ep383] mean episode reward : -5.364200125448406\n",
      "episode 384 done\n",
      "[ep384] episode_rewards for agent 0 : 90.36199423484504\n",
      "[ep384] episode_rewards for agent 1 : -56.35599667299539\n",
      "[ep384] episode_rewards for agent 2 : -44.87199766281992\n",
      "[ep384] episode_rewards for agent 3 : -20.93999911658466\n",
      "[ep384] episode_rewards for agent 4 : 76.71999493148178\n",
      "[ep384] episode_rewards for agent 5 : 66.66399508714676\n",
      "[ep384] episode_rewards for agent 6 : -0.9480004133656621\n",
      "[ep384] episode_rewards for agent 7 : -31.035998973995447\n",
      "[ep384] episode_rewards for agent 8 : -39.42399825621396\n",
      "[ep384] episode_rewards for agent 9 : 25.715997979044914\n",
      "[ep384] mean episode reward : 6.588599113654345\n",
      "episode 385 done\n",
      "[ep385] episode_rewards for agent 0 : 80.13799482304603\n",
      "[ep385] episode_rewards for agent 1 : -51.4919972140342\n",
      "[ep385] episode_rewards for agent 2 : -55.58799684140831\n",
      "[ep385] episode_rewards for agent 3 : -5.076000546105206\n",
      "[ep385] episode_rewards for agent 4 : 14.387998626567423\n",
      "[ep385] episode_rewards for agent 5 : 97.23599380999804\n",
      "[ep385] episode_rewards for agent 6 : -11.459999797865748\n",
      "[ep385] episode_rewards for agent 7 : -35.823998651467264\n",
      "[ep385] episode_rewards for agent 8 : -52.53999699745327\n",
      "[ep385] episode_rewards for agent 9 : 25.963998089544475\n",
      "[ep385] mean episode reward : 0.574599530082196\n",
      "episode 386 done\n",
      "[ep386] episode_rewards for agent 0 : 73.67399508412927\n",
      "[ep386] episode_rewards for agent 1 : -51.53599695023149\n",
      "[ep386] episode_rewards for agent 2 : -48.263997331261635\n",
      "[ep386] episode_rewards for agent 3 : -9.648000083863735\n",
      "[ep386] episode_rewards for agent 4 : -20.355999087914824\n",
      "[ep386] episode_rewards for agent 5 : 113.16799271665514\n",
      "[ep386] episode_rewards for agent 6 : 5.019998883828521\n",
      "[ep386] episode_rewards for agent 7 : -34.827998703345656\n",
      "[ep386] episode_rewards for agent 8 : -55.96399678196758\n",
      "[ep386] episode_rewards for agent 9 : 9.299999069422483\n",
      "[ep386] mean episode reward : -1.943400318454951\n",
      "episode 387 done\n",
      "[ep387] episode_rewards for agent 0 : 63.76999591756612\n",
      "[ep387] episode_rewards for agent 1 : -57.56799660436809\n",
      "[ep387] episode_rewards for agent 2 : -58.28399656433612\n",
      "[ep387] episode_rewards for agent 3 : -27.279999122023582\n",
      "[ep387] episode_rewards for agent 4 : -15.97599936183542\n",
      "[ep387] episode_rewards for agent 5 : 57.92799585219473\n",
      "[ep387] episode_rewards for agent 6 : -19.247999371029437\n",
      "[ep387] episode_rewards for agent 7 : -55.115996898151934\n",
      "[ep387] episode_rewards for agent 8 : -32.32399887405336\n",
      "[ep387] episode_rewards for agent 9 : -1.768000385724008\n",
      "[ep387] mean episode reward : -14.58659954117611\n",
      "episode 388 done\n",
      "[ep388] episode_rewards for agent 0 : 72.03799525089562\n",
      "[ep388] episode_rewards for agent 1 : -58.67199653200805\n",
      "[ep388] episode_rewards for agent 2 : -35.84399869013578\n",
      "[ep388] episode_rewards for agent 3 : 0.1839991072192788\n",
      "[ep388] episode_rewards for agent 4 : -8.139999772422016\n",
      "[ep388] episode_rewards for agent 5 : 55.07199610862881\n",
      "[ep388] episode_rewards for agent 6 : -1.532000563107431\n",
      "[ep388] episode_rewards for agent 7 : -44.99199779331684\n",
      "[ep388] episode_rewards for agent 8 : -35.09199872240424\n",
      "[ep388] episode_rewards for agent 9 : 85.10799454711378\n",
      "[ep388] mean episode reward : 2.8129992940463127\n",
      "episode 389 done\n",
      "[ep389] episode_rewards for agent 0 : 75.73799519520253\n",
      "[ep389] episode_rewards for agent 1 : -57.327996655367315\n",
      "[ep389] episode_rewards for agent 2 : -55.51999680045992\n",
      "[ep389] episode_rewards for agent 3 : -19.395999656058848\n",
      "[ep389] episode_rewards for agent 4 : 135.7679916098714\n",
      "[ep389] episode_rewards for agent 5 : 41.8039968283847\n",
      "[ep389] episode_rewards for agent 6 : -21.295999438501894\n",
      "[ep389] episode_rewards for agent 7 : -16.936000275425613\n",
      "[ep389] episode_rewards for agent 8 : -46.547997490502894\n",
      "[ep389] episode_rewards for agent 9 : 5.947999116033316\n",
      "[ep389] mean episode reward : 4.2233992433175445\n",
      "episode 390 done\n",
      "[ep390] episode_rewards for agent 0 : 51.63399650435895\n",
      "[ep390] episode_rewards for agent 1 : -53.77999692130834\n",
      "[ep390] episode_rewards for agent 2 : -56.519996689632535\n",
      "[ep390] episode_rewards for agent 3 : -6.484000375494361\n",
      "[ep390] episode_rewards for agent 4 : 43.84399703331292\n",
      "[ep390] episode_rewards for agent 5 : 62.019995495676994\n",
      "[ep390] episode_rewards for agent 6 : -5.104000711813569\n",
      "[ep390] episode_rewards for agent 7 : -50.85199727490544\n",
      "[ep390] episode_rewards for agent 8 : -54.091996908187866\n",
      "[ep390] episode_rewards for agent 9 : 18.8799985377118\n",
      "[ep390] mean episode reward : -5.0454001310281456\n",
      "episode 391 done\n",
      "[ep391] episode_rewards for agent 0 : 23.233998166397214\n",
      "[ep391] episode_rewards for agent 1 : -55.76799673959613\n",
      "[ep391] episode_rewards for agent 2 : -48.4039973532781\n",
      "[ep391] episode_rewards for agent 3 : -33.01999834924936\n",
      "[ep391] episode_rewards for agent 4 : 78.11199492774904\n",
      "[ep391] episode_rewards for agent 5 : 58.29999594204128\n",
      "[ep391] episode_rewards for agent 6 : 8.611998589709401\n",
      "[ep391] episode_rewards for agent 7 : -50.463997196406126\n",
      "[ep391] episode_rewards for agent 8 : -23.551999741233885\n",
      "[ep391] episode_rewards for agent 9 : 96.31599397864193\n",
      "[ep391] mean episode reward : 5.336599222477526\n",
      "episode 392 done\n",
      "[ep392] episode_rewards for agent 0 : 89.1019940301776\n",
      "[ep392] episode_rewards for agent 1 : -50.49199727550149\n",
      "[ep392] episode_rewards for agent 2 : -50.975997319445014\n",
      "[ep392] episode_rewards for agent 3 : 72.60799513012171\n",
      "[ep392] episode_rewards for agent 4 : 44.89199691172689\n",
      "[ep392] episode_rewards for agent 5 : 66.67599535547197\n",
      "[ep392] episode_rewards for agent 6 : 49.27999671921134\n",
      "[ep392] episode_rewards for agent 7 : -55.41999679710716\n",
      "[ep392] episode_rewards for agent 8 : -42.7879979852587\n",
      "[ep392] episode_rewards for agent 9 : -40.44399792421609\n",
      "[ep392] mean episode reward : 8.243799084518106\n",
      "episode 393 done\n",
      "[ep393] episode_rewards for agent 0 : 62.10999559890479\n",
      "[ep393] episode_rewards for agent 1 : -56.72399664949626\n",
      "[ep393] episode_rewards for agent 2 : -52.99999697133899\n",
      "[ep393] episode_rewards for agent 3 : 22.539998181164265\n",
      "[ep393] episode_rewards for agent 4 : 25.97199783474207\n",
      "[ep393] episode_rewards for agent 5 : 82.66799464076757\n",
      "[ep393] episode_rewards for agent 6 : -27.09999893605709\n",
      "[ep393] episode_rewards for agent 7 : -44.443997878581285\n",
      "[ep393] episode_rewards for agent 8 : -48.34799749031663\n",
      "[ep393] episode_rewards for agent 9 : 70.22399535216391\n",
      "[ep393] mean episode reward : 3.3897993681952356\n",
      "episode 394 done\n",
      "[ep394] episode_rewards for agent 0 : 82.48999461717904\n",
      "[ep394] episode_rewards for agent 1 : -47.65999728348106\n",
      "[ep394] episode_rewards for agent 2 : -52.71199706848711\n",
      "[ep394] episode_rewards for agent 3 : -22.04399977903813\n",
      "[ep394] episode_rewards for agent 4 : 127.65999211370945\n",
      "[ep394] episode_rewards for agent 5 : 98.35599371511489\n",
      "[ep394] episode_rewards for agent 6 : -4.236000590026379\n",
      "[ep394] episode_rewards for agent 7 : -36.895998453721404\n",
      "[ep394] episode_rewards for agent 8 : -54.999996829777956\n",
      "[ep394] episode_rewards for agent 9 : 54.523996168747544\n",
      "[ep394] mean episode reward : 14.448198661021888\n",
      "episode 395 done\n",
      "[ep395] episode_rewards for agent 0 : -10.345999808050692\n",
      "[ep395] episode_rewards for agent 1 : -55.67199673783034\n",
      "[ep395] episode_rewards for agent 2 : -51.97999715153128\n",
      "[ep395] episode_rewards for agent 3 : -15.88399968855083\n",
      "[ep395] episode_rewards for agent 4 : -14.38799951504916\n",
      "[ep395] episode_rewards for agent 5 : -15.996000155806541\n",
      "[ep395] episode_rewards for agent 6 : -2.9560009641572833\n",
      "[ep395] episode_rewards for agent 7 : -49.55599739216268\n",
      "[ep395] episode_rewards for agent 8 : -32.33999897632748\n",
      "[ep395] episode_rewards for agent 9 : 71.72799536027014\n",
      "[ep395] mean episode reward : -17.738999502919615\n",
      "episode 396 done\n",
      "[ep396] episode_rewards for agent 0 : 75.66199514642358\n",
      "[ep396] episode_rewards for agent 1 : -56.25199672020972\n",
      "[ep396] episode_rewards for agent 2 : -58.57999657839537\n",
      "[ep396] episode_rewards for agent 3 : -11.071999832987785\n",
      "[ep396] episode_rewards for agent 4 : 23.623998168855906\n",
      "[ep396] episode_rewards for agent 5 : 102.72799351904541\n",
      "[ep396] episode_rewards for agent 6 : -3.84400047454983\n",
      "[ep396] episode_rewards for agent 7 : -51.503997151739895\n",
      "[ep396] episode_rewards for agent 8 : -40.31599801778793\n",
      "[ep396] episode_rewards for agent 9 : 87.14799425564706\n",
      "[ep396] mean episode reward : 6.759399231430143\n",
      "episode 397 done\n",
      "[ep397] episode_rewards for agent 0 : 82.39399470109493\n",
      "[ep397] episode_rewards for agent 1 : -56.90399664826691\n",
      "[ep397] episode_rewards for agent 2 : -50.96399724856019\n",
      "[ep397] episode_rewards for agent 3 : -4.944000450894237\n",
      "[ep397] episode_rewards for agent 4 : 137.8079914469272\n",
      "[ep397] episode_rewards for agent 5 : 127.51599188428372\n",
      "[ep397] episode_rewards for agent 6 : -7.452000464312732\n",
      "[ep397] episode_rewards for agent 7 : -40.91999803762883\n",
      "[ep397] episode_rewards for agent 8 : -52.83199705928564\n",
      "[ep397] episode_rewards for agent 9 : 11.747998815961182\n",
      "[ep397] mean episode reward : 14.544998693931849\n",
      "episode 398 done\n",
      "[ep398] episode_rewards for agent 0 : 20.865998338907957\n",
      "[ep398] episode_rewards for agent 1 : -51.89199706725776\n",
      "[ep398] episode_rewards for agent 2 : -50.71199725754559\n",
      "[ep398] episode_rewards for agent 3 : -27.995998796075583\n",
      "[ep398] episode_rewards for agent 4 : 92.94799394719303\n",
      "[ep398] episode_rewards for agent 5 : 36.923996911384165\n",
      "[ep398] episode_rewards for agent 6 : -18.824000134132802\n",
      "[ep398] episode_rewards for agent 7 : -42.047998066060245\n",
      "[ep398] episode_rewards for agent 8 : -49.85599734913558\n",
      "[ep398] episode_rewards for agent 9 : 57.25599606893957\n",
      "[ep398] mean episode reward : -3.3334003403782844\n",
      "episode 399 done\n",
      "[ep399] episode_rewards for agent 0 : 105.36599327903241\n",
      "[ep399] episode_rewards for agent 1 : -54.603996807709336\n",
      "[ep399] episode_rewards for agent 2 : -53.88799702282995\n",
      "[ep399] episode_rewards for agent 3 : -4.004000321961939\n",
      "[ep399] episode_rewards for agent 4 : 60.851995767094195\n",
      "[ep399] episode_rewards for agent 5 : 41.93199678044766\n",
      "[ep399] episode_rewards for agent 6 : -35.72799831535667\n",
      "[ep399] episode_rewards for agent 7 : -48.09599753562361\n",
      "[ep399] episode_rewards for agent 8 : -47.43599741626531\n",
      "[ep399] episode_rewards for agent 9 : 35.45599719788879\n",
      "[ep399] mean episode reward : -0.015000439528375865\n",
      "episode 400 done\n",
      "[ep400] episode_rewards for agent 0 : 112.98999256733805\n",
      "[ep400] episode_rewards for agent 1 : -55.523996788077056\n",
      "[ep400] episode_rewards for agent 2 : -39.099998254328966\n",
      "[ep400] episode_rewards for agent 3 : -23.959999088197947\n",
      "[ep400] episode_rewards for agent 4 : 49.89199660625309\n",
      "[ep400] episode_rewards for agent 5 : 25.135997924022377\n",
      "[ep400] episode_rewards for agent 6 : -17.43599949311465\n",
      "[ep400] episode_rewards for agent 7 : -14.643999950028956\n",
      "[ep400] episode_rewards for agent 8 : -42.3719979878515\n",
      "[ep400] episode_rewards for agent 9 : 84.19999454449862\n",
      "[ep400] mean episode reward : 7.918199008051306\n",
      "episode 401 done\n",
      "[ep401] episode_rewards for agent 0 : 98.2259937170893\n",
      "[ep401] episode_rewards for agent 1 : -59.37199646234512\n",
      "[ep401] episode_rewards for agent 2 : -53.3519969927147\n",
      "[ep401] episode_rewards for agent 3 : -34.25599857699126\n",
      "[ep401] episode_rewards for agent 4 : 34.283997202292085\n",
      "[ep401] episode_rewards for agent 5 : 134.5279915202409\n",
      "[ep401] episode_rewards for agent 6 : -21.711999487131834\n",
      "[ep401] episode_rewards for agent 7 : -44.76799772400409\n",
      "[ep401] episode_rewards for agent 8 : -54.451996959745884\n",
      "[ep401] episode_rewards for agent 9 : 45.963996599428356\n",
      "[ep401] mean episode reward : 4.508999283611774\n",
      "episode 402 done\n",
      "[ep402] episode_rewards for agent 0 : -10.713999812491238\n",
      "[ep402] episode_rewards for agent 1 : -51.94799704104662\n",
      "[ep402] episode_rewards for agent 2 : -56.41999670676887\n",
      "[ep402] episode_rewards for agent 3 : -39.6039979737252\n",
      "[ep402] episode_rewards for agent 4 : 25.927998050116003\n",
      "[ep402] episode_rewards for agent 5 : 75.33199498057365\n",
      "[ep402] episode_rewards for agent 6 : -16.53199987951666\n",
      "[ep402] episode_rewards for agent 7 : -46.21999771986157\n",
      "[ep402] episode_rewards for agent 8 : -40.8279981687665\n",
      "[ep402] episode_rewards for agent 9 : 73.5959951505065\n",
      "[ep402] mean episode reward : -8.74099991209805\n",
      "episode 403 done\n",
      "[ep403] episode_rewards for agent 0 : 87.45799441076815\n",
      "[ep403] episode_rewards for agent 1 : -53.99599692597985\n",
      "[ep403] episode_rewards for agent 2 : -41.019998150877655\n",
      "[ep403] episode_rewards for agent 3 : -17.403999472036958\n",
      "[ep403] episode_rewards for agent 4 : 39.531997326761484\n",
      "[ep403] episode_rewards for agent 5 : 65.98399523738772\n",
      "[ep403] episode_rewards for agent 6 : -21.41999959014356\n",
      "[ep403] episode_rewards for agent 7 : -34.715998735278845\n",
      "[ep403] episode_rewards for agent 8 : -37.43999841157347\n",
      "[ep403] episode_rewards for agent 9 : 52.07599639054388\n",
      "[ep403] mean episode reward : 3.905399207957089\n",
      "episode 404 done\n",
      "[ep404] episode_rewards for agent 0 : 88.67399419471622\n",
      "[ep404] episode_rewards for agent 1 : -44.191997670568526\n",
      "[ep404] episode_rewards for agent 2 : -48.91199725307524\n",
      "[ep404] episode_rewards for agent 3 : -23.89599933475256\n",
      "[ep404] episode_rewards for agent 4 : 104.35199328698218\n",
      "[ep404] episode_rewards for agent 5 : 98.41599348094314\n",
      "[ep404] episode_rewards for agent 6 : -15.227999922819436\n",
      "[ep404] episode_rewards for agent 7 : -52.08799710031599\n",
      "[ep404] episode_rewards for agent 8 : -50.74799722805619\n",
      "[ep404] episode_rewards for agent 9 : -35.76799832098186\n",
      "[ep404] mean episode reward : 2.060999413207173\n",
      "episode 405 done\n",
      "[ep405] episode_rewards for agent 0 : -12.25399972870946\n",
      "[ep405] episode_rewards for agent 1 : -54.4479969246313\n",
      "[ep405] episode_rewards for agent 2 : -59.83599643688649\n",
      "[ep405] episode_rewards for agent 3 : -9.792000586166978\n",
      "[ep405] episode_rewards for agent 4 : -9.860000326298177\n",
      "[ep405] episode_rewards for agent 5 : 117.54799260944128\n",
      "[ep405] episode_rewards for agent 6 : -37.47199843078852\n",
      "[ep405] episode_rewards for agent 7 : -45.24799767136574\n",
      "[ep405] episode_rewards for agent 8 : -50.90799727477133\n",
      "[ep405] episode_rewards for agent 9 : 7.6159989926964045\n",
      "[ep405] mean episode reward : -15.46539957774803\n",
      "episode 406 done\n",
      "[ep406] episode_rewards for agent 0 : 20.06999829597771\n",
      "[ep406] episode_rewards for agent 1 : -59.1919964896515\n",
      "[ep406] episode_rewards for agent 2 : -49.827997327782214\n",
      "[ep406] episode_rewards for agent 3 : 10.55999856814742\n",
      "[ep406] episode_rewards for agent 4 : 57.52799593936652\n",
      "[ep406] episode_rewards for agent 5 : 91.00399389956146\n",
      "[ep406] episode_rewards for agent 6 : -3.880000569857657\n",
      "[ep406] episode_rewards for agent 7 : -50.41199732106179\n",
      "[ep406] episode_rewards for agent 8 : -52.84799701999873\n",
      "[ep406] episode_rewards for agent 9 : 20.403998354449868\n",
      "[ep406] mean episode reward : -1.6594003670848907\n",
      "episode 407 done\n",
      "[ep407] episode_rewards for agent 0 : 46.24199659842998\n",
      "[ep407] episode_rewards for agent 1 : -53.60399687383324\n",
      "[ep407] episode_rewards for agent 2 : -41.95999788492918\n",
      "[ep407] episode_rewards for agent 3 : 2.255999012850225\n",
      "[ep407] episode_rewards for agent 4 : 84.2119945473969\n",
      "[ep407] episode_rewards for agent 5 : 53.73199619818479\n",
      "[ep407] episode_rewards for agent 6 : -40.74399814661592\n",
      "[ep407] episode_rewards for agent 7 : -42.85999800544232\n",
      "[ep407] episode_rewards for agent 8 : -32.36399892345071\n",
      "[ep407] episode_rewards for agent 9 : 26.89599773660302\n",
      "[ep407] mean episode reward : 0.18059942591935396\n",
      "episode 408 done\n",
      "[ep408] episode_rewards for agent 0 : 93.57399403396994\n",
      "[ep408] episode_rewards for agent 1 : -59.599996459670365\n",
      "[ep408] episode_rewards for agent 2 : -52.71999696176499\n",
      "[ep408] episode_rewards for agent 3 : -51.443997111171484\n",
      "[ep408] episode_rewards for agent 4 : 63.63999589718878\n",
      "[ep408] episode_rewards for agent 5 : 77.97199490386993\n",
      "[ep408] episode_rewards for agent 6 : -25.16399958729744\n",
      "[ep408] episode_rewards for agent 7 : -29.16399909555912\n",
      "[ep408] episode_rewards for agent 8 : -40.75999819487333\n",
      "[ep408] episode_rewards for agent 9 : 82.62399467080832\n",
      "[ep408] mean episode reward : 5.895799209550023\n",
      "episode 409 done\n",
      "[ep409] episode_rewards for agent 0 : 100.41399345267564\n",
      "[ep409] episode_rewards for agent 1 : -49.8439973089844\n",
      "[ep409] episode_rewards for agent 2 : -59.77199644502252\n",
      "[ep409] episode_rewards for agent 3 : -1.2520008580759168\n",
      "[ep409] episode_rewards for agent 4 : 128.93199170473963\n",
      "[ep409] episode_rewards for agent 5 : -5.496000972576439\n",
      "[ep409] episode_rewards for agent 6 : -21.327999632805586\n",
      "[ep409] episode_rewards for agent 7 : -31.86399870738387\n",
      "[ep409] episode_rewards for agent 8 : -41.16399801056832\n",
      "[ep409] episode_rewards for agent 9 : 6.271999407559633\n",
      "[ep409] mean episode reward : 2.489799262955785\n",
      "episode 410 done\n",
      "[ep410] episode_rewards for agent 0 : 57.63799611944705\n",
      "[ep410] episode_rewards for agent 1 : -57.04799663461745\n",
      "[ep410] episode_rewards for agent 2 : -54.25199691299349\n",
      "[ep410] episode_rewards for agent 3 : 31.911997518502176\n",
      "[ep410] episode_rewards for agent 4 : 56.891996084712446\n",
      "[ep410] episode_rewards for agent 5 : 134.1479914272204\n",
      "[ep410] episode_rewards for agent 6 : -2.1160004399716854\n",
      "[ep410] episode_rewards for agent 7 : -54.803996939212084\n",
      "[ep410] episode_rewards for agent 8 : -43.12399788480252\n",
      "[ep410] episode_rewards for agent 9 : -7.448000070638955\n",
      "[ep410] mean episode reward : 6.179799226764589\n",
      "episode 411 done\n",
      "[ep411] episode_rewards for agent 0 : 54.497996324673295\n",
      "[ep411] episode_rewards for agent 1 : -52.41599699854851\n",
      "[ep411] episode_rewards for agent 2 : -45.55199774354696\n",
      "[ep411] episode_rewards for agent 3 : -16.951999727636576\n",
      "[ep411] episode_rewards for agent 4 : 40.08799717761576\n",
      "[ep411] episode_rewards for agent 5 : 93.17599390633404\n",
      "[ep411] episode_rewards for agent 6 : -19.055999787524343\n",
      "[ep411] episode_rewards for agent 7 : -54.73999689426273\n",
      "[ep411] episode_rewards for agent 8 : -33.843998591415584\n",
      "[ep411] episode_rewards for agent 9 : 90.89999423455447\n",
      "[ep411] mean episode reward : 5.610199190024287\n",
      "episode 412 done\n",
      "[ep412] episode_rewards for agent 0 : 78.04599480424076\n",
      "[ep412] episode_rewards for agent 1 : -57.51599660143256\n",
      "[ep412] episode_rewards for agent 2 : -41.059998136013746\n",
      "[ep412] episode_rewards for agent 3 : -16.743999680504203\n",
      "[ep412] episode_rewards for agent 4 : 36.283997278660536\n",
      "[ep412] episode_rewards for agent 5 : 87.63199403695762\n",
      "[ep412] episode_rewards for agent 6 : -4.840000591240823\n",
      "[ep412] episode_rewards for agent 7 : -54.935996857471764\n",
      "[ep412] episode_rewards for agent 8 : -46.259997544810176\n",
      "[ep412] episode_rewards for agent 9 : 11.123998784460127\n",
      "[ep412] mean episode reward : -0.8270004507154226\n",
      "episode 413 done\n",
      "[ep413] episode_rewards for agent 0 : 58.71799614280462\n",
      "[ep413] episode_rewards for agent 1 : -45.98399761505425\n",
      "[ep413] episode_rewards for agent 2 : -59.391996482387185\n",
      "[ep413] episode_rewards for agent 3 : -6.560000244528055\n",
      "[ep413] episode_rewards for agent 4 : 45.887996731325984\n",
      "[ep413] episode_rewards for agent 5 : -15.94400024227798\n",
      "[ep413] episode_rewards for agent 6 : -19.796000090427697\n",
      "[ep413] episode_rewards for agent 7 : -24.6079994533211\n",
      "[ep413] episode_rewards for agent 8 : -31.083999098278582\n",
      "[ep413] episode_rewards for agent 9 : 109.69199304655194\n",
      "[ep413] mean episode reward : 1.0929992694407702\n",
      "episode 414 done\n",
      "[ep414] episode_rewards for agent 0 : 70.31399517320096\n",
      "[ep414] episode_rewards for agent 1 : -53.78399682510644\n",
      "[ep414] episode_rewards for agent 2 : -47.023997587151825\n",
      "[ep414] episode_rewards for agent 3 : -16.307999380864203\n",
      "[ep414] episode_rewards for agent 4 : 37.27199720963836\n",
      "[ep414] episode_rewards for agent 5 : 133.51199167687446\n",
      "[ep414] episode_rewards for agent 6 : 22.823997788131237\n",
      "[ep414] episode_rewards for agent 7 : -28.603999350219965\n",
      "[ep414] episode_rewards for agent 8 : -55.8279968239367\n",
      "[ep414] episode_rewards for agent 9 : 50.13199648167938\n",
      "[ep414] mean episode reward : 11.250598836224526\n",
      "episode 415 done\n",
      "[ep415] episode_rewards for agent 0 : 100.05799351539463\n",
      "[ep415] episode_rewards for agent 1 : -51.12399719003588\n",
      "[ep415] episode_rewards for agent 2 : -51.667997115291655\n",
      "[ep415] episode_rewards for agent 3 : -3.6320005767047405\n",
      "[ep415] episode_rewards for agent 4 : 34.42799736559391\n",
      "[ep415] episode_rewards for agent 5 : 91.73599415365607\n",
      "[ep415] episode_rewards for agent 6 : -6.868000182323158\n",
      "[ep415] episode_rewards for agent 7 : -49.83599732629955\n",
      "[ep415] episode_rewards for agent 8 : -55.39999685063958\n",
      "[ep415] episode_rewards for agent 9 : 77.93999483808875\n",
      "[ep415] mean episode reward : 8.56339906314388\n",
      "episode 416 done\n",
      "[ep416] episode_rewards for agent 0 : 26.737997910939157\n",
      "[ep416] episode_rewards for agent 1 : -48.679997416213155\n",
      "[ep416] episode_rewards for agent 2 : -48.235997308045626\n",
      "[ep416] episode_rewards for agent 3 : -18.91199970152229\n",
      "[ep416] episode_rewards for agent 4 : 50.05999642517418\n",
      "[ep416] episode_rewards for agent 5 : 20.24799818173051\n",
      "[ep416] episode_rewards for agent 6 : -11.227999862283468\n",
      "[ep416] episode_rewards for agent 7 : -51.05199727229774\n",
      "[ep416] episode_rewards for agent 8 : -47.54799744673073\n",
      "[ep416] episode_rewards for agent 9 : 142.69999103806913\n",
      "[ep416] mean episode reward : 1.408999454881996\n",
      "episode 417 done\n",
      "[ep417] episode_rewards for agent 0 : 21.537998107261956\n",
      "[ep417] episode_rewards for agent 1 : -49.71999721042812\n",
      "[ep417] episode_rewards for agent 2 : -59.52799645718187\n",
      "[ep417] episode_rewards for agent 3 : -17.348000126890838\n",
      "[ep417] episode_rewards for agent 4 : -18.519999593496323\n",
      "[ep417] episode_rewards for agent 5 : 12.119998379610479\n",
      "[ep417] episode_rewards for agent 6 : -25.995999459177256\n",
      "[ep417] episode_rewards for agent 7 : -49.05999744962901\n",
      "[ep417] episode_rewards for agent 8 : -30.68399902433157\n",
      "[ep417] episode_rewards for agent 9 : 62.32399583980441\n",
      "[ep417] mean episode reward : -15.487399699445813\n",
      "episode 418 done\n",
      "[ep418] episode_rewards for agent 0 : 76.0299950093031\n",
      "[ep418] episode_rewards for agent 1 : -51.78799719084054\n",
      "[ep418] episode_rewards for agent 2 : -33.27999885007739\n",
      "[ep418] episode_rewards for agent 3 : -26.03199898544699\n",
      "[ep418] episode_rewards for agent 4 : 71.67599542904645\n",
      "[ep418] episode_rewards for agent 5 : 89.73199419863522\n",
      "[ep418] episode_rewards for agent 6 : -15.592000440694392\n",
      "[ep418] episode_rewards for agent 7 : -50.27599726803601\n",
      "[ep418] episode_rewards for agent 8 : -37.331998511217535\n",
      "[ep418] episode_rewards for agent 9 : 18.84399837255478\n",
      "[ep418] mean episode reward : 4.198199176322669\n",
      "episode 419 done\n",
      "[ep419] episode_rewards for agent 0 : 87.36599436495453\n",
      "[ep419] episode_rewards for agent 1 : -58.72399651259184\n",
      "[ep419] episode_rewards for agent 2 : -45.36799768265337\n",
      "[ep419] episode_rewards for agent 3 : 1.9159993343055248\n",
      "[ep419] episode_rewards for agent 4 : 49.84799673128873\n",
      "[ep419] episode_rewards for agent 5 : 93.5999941052869\n",
      "[ep419] episode_rewards for agent 6 : -43.423997935839\n",
      "[ep419] episode_rewards for agent 7 : -31.85599904321134\n",
      "[ep419] episode_rewards for agent 8 : -56.683996718376875\n",
      "[ep419] episode_rewards for agent 9 : 30.41999755334109\n",
      "[ep419] mean episode reward : 2.7093994196504356\n",
      "episode 420 done\n",
      "[ep420] episode_rewards for agent 0 : -23.769999001175165\n",
      "[ep420] episode_rewards for agent 1 : -51.39599706791341\n",
      "[ep420] episode_rewards for agent 2 : -59.97999642603099\n",
      "[ep420] episode_rewards for agent 3 : -5.416000205092132\n",
      "[ep420] episode_rewards for agent 4 : 17.74399839155376\n",
      "[ep420] episode_rewards for agent 5 : 13.931998243555427\n",
      "[ep420] episode_rewards for agent 6 : -6.256000600755215\n",
      "[ep420] episode_rewards for agent 7 : -22.059999882243574\n",
      "[ep420] episode_rewards for agent 8 : -48.73599738907069\n",
      "[ep420] episode_rewards for agent 9 : 51.563996659591794\n",
      "[ep420] mean episode reward : -13.43739972775802\n",
      "episode 421 done\n",
      "[ep421] episode_rewards for agent 0 : 18.61399824451655\n",
      "[ep421] episode_rewards for agent 1 : -46.10399755742401\n",
      "[ep421] episode_rewards for agent 2 : -59.723996450193226\n",
      "[ep421] episode_rewards for agent 3 : -33.93999830260873\n",
      "[ep421] episode_rewards for agent 4 : 25.827998095192015\n",
      "[ep421] episode_rewards for agent 5 : 117.12799239251763\n",
      "[ep421] episode_rewards for agent 6 : -23.007999317720532\n",
      "[ep421] episode_rewards for agent 7 : -35.739998104050756\n",
      "[ep421] episode_rewards for agent 8 : -54.59199693519622\n",
      "[ep421] episode_rewards for agent 9 : 35.863997609354556\n",
      "[ep421] mean episode reward : -5.567400032561272\n",
      "episode 422 done\n",
      "[ep422] episode_rewards for agent 0 : 106.24999336525798\n",
      "[ep422] episode_rewards for agent 1 : -41.311997787095606\n",
      "[ep422] episode_rewards for agent 2 : -53.451996992342174\n",
      "[ep422] episode_rewards for agent 3 : -15.327999634668231\n",
      "[ep422] episode_rewards for agent 4 : 12.635998831130564\n",
      "[ep422] episode_rewards for agent 5 : 81.90399449225515\n",
      "[ep422] episode_rewards for agent 6 : 6.855998546816409\n",
      "[ep422] episode_rewards for agent 7 : -49.33999733906239\n",
      "[ep422] episode_rewards for agent 8 : -35.23599866125733\n",
      "[ep422] episode_rewards for agent 9 : 95.25599381327629\n",
      "[ep422] mean episode reward : 10.823398863431066\n",
      "episode 423 done\n",
      "[ep423] episode_rewards for agent 0 : 65.78599553834647\n",
      "[ep423] episode_rewards for agent 1 : -55.69199669919908\n",
      "[ep423] episode_rewards for agent 2 : -45.55999759212136\n",
      "[ep423] episode_rewards for agent 3 : -22.995999545790255\n",
      "[ep423] episode_rewards for agent 4 : 12.539998554624617\n",
      "[ep423] episode_rewards for agent 5 : 24.019997782073915\n",
      "[ep423] episode_rewards for agent 6 : 7.1999987699091434\n",
      "[ep423] episode_rewards for agent 7 : -52.21599707659334\n",
      "[ep423] episode_rewards for agent 8 : -43.367997881025076\n",
      "[ep423] episode_rewards for agent 9 : 112.60799296852201\n",
      "[ep423] mean episode reward : 0.23219948187470435\n",
      "episode 424 done\n",
      "[ep424] episode_rewards for agent 0 : 84.13399436790496\n",
      "[ep424] episode_rewards for agent 1 : -49.00399718619883\n",
      "[ep424] episode_rewards for agent 2 : -45.87999778892845\n",
      "[ep424] episode_rewards for agent 3 : -9.22800026834011\n",
      "[ep424] episode_rewards for agent 4 : 37.99999716505408\n",
      "[ep424] episode_rewards for agent 5 : 119.19199242535979\n",
      "[ep424] episode_rewards for agent 6 : -20.755999475717545\n",
      "[ep424] episode_rewards for agent 7 : -49.559997361153364\n",
      "[ep424] episode_rewards for agent 8 : -51.37999706622213\n",
      "[ep424] episode_rewards for agent 9 : 74.35599497333169\n",
      "[ep424] mean episode reward : 8.98739897850901\n",
      "episode 425 done\n",
      "[ep425] episode_rewards for agent 0 : 22.437998336739838\n",
      "[ep425] episode_rewards for agent 1 : -56.235996682196856\n",
      "[ep425] episode_rewards for agent 2 : -56.07599678542465\n",
      "[ep425] episode_rewards for agent 3 : -17.08799958229065\n",
      "[ep425] episode_rewards for agent 4 : 52.04399645701051\n",
      "[ep425] episode_rewards for agent 5 : 46.04399672616273\n",
      "[ep425] episode_rewards for agent 6 : -8.523999945260584\n",
      "[ep425] episode_rewards for agent 7 : -52.775997038930655\n",
      "[ep425] episode_rewards for agent 8 : -32.81199890933931\n",
      "[ep425] episode_rewards for agent 9 : 78.03199477028102\n",
      "[ep425] mean episode reward : -2.495400265324861\n",
      "episode 426 done\n",
      "[ep426] episode_rewards for agent 0 : 84.19399461429566\n",
      "[ep426] episode_rewards for agent 1 : -55.27199683431536\n",
      "[ep426] episode_rewards for agent 2 : -55.88799675647169\n",
      "[ep426] episode_rewards for agent 3 : -25.659998985938728\n",
      "[ep426] episode_rewards for agent 4 : 46.467996599152684\n",
      "[ep426] episode_rewards for agent 5 : 59.57199584040791\n",
      "[ep426] episode_rewards for agent 6 : -18.327999303117394\n",
      "[ep426] episode_rewards for agent 7 : -29.191999142058194\n",
      "[ep426] episode_rewards for agent 8 : -49.379997262731194\n",
      "[ep426] episode_rewards for agent 9 : 42.8159970138222\n",
      "[ep426] mean episode reward : -0.0670004216954112\n",
      "episode 427 done\n",
      "[ep427] episode_rewards for agent 0 : 37.64999733865261\n",
      "[ep427] episode_rewards for agent 1 : -58.18399656750262\n",
      "[ep427] episode_rewards for agent 2 : -57.70799665432423\n",
      "[ep427] episode_rewards for agent 3 : -0.1080007953569293\n",
      "[ep427] episode_rewards for agent 4 : 38.24399728886783\n",
      "[ep427] episode_rewards for agent 5 : 66.62399522960186\n",
      "[ep427] episode_rewards for agent 6 : -20.22799944318831\n",
      "[ep427] episode_rewards for agent 7 : -47.0439976118505\n",
      "[ep427] episode_rewards for agent 8 : -31.815998856909573\n",
      "[ep427] episode_rewards for agent 9 : 25.871997894719243\n",
      "[ep427] mean episode reward : -4.669800217729062\n",
      "episode 428 done\n",
      "[ep428] episode_rewards for agent 0 : 29.197997983545065\n",
      "[ep428] episode_rewards for agent 1 : -55.70799682568759\n",
      "[ep428] episode_rewards for agent 2 : -54.40799688920379\n",
      "[ep428] episode_rewards for agent 3 : 2.9959990484640002\n",
      "[ep428] episode_rewards for agent 4 : 15.047998610883951\n",
      "[ep428] episode_rewards for agent 5 : 109.49999304302037\n",
      "[ep428] episode_rewards for agent 6 : -27.675998841412365\n",
      "[ep428] episode_rewards for agent 7 : -46.51199767179787\n",
      "[ep428] episode_rewards for agent 8 : -31.323999074287713\n",
      "[ep428] episode_rewards for agent 9 : 30.00399766676128\n",
      "[ep428] mean episode reward : -2.8882002949714662\n",
      "episode 429 done\n",
      "[ep429] episode_rewards for agent 0 : 53.01399661041796\n",
      "[ep429] episode_rewards for agent 1 : -52.755997019819915\n",
      "[ep429] episode_rewards for agent 2 : -42.44399791676551\n",
      "[ep429] episode_rewards for agent 3 : -4.452000491321087\n",
      "[ep429] episode_rewards for agent 4 : 15.71999863255769\n",
      "[ep429] episode_rewards for agent 5 : 49.24799662269652\n",
      "[ep429] episode_rewards for agent 6 : -19.531999920494854\n",
      "[ep429] episode_rewards for agent 7 : -45.899997734464705\n",
      "[ep429] episode_rewards for agent 8 : -51.975997044704854\n",
      "[ep429] episode_rewards for agent 9 : -15.627999596297741\n",
      "[ep429] mean episode reward : -11.47059978581965\n",
      "episode 430 done\n",
      "[ep430] episode_rewards for agent 0 : 52.22199638839811\n",
      "[ep430] episode_rewards for agent 1 : -58.811996535398066\n",
      "[ep430] episode_rewards for agent 2 : -54.17199687939137\n",
      "[ep430] episode_rewards for agent 3 : -20.039999540895224\n",
      "[ep430] episode_rewards for agent 4 : -7.820000227540731\n",
      "[ep430] episode_rewards for agent 5 : 76.32399505004287\n",
      "[ep430] episode_rewards for agent 6 : -16.091999522410333\n",
      "[ep430] episode_rewards for agent 7 : -45.53599777724594\n",
      "[ep430] episode_rewards for agent 8 : -41.499997857026756\n",
      "[ep430] episode_rewards for agent 9 : 63.015995755791664\n",
      "[ep430] mean episode reward : -5.241000114567578\n",
      "episode 431 done\n",
      "[ep431] episode_rewards for agent 0 : 91.93399419356138\n",
      "[ep431] episode_rewards for agent 1 : -58.451996565796435\n",
      "[ep431] episode_rewards for agent 2 : -52.4199970876798\n",
      "[ep431] episode_rewards for agent 3 : -0.1400011656805873\n",
      "[ep431] episode_rewards for agent 4 : -25.92399895284325\n",
      "[ep431] episode_rewards for agent 5 : 64.26399578899145\n",
      "[ep431] episode_rewards for agent 6 : -11.17199984099716\n",
      "[ep431] episode_rewards for agent 7 : -46.76399740669876\n",
      "[ep431] episode_rewards for agent 8 : -34.06399850267917\n",
      "[ep431] episode_rewards for agent 9 : 98.35599355772138\n",
      "[ep431] mean episode reward : 2.5617994017899037\n",
      "episode 432 done\n",
      "[ep432] episode_rewards for agent 0 : 49.04599656444043\n",
      "[ep432] episode_rewards for agent 1 : -54.91999679803848\n",
      "[ep432] episode_rewards for agent 2 : -59.97999642603099\n",
      "[ep432] episode_rewards for agent 3 : -20.763999328948557\n",
      "[ep432] episode_rewards for agent 4 : 16.63599850423634\n",
      "[ep432] episode_rewards for agent 5 : 57.0119959237054\n",
      "[ep432] episode_rewards for agent 6 : -19.463999390602112\n",
      "[ep432] episode_rewards for agent 7 : -48.463997442275286\n",
      "[ep432] episode_rewards for agent 8 : -50.89599727932364\n",
      "[ep432] episode_rewards for agent 9 : 47.40799676068127\n",
      "[ep432] mean episode reward : -8.438599891215564\n",
      "episode 433 done\n",
      "[ep433] episode_rewards for agent 0 : 82.01799470372498\n",
      "[ep433] episode_rewards for agent 1 : -58.61599656753242\n",
      "[ep433] episode_rewards for agent 2 : -53.695996986702085\n",
      "[ep433] episode_rewards for agent 3 : -15.35599990747869\n",
      "[ep433] episode_rewards for agent 4 : 14.707998747006059\n",
      "[ep433] episode_rewards for agent 5 : 73.87599507719278\n",
      "[ep433] episode_rewards for agent 6 : -16.88800007291138\n",
      "[ep433] episode_rewards for agent 7 : -49.827997357584536\n",
      "[ep433] episode_rewards for agent 8 : -38.60399825591594\n",
      "[ep433] episode_rewards for agent 9 : 31.04399778228253\n",
      "[ep433] mean episode reward : -3.13420028379187\n",
      "episode 434 done\n",
      "[ep434] episode_rewards for agent 0 : 51.06599649321288\n",
      "[ep434] episode_rewards for agent 1 : -47.86399739142507\n",
      "[ep434] episode_rewards for agent 2 : -55.87999676819891\n",
      "[ep434] episode_rewards for agent 3 : -24.98799915984273\n",
      "[ep434] episode_rewards for agent 4 : 22.139998109079897\n",
      "[ep434] episode_rewards for agent 5 : 66.43199537787586\n",
      "[ep434] episode_rewards for agent 6 : -15.152000390924513\n",
      "[ep434] episode_rewards for agent 7 : -38.647998369298875\n",
      "[ep434] episode_rewards for agent 8 : -51.187997235916555\n",
      "[ep434] episode_rewards for agent 9 : 36.79199728555977\n",
      "[ep434] mean episode reward : -5.729000204987824\n",
      "episode 435 done\n",
      "[ep435] episode_rewards for agent 0 : 61.737995819188654\n",
      "[ep435] episode_rewards for agent 1 : -58.62399651762098\n",
      "[ep435] episode_rewards for agent 2 : -45.32399759814143\n",
      "[ep435] episode_rewards for agent 3 : -46.059997506439686\n",
      "[ep435] episode_rewards for agent 4 : 33.39199750777334\n",
      "[ep435] episode_rewards for agent 5 : 84.78399436920881\n",
      "[ep435] episode_rewards for agent 6 : -30.651998979970813\n",
      "[ep435] episode_rewards for agent 7 : 5.871998460963368\n",
      "[ep435] episode_rewards for agent 8 : -50.10799726564437\n",
      "[ep435] episode_rewards for agent 9 : 105.24799332302064\n",
      "[ep435] mean episode reward : 6.026599161233753\n",
      "episode 436 done\n",
      "[ep436] episode_rewards for agent 0 : 1.4099994897842407\n",
      "[ep436] episode_rewards for agent 1 : -49.555997321382165\n",
      "[ep436] episode_rewards for agent 2 : -52.61199702974409\n",
      "[ep436] episode_rewards for agent 3 : -33.6759984921664\n",
      "[ep436] episode_rewards for agent 4 : 22.13999831303954\n",
      "[ep436] episode_rewards for agent 5 : 103.1359934238717\n",
      "[ep436] episode_rewards for agent 6 : -5.6600005039945245\n",
      "[ep436] episode_rewards for agent 7 : -22.491999845020473\n",
      "[ep436] episode_rewards for agent 8 : -49.30399743746966\n",
      "[ep436] episode_rewards for agent 9 : 19.559998353011906\n",
      "[ep436] mean episode reward : -6.7054001050069925\n",
      "episode 437 done\n",
      "[ep437] episode_rewards for agent 0 : 94.30599404126406\n",
      "[ep437] episode_rewards for agent 1 : -58.543996524997056\n",
      "[ep437] episode_rewards for agent 2 : -46.235997499898076\n",
      "[ep437] episode_rewards for agent 3 : 11.291998663917184\n",
      "[ep437] episode_rewards for agent 4 : 35.987997602671385\n",
      "[ep437] episode_rewards for agent 5 : 124.73599190451205\n",
      "[ep437] episode_rewards for agent 6 : -38.44799815304577\n",
      "[ep437] episode_rewards for agent 7 : -35.78399860113859\n",
      "[ep437] episode_rewards for agent 8 : -49.939997248351574\n",
      "[ep437] episode_rewards for agent 9 : 85.66799450665712\n",
      "[ep437] mean episode reward : 12.303798869159072\n",
      "episode 438 done\n",
      "[ep438] episode_rewards for agent 0 : 69.67399552557617\n",
      "[ep438] episode_rewards for agent 1 : -58.46399656590074\n",
      "[ep438] episode_rewards for agent 2 : -39.15999828837812\n",
      "[ep438] episode_rewards for agent 3 : -20.259999750182033\n",
      "[ep438] episode_rewards for agent 4 : 8.675998823717237\n",
      "[ep438] episode_rewards for agent 5 : 102.76399331353605\n",
      "[ep438] episode_rewards for agent 6 : -30.403998899273574\n",
      "[ep438] episode_rewards for agent 7 : -41.047998018562794\n",
      "[ep438] episode_rewards for agent 8 : -48.10399752482772\n",
      "[ep438] episode_rewards for agent 9 : 28.011997844092548\n",
      "[ep438] mean episode reward : -2.8314003540202974\n",
      "episode 439 done\n",
      "[ep439] episode_rewards for agent 0 : 65.5499956374988\n",
      "[ep439] episode_rewards for agent 1 : -57.799996595829725\n",
      "[ep439] episode_rewards for agent 2 : -47.55599742103368\n",
      "[ep439] episode_rewards for agent 3 : 7.103998563252389\n",
      "[ep439] episode_rewards for agent 4 : 63.53599572554231\n",
      "[ep439] episode_rewards for agent 5 : 118.5439923601225\n",
      "[ep439] episode_rewards for agent 6 : -13.943999976851046\n",
      "[ep439] episode_rewards for agent 7 : -41.99199754651636\n",
      "[ep439] episode_rewards for agent 8 : -49.01599736884236\n",
      "[ep439] episode_rewards for agent 9 : 72.04799545928836\n",
      "[ep439] mean episode reward : 11.647398883663119\n",
      "episode 440 done\n",
      "[ep440] episode_rewards for agent 0 : 79.68199484609067\n",
      "[ep440] episode_rewards for agent 1 : -50.35199730377644\n",
      "[ep440] episode_rewards for agent 2 : -56.3959967456758\n",
      "[ep440] episode_rewards for agent 3 : -0.15200053621083498\n",
      "[ep440] episode_rewards for agent 4 : 80.13999465666711\n",
      "[ep440] episode_rewards for agent 5 : 63.1959956260398\n",
      "[ep440] episode_rewards for agent 6 : -12.239999814890325\n",
      "[ep440] episode_rewards for agent 7 : -49.87199737969786\n",
      "[ep440] episode_rewards for agent 8 : -50.69199720863253\n",
      "[ep440] episode_rewards for agent 9 : 19.871998285874724\n",
      "[ep440] mean episode reward : 2.318599442578852\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[320], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mdecide_action_and_set()\n\u001b[1;32m      9\u001b[0m     actions[agent_id] \u001b[38;5;241m=\u001b[39m action[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m agent_ids, states, rewards, dones \u001b[38;5;241m=\u001b[39m \u001b[43mw_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_id, agent \u001b[38;5;129;01min\u001b[39;00m agents\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     12\u001b[0m     agent\u001b[38;5;241m.\u001b[39mupdate_experience(agent_ids, states, rewards, dones, actions[agent_id])\n",
      "Cell \u001b[0;32mIn[138], line 54\u001b[0m, in \u001b[0;36mEnvWrapper.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     agent_ids, states, rewards, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m agent_ids, states, rewards, dones\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/timers.py:305\u001b[0m, in \u001b[0;36mtimed.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/environment.py:348\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m step_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_step_input(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env_actions)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunicator.exchange\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexchange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnityCommunicatorStoppedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunicator has exited.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/rpc_communicator.py:142\u001b[0m, in \u001b[0;36mRpcCommunicator.exchange\u001b[0;34m(self, inputs, poll_callback)\u001b[0m\n\u001b[1;32m    140\u001b[0m message\u001b[38;5;241m.\u001b[39munity_input\u001b[38;5;241m.\u001b[39mCopyFrom(inputs)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munity_to_external\u001b[38;5;241m.\u001b[39mparent_conn\u001b[38;5;241m.\u001b[39msend(message)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll_for_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munity_to_external\u001b[38;5;241m.\u001b[39mparent_conn\u001b[38;5;241m.\u001b[39mrecv()\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mheader\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/mnt/d/Program Files/Unity/ml-agents-release_20/ml-agents-envs/mlagents_envs/rpc_communicator.py:106\u001b[0m, in \u001b[0;36mRpcCommunicator.poll_for_timeout\u001b[0;34m(self, poll_callback)\u001b[0m\n\u001b[1;32m    104\u001b[0m callback_timeout_wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout_wait \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m<\u001b[39m deadline:\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munity_to_external\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback_timeout_wait\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;66;03m# Got an acknowledgment from the connection\u001b[39;00m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m poll_callback:\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;66;03m# Fire the callback - if it detects something wrong, it should raise an exception.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# episode = 1\n",
    "\n",
    "# while True:\n",
    "#     # exploration\n",
    "#     for step in range(TRAJECTORY_SIZE):\n",
    "#         actions = {}\n",
    "#         for agent_id, agent in agents.items():\n",
    "#             action = agent.decide_action_and_set()\n",
    "#             actions[agent_id] = action[0]\n",
    "#         agent_ids, states, rewards, dones = w_env.step()\n",
    "#         for agent_id, agent in agents.items():\n",
    "#             agent.update_experience(agent_ids, states, rewards, dones, actions[agent_id])\n",
    "#         if any(dones):\n",
    "#             print(f'episode {episode} done')\n",
    "#             _ = w_env.reset()\n",
    "#             all_agents_rewards = []\n",
    "#             for agent_id, agent in agents.items():\n",
    "#                 agent.reset_episode()\n",
    "#                 print(f'[ep{episode}] episode_rewards for agent {agent_id} : {agent._episode_rewards[-1]}')\n",
    "#                 all_agents_rewards.append(agent._episode_rewards[-1])\n",
    "#             print(f'[ep{episode}] mean episode reward : {sum(all_agents_rewards) / len(all_agents_rewards)}')\n",
    "#             episode += 1\n",
    "#     # train\n",
    "#     for agent_id, agent in agents.items():\n",
    "#         agent.train(ppo_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af429e-7240-4093-9fd4-ab299fe7681f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c23353-90a5-4703-abad-cb36e728383c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab97775-a9a7-4765-b18d-a94474dc4ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "912de090-3fa5-49f3-8f21-14cbad86a7d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:39<00:00, 10.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# for i in tqdm(range(1000)):\n",
    "#     for agent in agents:\n",
    "#         c_acts, d_acts = w_env.random_action()\n",
    "#         agent.set_action(c_acts, d_acts)\n",
    "#     agent_ids, states, rewards, dones = w_env.step()\n",
    "#     if any(dones):\n",
    "#         print(dones)\n",
    "#         w_env.reset()\n",
    "#     # time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e7c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "143ae611",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d58382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
